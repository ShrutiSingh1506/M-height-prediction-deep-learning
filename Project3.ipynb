{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CSCE 636 — Project 3  \n",
        "## m-Height Prediction with Advanced Deep Learning Methods  \n",
        "**Student:** Shruti Singh  \n",
        "**Semester:** Fall 2025\n",
        "\n",
        "---\n",
        "\n",
        "##  Project Overview\n",
        "\n",
        "The goal of **Project 3** is to build a high-accuracy deep learning model that predicts the  \n",
        "**m-height** of generator matrices associated with \\((n,k,m,P)\\) constructions in coding theory,  \n",
        "under the fixed specification **\\(n = 9\\)**.\n",
        "\n",
        "We are given a **larger training dataset (56,365 samples)** that contains all of Project 2’s data  \n",
        "plus new samples. We are also encouraged to **augment the dataset further** and  \n",
        "**experiment with new architectures**, including:\n",
        "\n",
        "- Transformer-style models  \n",
        "- Mixture-of-Experts (MoE) architectures  \n",
        "- Larger / deeper feature extractors  \n",
        "- Alternative featurizations  \n",
        "- New augmentation strategies  \n",
        "- Mathematical properties of \\(P\\) and m-heights  \n",
        "- Increased dataset generation  \n",
        "\n",
        "---\n",
        "\n",
        "##  What This Notebook Does\n",
        "\n",
        "This notebook builds **two complete end-to-end models**:\n",
        "\n",
        "### **1. MoE-Style Expert Ensemble (Best Score ≈ 0.838 log₂-MSE)**  \n",
        "- Extension of the best-performing Project 2 model  \n",
        "- Group-aware splits (no leakage between permuted samples)  \n",
        "- Difficulty-aware augmentation (easy/medium/hard buckets)  \n",
        "- Learned feature extractor (SVD-64)  \n",
        "- Expert ensembles per \\((k,m)\\) bucket with linear calibration  \n",
        "- This model delivers the **best score** and will be used for submission.\n",
        "\n",
        "### **2. Transformer-Based Global Model (Experimental)**  \n",
        "- Treats \\(P\\) as a masked sequence of tokens  \n",
        "- Performs global attention over padded tokens  \n",
        "- Shows competitive but slightly weaker performance  \n",
        "  compared to the MoE ensemble  \n",
        "- Included for comparison & completeness  \n",
        "- Justifies why MoE is chosen for final submission\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "##  Notebook Structure\n",
        "\n",
        "1. **Phase 1** — Environment & Global Configuration  \n",
        "2. **Phase 2** — Enhanced Featurizer (64-dim)  \n",
        "3. **Phase 3** — Load DS-3 Dataset  \n",
        "4. **Phase 4** — Leakage-Protected Group-Aware Splitting  \n",
        "5. **Phase 5** — Oversampling & Difficulty-Aware Augmentation  \n",
        "6. **Phase 6** — Mixture-of-Experts (MoE) Ensemble Training  \n",
        "7. **Phase 7** — Validation & Test Evaluation  \n",
        "8. **Phase 8** — Transformer Model (Experimental)    \n",
        "9. **Phase 9** — Save Submission Artifacts  \n",
        "10. **Phase 10** — Final Submission Cell (auto-zip & prediction generator)\n",
        "\n",
        "---\n",
        "\n",
        "##  Goal for Project 3\n",
        "\n",
        "To outperform Project 2 and approach the **high-score regime **  \n",
        "via methodical:\n",
        "\n",
        "- Data augmentation  \n",
        "- Careful leakage prevention  \n",
        "- Advanced model design  \n",
        "- Proper calibration  \n",
        "- Ensemble averaging  \n",
        "- Large-scale feature engineering  \n",
        "\n",
        "The MoE model in this notebook currently achieves **≈0.838**, which is strong,  \n",
        "and all additional experiments are included transparently.\n",
        "\n",
        "---\n",
        "\n",
        "Below begins **Phase 1 — Environment & Global Configuration**.\n"
      ],
      "metadata": {
        "id": "RnOr5cW6wtZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1 — Environment & Global Configuration\n",
        "\n",
        "This phase sets up the **reproducible environment** and **global hyperparameters** for Project 3.\n",
        "\n",
        "**Goals of this phase:**\n",
        "- Fix all random seeds (NumPy, Python, TensorFlow/Keras) for **deterministic experiments**.\n",
        "- Define the **problem structure**:\n",
        "  - Fixed block length: \\( n = 9 \\)\n",
        "  - Valid \\((k, m)\\) pairs:  \n",
        "    \\((4,2),(4,3),(4,4),(4,5),(5,2),(5,3),(5,4),(6,2),(6,3)\\)\n",
        "- Configure the **TVT split plan**:\n",
        "  - Train / Val / Test = **60% / 20% / 20%**\n",
        "- Set **training defaults** shared across models:\n",
        "  - Batch size, max epochs, early-stopping patience, learning rate schedule\n",
        "  - AdamW optimizer with weight decay + gradient clipping\n",
        "  - Optionally use **Huber loss** for hard \\((k,m)\\) buckets to stabilize training on outliers.\n",
        "- Define **ensemble seeds**:\n",
        "  - 3-model ensembles for **easy/medium** pairs\n",
        "  - 5-model ensembles for **hard** pairs (higher variance / more difficult m-heights)\n",
        "- Provide a small helper metric `log2_mse` that matches the **professor’s grading metric**:\n",
        "  - All models are trained and evaluated in **log2(m-height)** space.\n",
        "\n",
        "The final printout confirms:\n",
        "- Library versions (Python, NumPy, TF, Keras)\n",
        "- Available GPU (if any)\n",
        "- Valid \\((k,m)\\) pairs and TVT fractions\n",
        "- Seed sets for the ensembles\n",
        "\n",
        "All later phases (MoE baseline and Transformer experiments) use these shared settings to make results **comparable and reproducible**.\n"
      ],
      "metadata": {
        "id": "9BPxRvnMwNOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q94BdpN4u62m",
        "outputId": "ce3c7290-7e53-4eb2-aa1c-61cc7da57d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment summary\n",
            "Python : 3.12.12\n",
            "NumPy  : 2.0.2\n",
            "TF     : 2.19.0\n",
            "Keras  : 3.10.0\n",
            "GPU    : []\n",
            "\n",
            "VALID_PAIRS: [(4, 2), (4, 3), (4, 4), (4, 5), (5, 2), (5, 3), (5, 4), (6, 2), (6, 3)]\n",
            "Splits (train/val/test): (0.6, 0.2, 0.2)\n",
            "Ensemble seeds (easy/med): [41, 1337, 9001]\n",
            "Ensemble seeds (hard):     [41, 1337, 9001, 2027, 7]\n"
          ]
        }
      ],
      "source": [
        "# Phase 1 — Environment & Global Configuration\n",
        "# CSCE 636 | Project 3 — m-height Prediction\n",
        "\n",
        "import os, sys, math, random, pickle, hashlib\n",
        "from collections import defaultdict, Counter\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# TensorFlow / Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Reproducibility utilities\n",
        "def set_global_seed(seed: int = 2025):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    try:\n",
        "        tf.keras.utils.set_random_seed(seed)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        tf.config.experimental.enable_op_determinism()\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        tf.config.threading.set_inter_op_parallelism_threads(1)\n",
        "        tf.config.threading.set_intra_op_parallelism_threads(1)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "SEED = 2025\n",
        "set_global_seed(SEED)\n",
        "\n",
        "# Problem constants (per spec)\n",
        "N = 9\n",
        "VALID_PAIRS = [(k, m) for k in (4, 5, 6) for m in range(2, N - k + 1)]\n",
        "assert VALID_PAIRS == [(4,2),(4,3),(4,4),(4,5),\n",
        "                       (5,2),(5,3),(5,4),\n",
        "                       (6,2),(6,3)]\n",
        "\n",
        "# Train/Val/Test plan\n",
        "TRAIN_FRAC = 0.60\n",
        "VAL_FRAC   = 0.20\n",
        "TEST_FRAC  = 0.20\n",
        "assert abs(TRAIN_FRAC + VAL_FRAC + TEST_FRAC - 1.0) < 1e-8\n",
        "\n",
        "# Training defaults\n",
        "BATCH_SIZE    = 256\n",
        "MAX_EPOCHS    = 300\n",
        "PATIENCE      = 25\n",
        "LR_PATIENCE   = 10\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY  = 1e-4\n",
        "GRAD_CLIP_NORM = 1.0\n",
        "\n",
        "# For hard buckets we'll use Huber; for others plain MSE\n",
        "USE_HUBER_FOR_HARD = True\n",
        "HUBER_DELTA = 0.75\n",
        "\n",
        "# Ensemble seeds\n",
        "ENSEMBLE_SEEDS_EASYMED = [41, 1337, 9001]\n",
        "ENSEMBLE_SEEDS_HARD    = [41, 1337, 9001, 2027, 7]\n",
        "\n",
        "# Helper: log2-MSE metric\n",
        "def log2_mse(z_true, z_pred):\n",
        "    z_true = np.asarray(z_true).ravel()\n",
        "    z_pred = np.asarray(z_pred).ravel()\n",
        "    return float(np.mean((z_true - z_pred) ** 2))\n",
        "\n",
        "print(\"Environment summary\")\n",
        "print(\"Python :\", sys.version.split()[0])\n",
        "print(\"NumPy  :\", np.__version__)\n",
        "print(\"TF     :\", tf.__version__)\n",
        "print(\"Keras  :\", keras.__version__)\n",
        "print(\"GPU    :\", tf.config.list_physical_devices('GPU'))\n",
        "print()\n",
        "print(\"VALID_PAIRS:\", VALID_PAIRS)\n",
        "print(\"Splits (train/val/test):\", (TRAIN_FRAC, VAL_FRAC, TEST_FRAC))\n",
        "print(\"Ensemble seeds (easy/med):\", ENSEMBLE_SEEDS_EASYMED)\n",
        "print(\"Ensemble seeds (hard):    \", ENSEMBLE_SEEDS_HARD)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Phase 2 — Permutation-Invariant SVD-64 Featurizer**\n",
        "\n",
        "This phase builds the **core feature extractor** used throughout the entire project.  \n",
        "Unlike standard “handcrafted + SVD” feature sets, this featurizer is:\n",
        "\n",
        "###  **Permutation-Invariant**\n",
        "It produces **identical features** even if the rows or columns of matrix \\(P\\) are permuted.  \n",
        "This is essential because:\n",
        "\n",
        "- In generator matrices, **row and column order is not meaningful**,  \n",
        "- Row/column permutations **preserve the m-height**,  \n",
        "- Without invariance, the model would learn artificial noise, hurting generalization.\n",
        "\n",
        "###  **Stable & Continuous**\n",
        "All features are based on smooth numerical operations: norms, energy shares, entropies, etc.  \n",
        "This ensures the model receives **well-behaved gradients** and avoids brittle behaviors.\n",
        "\n",
        "###  **Information-Rich (64-dim)**\n",
        "The featurizer includes:\n",
        "\n",
        "#### **1. Structural scalar features**\n",
        "- \\(n, k, m\\),  \n",
        "- ratios such as \\(k/n\\), \\(m/k\\), \\(m/(n-k)\\),  \n",
        "- polynomial/logarithmic interactions.\n",
        "\n",
        "#### **2. Column & row norm statistics**\n",
        "- mean / std / min / max  \n",
        "- top-3 largest column norms  \n",
        "- Gini coefficients (inequality measures)  \n",
        "- energy concentration ratios  \n",
        "- row/column cross-statistics  \n",
        "\n",
        "These capture how mass is distributed within \\(P\\).\n",
        "\n",
        "#### **3. Matrix-level features**\n",
        "- mean, std, Frobenius norm  \n",
        "- rank  \n",
        "- sign distribution  \n",
        "- max absolute entry  \n",
        "\n",
        "These describe global structure of \\(P\\).\n",
        "\n",
        "#### **4. SVD-based spectral features**\n",
        "The key for strong performance:\n",
        "\n",
        "- Top 5 singular values  \n",
        "- Squared-energy shares  \n",
        "- Spectral entropy  \n",
        "- Condition numbers  \n",
        "- Log-det proxy  \n",
        "- Cumulative energy until \\(m\\)\n",
        "\n",
        "Singular values are **the most informative permutation-invariant descriptors** of a matrix.\n",
        "\n",
        "#### **5. Cross statistics**\n",
        "Capturing interactions between row- and column-based structures.\n",
        "\n",
        "###  **Sanity Checks Performed**\n",
        "The notebook verifies:\n",
        "\n",
        "- output dimension is exactly **64**\n",
        "- permuting rows/columns yields **max diff = 0.000e+00**\n",
        "- features are numerically stable (no NaNs, no discontinuities)\n",
        "\n",
        "This confirms the featurizer is correctly invariant and ready for training.\n",
        "\n",
        "###  Why This Featurizer?\n",
        "This 64-dim extractor aligns perfectly with the below:\n",
        "- The **importance of spectral information**  \n",
        "- The usefulness of **permutation-invariant statistics**  \n",
        "- Avoiding reliance on raw P-matrix entries (which are order-dependent)\n",
        "\n",
        "It is the **single most critical component** enabling the model to reach  \n",
        "**0.83–0.84 log₂-MSE** with relatively compact networks.\n",
        "\n",
        "---\n",
        "\n",
        "**Below is the implementation of the SVD-64 featurizer along with permutation-invariance tests.**\n"
      ],
      "metadata": {
        "id": "BgsWVjM2xjlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 2 — Permutation-Invariant SVD-64 Featurizer\n",
        "\n",
        "FEAT_DIM = 64\n",
        "EPS = 1e-12\n",
        "\n",
        "def _gini_like(x: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Simple inequality measure in [0,1). Invariant to permutation and scaling.\n",
        "    Returns 0 if vector is all zeros.\n",
        "    \"\"\"\n",
        "    x = np.abs(np.asarray(x, dtype=np.float64)).ravel()\n",
        "    if x.size == 0:\n",
        "        return 0.0\n",
        "    s = np.sum(x)\n",
        "    if s <= EPS:\n",
        "        return 0.0\n",
        "    xs = np.sort(x)  # ascending\n",
        "    n = x.size\n",
        "    idx = np.arange(1, n + 1, dtype=np.float64)\n",
        "    # Gini = (2 * sum(i*xi)/(n*sum) ) - (n+1)/n\n",
        "    return float((2.0 * np.sum(idx * xs) / (n * s)) - (n + 1.0) / n)\n",
        "\n",
        "def featurize_sample(n: int, k: int, m: int, P: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Build a FEAT_DIM-D permutation-invariant vector from (n,k,m,P); returns float32[FEAT_DIM].\n",
        "    Assumes n == 9, k in {4,5,6}, 2 <= m <= n-k, and P.shape == (k, n-k).\n",
        "    Invariance: row/column permutations of P do not change the features.\n",
        "    \"\"\"\n",
        "    # --- guards ---\n",
        "    P = np.asarray(P, dtype=np.float64)\n",
        "    assert n == 9, f\"Expected n=9, got n={n}\"\n",
        "    assert k in (4, 5, 6), f\"Expected k in {{4,5,6}}, got k={k}\"\n",
        "    nk = n - k\n",
        "    assert 2 <= m <= nk, f\"Expected 2 <= m <= {nk}, got m={m}\"\n",
        "    assert P.shape == (k, nk), f\"P shape should be ({k}, {nk}), got {P.shape}\"\n",
        "\n",
        "    feats = []\n",
        "\n",
        "    # ---------- 1) Basics from (n,k,m) ----------\n",
        "    n_f = float(n); k_f = float(k); m_f = float(m); nk_f = float(nk)\n",
        "    feats.extend([\n",
        "        n_f, k_f, m_f,                # raw\n",
        "        k_f / n_f,                    # k/n\n",
        "        m_f / (k_f + EPS),            # m/k\n",
        "        m_f / (nk_f + EPS),           # m/(n-k)\n",
        "        (m_f**2) / (k_f + EPS),       # m^2/k\n",
        "        m_f * k_f,                    # m*k\n",
        "        float(np.log2(m_f + 1.0)),\n",
        "        float(np.log2(k_f + 1.0)),\n",
        "    ])  # 10 so far\n",
        "\n",
        "    # ---------- 2) Column & row norms ----------\n",
        "    col_norms = np.linalg.norm(P, axis=0)  # len = nk\n",
        "    row_norms = np.linalg.norm(P, axis=1)  # len = k\n",
        "\n",
        "    # Column stats (permutation-invariant)\n",
        "    c_mean = float(np.mean(col_norms)) if col_norms.size else 0.0\n",
        "    c_std  = float(np.std(col_norms))  if col_norms.size else 0.0\n",
        "    c_max  = float(np.max(col_norms))  if col_norms.size else 0.0\n",
        "    c_min  = float(np.min(col_norms))  if col_norms.size else 0.0\n",
        "    c_gini = _gini_like(col_norms)\n",
        "\n",
        "    col_sorted = np.sort(col_norms)[::-1]\n",
        "    top3 = [float(col_sorted[i]) if i < len(col_sorted) else 0.0 for i in range(3)]\n",
        "    mth  = float(col_sorted[m-1]) if (m-1) < len(col_sorted) and m >= 1 else 0.0\n",
        "    topm_sum = float(np.sum(col_sorted[:m])) if m <= len(col_sorted) else float(np.sum(col_sorted))\n",
        "    col_sum = float(np.sum(col_sorted)) + EPS\n",
        "    topm_share = topm_sum / col_sum\n",
        "\n",
        "    feats.extend([\n",
        "        c_mean, c_std, c_max, c_min, c_gini,\n",
        "        *top3, mth, topm_share\n",
        "    ])  # +9 → 19 total\n",
        "\n",
        "    # Row stats (permutation-invariant)\n",
        "    r_mean = float(np.mean(row_norms)) if row_norms.size else 0.0\n",
        "    r_std  = float(np.std(row_norms))  if row_norms.size else 0.0\n",
        "    r_max  = float(np.max(row_norms))  if row_norms.size else 0.0\n",
        "    r_min  = float(np.min(row_norms))  if row_norms.size else 0.0\n",
        "    r_ratio = float(r_max / (r_min + EPS)) if r_min > 0 else 1000.0\n",
        "    r_gini  = _gini_like(row_norms)\n",
        "\n",
        "    feats.extend([r_mean, r_std, r_max, r_min, r_ratio, r_gini])  # +6 → 25\n",
        "\n",
        "    # ---------- 3) Matrix-level stats ----------\n",
        "    feats.extend([\n",
        "        float(np.mean(P)),\n",
        "        float(np.std(P)),\n",
        "        float(np.max(np.abs(P))) if P.size else 0.0,\n",
        "        float(np.linalg.norm(P, 'fro')),\n",
        "        float(np.sum(P * P)),\n",
        "        float(np.mean(P > 0)) if P.size else 0.0,\n",
        "        float(np.linalg.matrix_rank(P)),\n",
        "    ])  # +7 → 32\n",
        "\n",
        "    # ---------- 4) Spectrum (SVD) ----------\n",
        "    # Singular values are invariant to row/column permutations\n",
        "    try:\n",
        "        svals = np.sort(np.linalg.svd(P, compute_uv=False))[::-1]\n",
        "    except np.linalg.LinAlgError:\n",
        "        svals = np.zeros(min(k, nk), dtype=np.float64)\n",
        "\n",
        "    # pad to 5 singular values\n",
        "    S = np.zeros(5, dtype=np.float64)\n",
        "    r = min(5, svals.size)\n",
        "    if r > 0:\n",
        "        S[:r] = svals[:r]\n",
        "\n",
        "    energy = S**2\n",
        "    tot_energy = float(np.sum(energy)) + EPS\n",
        "    shares = (energy / tot_energy).tolist()  # length 5\n",
        "    cum_at_m = float(np.sum(energy[:min(m, 5)]) / tot_energy)\n",
        "\n",
        "    ps = energy / tot_energy\n",
        "    ps = np.clip(ps, EPS, 1.0)\n",
        "    spec_entropy = float(-np.sum(ps * np.log(ps)))\n",
        "\n",
        "    s_top = float(S[0])\n",
        "    s_bot = float(S[r-1]) if r > 0 and S[r-1] > 0 else EPS\n",
        "    s_med = float(np.median(S[:r])) if r > 0 else EPS\n",
        "    cond_tb = float(s_top / (s_bot + EPS))\n",
        "    cond_tm = float(s_top / (s_med + EPS))\n",
        "\n",
        "    feats.extend([\n",
        "        *S.tolist(),                         # 5\n",
        "        *shares,                             # 5\n",
        "        cum_at_m,                            # 1\n",
        "        spec_entropy,                        # 1\n",
        "        float(2.0 * np.sum(np.log(S[:r] + EPS))),  # log-det(Gram)\n",
        "        cond_tb, cond_tm,                    # 2\n",
        "        float(np.sum(S[:r])),                # sum singulars\n",
        "        float(np.mean(S[:r])) if r > 0 else 0.0,   # mean singular\n",
        "    ])  # +5+5+1+1+1+2+2 = 17 → 49 total\n",
        "\n",
        "    # ---------- 5) Cross stats ----------\n",
        "    feats.extend([\n",
        "        float(r_mean * c_mean),\n",
        "        float((r_mean / (c_mean + EPS)) if c_mean > 0 else 0.0),\n",
        "        float((c_max / (c_min + EPS)) if c_min > 0 else 1000.0),\n",
        "    ])  # +3 → 52\n",
        "\n",
        "    # ---------- 6) Pad / truncate to FEAT_DIM ----------\n",
        "    if len(feats) < FEAT_DIM:\n",
        "        feats.extend([0.0] * (FEAT_DIM - len(feats)))\n",
        "    elif len(feats) > FEAT_DIM:\n",
        "        feats = feats[:FEAT_DIM]\n",
        "\n",
        "    return np.asarray(feats, dtype=np.float32)\n",
        "\n",
        "def featurize_list(X_list):\n",
        "    \"\"\"\n",
        "    X_list: list of [n, k, m, P]\n",
        "    Returns:\n",
        "      F: float32 [N, FEAT_DIM]\n",
        "      KS: int32 [N]\n",
        "      MS: int32 [N]\n",
        "    \"\"\"\n",
        "    N = len(X_list)\n",
        "    F = np.zeros((N, FEAT_DIM), dtype=np.float32)\n",
        "    KS = np.zeros(N, dtype=np.int32)\n",
        "    MS = np.zeros(N, dtype=np.int32)\n",
        "    for i, (n, k, m, P) in enumerate(X_list):\n",
        "        F[i] = featurize_sample(n, k, m, P)\n",
        "        KS[i] = int(k); MS[i] = int(m)\n",
        "    return F, KS, MS\n",
        "\n",
        "# Quick self-check for shape + invariance to row/col permutations\n",
        "rng = np.random.default_rng(0)\n",
        "_k, _m = 5, 3\n",
        "_P = rng.normal(size=(_k, 9 - _k))\n",
        "_feat = featurize_sample(9, _k, _m, _P)\n",
        "\n",
        "print(f\"Featurizer sanity check:\")\n",
        "print(f\"  Feature dim: {FEAT_DIM}\")\n",
        "print(f\"  One sample feat shape: {_feat.shape}, sum={float(_feat.sum()):.4f}\")\n",
        "\n",
        "for k, m in [(4,2), (5,3), (6,3)]:\n",
        "    nk = 9 - k\n",
        "    P = rng.normal(size=(k, nk))\n",
        "    f0 = featurize_sample(9, k, m, P)\n",
        "    rperm = rng.permutation(k)\n",
        "    cperm = rng.permutation(nk)\n",
        "    Pp = P[rperm][:, cperm]\n",
        "    f1 = featurize_sample(9, k, m, Pp)\n",
        "    diff = np.max(np.abs(f0 - f1))\n",
        "    print(f\"  (k={k}, m={m}) max|feat(P) - feat(perm(P))| = {diff:.3e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwBJV2EbwXFP",
        "outputId": "01dc070d-0697-4d27-d0e7-1df593cee7b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Featurizer sanity check:\n",
            "  Feature dim: 64\n",
            "  One sample feat shape: (64,), sum=126.5709\n",
            "  (k=4, m=2) max|feat(P) - feat(perm(P))| = 0.000e+00\n",
            "  (k=5, m=3) max|feat(P) - feat(perm(P))| = 0.000e+00\n",
            "  (k=6, m=3) max|feat(P) - feat(perm(P))| = 0.000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 3 — Load Project-3 Data and Build SVD-64 Features\n",
        "\n",
        "In this phase, I ingest the **Project 3 training set** and convert it into the feature space used by all downstream models.\n",
        "\n",
        "### 3.1 Load `(n, k, m, P)` and m-height pickles\n",
        "\n",
        "- A robust loader scans all `.pkl/.pickle` files in the working directory and:\n",
        "  - Auto-detects the **input file** as a list of tuples `(n, k, m, P)`  \n",
        "    where `P` has shape `(k, 9−k)` and `n = 9`, `k ∈ {4,5,6}`, `2 ≤ m ≤ 9−k`.\n",
        "  - Auto-detects the **output file** as a 1-D numeric array of m-heights.\n",
        "- It validates:\n",
        "  - Equal length between inputs and outputs.\n",
        "  - Basic shape constraints on `P`.\n",
        "\n",
        "This matches the **DS-3 training set** specification given in the project description.\n",
        "\n",
        "### 3.2 Target transformation: m-height → log₂(m-height)\n",
        "\n",
        "- Raw targets `y` (m-heights) are:\n",
        "  - Clamped to `y ≥ 1` to avoid log issues.\n",
        "  - Transformed to `z = log₂(y)` which:\n",
        "    - Compresses the large dynamic range of m-heights,\n",
        "    - Matches the **grading metric** (log₂-MSE) used by the professor,\n",
        "    - Makes optimization more numerically stable.\n",
        "\n",
        "All models in this notebook are trained and evaluated in **log₂ space**.\n",
        "\n",
        "### 3.3 SVD-64 feature construction\n",
        "\n",
        "- For every sample `(n, k, m, P)`:\n",
        "  - The Phase-2 **permutation-invariant SVD-64 featurizer** is applied.\n",
        "  - This yields a fixed-dimensional, information-rich representation:\n",
        "    \\[\n",
        "    (n, k, m, P) \\longrightarrow \\mathbf{x} \\in \\mathbb{R}^{64}\n",
        "    \\]\n",
        "- The notebook reports:\n",
        "  - `ALL_FEATURES.shape` (should be `[N, 64]`),\n",
        "  - Summary statistics of `y` and `z`.\n",
        "\n",
        "This confirms that the **entire DS-3 training set** has been successfully mapped into the 64-D feature space.\n",
        "\n",
        "### 3.4 Per-bucket (k, m) distribution\n",
        "\n",
        "- I compute counts for each valid pair \\((k, m)\\) in:\n",
        "  \\[\n",
        "    (4,2), (4,3), (4,4), (4,5),\n",
        "    (5,2), (5,3), (5,4),\n",
        "    (6,2), (6,3)\n",
        "  \\]\n",
        "- This is used later to:\n",
        "  - Define **easy / medium / hard** difficulty tiers,\n",
        "  - Design **non-uniform augmentation** strategies that emphasize harder buckets (e.g., (4,5), (5,4), (6,3)),\n",
        "  - Report per-bucket performance the same way the professor summarizes results.\n",
        "\n",
        "### 3.5 Base group IDs (for leakage-safe splitting)\n",
        "\n",
        "- I assign a **unique group ID** to every original sample:\n",
        "  - `BASE_GROUP_IDS = [0, 1, 2, ..., N−1]`\n",
        "- These group IDs are used in the next phase with **GroupShuffleSplit** to ensure:\n",
        "  - All future augmented copies of a sample stay in the **same split**,\n",
        "  - There is **no data leakage** between train / val / test, even under heavy data augmentation.\n",
        "\n",
        "---\n",
        "\n",
        "At the end of this phase, I have:\n",
        "\n",
        "- Raw DS-3 data loaded and validated,\n",
        "- Log₂-transformed targets `z`,\n",
        "- A full **[N × 64]** feature matrix from the SVD-64 featurizer,\n",
        "- Per-bucket counts and leakage-safe group IDs ready for deterministic TVT splitting.\n"
      ],
      "metadata": {
        "id": "aTwQR05Qyqip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 3 — Load Project 3 Data + SVD-64 Features\n",
        "\n",
        "import glob\n",
        "\n",
        "# ---------- Helpers to detect input/output pickles ----------\n",
        "\n",
        "def _looks_like_inputs(obj):\n",
        "    \"\"\"\n",
        "    Heuristic: list of [n,k,m,P] with n=9, k in {4,5,6}, 2<=m<=n-k, P shape (k, 9-k).\n",
        "    \"\"\"\n",
        "    if not isinstance(obj, (list, tuple)) or not obj:\n",
        "        return False\n",
        "    a = obj[0]\n",
        "    if not (isinstance(a, (list, tuple)) and len(a) == 4):\n",
        "        return False\n",
        "    n, k, m, P = a\n",
        "    try:\n",
        "        P = np.asarray(P)\n",
        "        return (n == 9) and (k in (4,5,6)) and (2 <= m <= (9-k)) and (P.ndim == 2) and (P.shape == (k, 9-k))\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def _looks_like_outputs(obj):\n",
        "    \"\"\"\n",
        "    Heuristic: 1D numeric array/list of m-heights.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        arr = np.asarray(obj)\n",
        "        return (arr.ndim == 1) and np.issubdtype(arr.dtype, np.number) and (len(arr) >= 1)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def load_project3_pickles(input_path=None, output_path=None):\n",
        "    \"\"\"\n",
        "    Robust loader for Project 3 train pickles.\n",
        "    If paths not provided, tries to auto-detect from all .pkl/.pickle in cwd.\n",
        "    \"\"\"\n",
        "    # 1) Collect candidate paths\n",
        "    paths = []\n",
        "    if input_path and output_path and os.path.exists(input_path) and os.path.exists(output_path):\n",
        "        paths = [input_path, output_path]\n",
        "    else:\n",
        "        paths = [p for p in os.listdir(\".\") if p.endswith((\".pkl\", \".pickle\"))]\n",
        "        if not paths:\n",
        "            try:\n",
        "                from google.colab import files  # type: ignore\n",
        "                print(\"No pickle files found. Please upload the Project 3 input/output pickles now.\")\n",
        "                up = files.upload()\n",
        "                paths = list(up.keys())\n",
        "            except Exception as e:\n",
        "                raise RuntimeError(\"No pickle files found; please provide explicit paths.\") from e\n",
        "\n",
        "    # 2) Try to load everything\n",
        "    cache = {}\n",
        "    for p in paths:\n",
        "        try:\n",
        "            with open(p, \"rb\") as f:\n",
        "                cache[p] = pickle.load(f)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # 3) Detect inputs & outputs\n",
        "    inputs, outputs = None, None\n",
        "    for p, obj in cache.items():\n",
        "        if _looks_like_inputs(obj) and inputs is None:\n",
        "            inputs = (p, obj)\n",
        "        elif _looks_like_outputs(obj) and outputs is None:\n",
        "            outputs = (p, obj)\n",
        "\n",
        "    # Fallback based on length match\n",
        "    if (inputs is None) or (outputs is None):\n",
        "        keys = list(cache.keys())\n",
        "        for i in range(len(keys)):\n",
        "            for j in range(len(keys)):\n",
        "                if i == j:\n",
        "                    continue\n",
        "                a, b = cache[keys[i]], cache[keys[j]]\n",
        "                if _looks_like_inputs(a) and _looks_like_outputs(b) and len(a) == len(b):\n",
        "                    inputs, outputs = (keys[i], a), (keys[j], b)\n",
        "                    break\n",
        "            if inputs and outputs:\n",
        "                break\n",
        "\n",
        "    if (inputs is None) or (outputs is None):\n",
        "        raise RuntimeError(\"Could not identify Project 3 input/output pickles. Check files.\")\n",
        "\n",
        "    in_name, X_list = inputs\n",
        "    out_name, y_list = outputs\n",
        "    if len(X_list) != len(y_list):\n",
        "        raise RuntimeError(f\"Length mismatch: inputs={len(X_list)} vs outputs={len(y_list)}\")\n",
        "\n",
        "    print(f\"Using input file:  {in_name}\")\n",
        "    print(f\"Using output file: {out_name}\")\n",
        "    print(f\"Total samples:     {len(X_list):,}\")\n",
        "    return X_list, y_list\n",
        "\n",
        "# ---------- Load Project 3 train set ----------\n",
        "\n",
        "X_list, y_list = load_project3_pickles()\n",
        "\n",
        "N_samples = len(X_list)\n",
        "\n",
        "# y: clamp to >=1, then log2\n",
        "y_arr = np.asarray(y_list, dtype=np.float64)\n",
        "y_arr = np.maximum(1.0, y_arr)\n",
        "z_arr = np.log2(y_arr)\n",
        "\n",
        "# Build SVD-64 features\n",
        "ALL_FEATURES, KS, MS = featurize_list(X_list)\n",
        "\n",
        "print(\"\\nFeature / target summary:\")\n",
        "print(f\"  Features shape: {ALL_FEATURES.shape}  (FEAT_DIM={ALL_FEATURES.shape[1]})\")\n",
        "print(f\"  y (m-height) clamp>=1: min={y_arr.min():.4f}  max={y_arr.max():.4f}\")\n",
        "print(f\"  z = log2(y):           min={z_arr.min():.4f}  max={z_arr.max():.4f}  mean={z_arr.mean():.4f}  std={z_arr.std():.4f}\")\n",
        "\n",
        "# ---------- Per-(k,m) distribution ----------\n",
        "pair_counts = Counter((int(k), int(m)) for k, m in zip(KS, MS))\n",
        "\n",
        "print(\"\\nPer-(k,m) counts in Project 3 train set:\")\n",
        "total_check = 0\n",
        "for (k, m) in sorted(pair_counts.keys()):\n",
        "    c = pair_counts[(k, m)]\n",
        "    total_check += c\n",
        "    print(f\"  (k={k}, m={m}): {c:6d}\")\n",
        "print(f\"  TOTAL: {total_check:,} (should match {N_samples:,})\")\n",
        "\n",
        "# ---------- Base group IDs (one per sample) ----------\n",
        "# For now each sample is its own \"group\"; when we augment, we will\n",
        "# duplicate these group IDs so augmentations never cross splits.\n",
        "BASE_GROUP_IDS = np.arange(N_samples, dtype=np.int64)\n",
        "\n",
        "print(\"\\nBase group IDs prepared (one group per original sample).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "RR7KxIDvx2gu",
        "outputId": "6e194be4-5464-44a6-ac19-4aaa307f76ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No pickle files found. Please upload the Project 3 input/output pickles now.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0f122f50-bceb-4fd9-a410-7334332083cc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0f122f50-bceb-4fd9-a410-7334332083cc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving DS-3-Train-n_k_m_P to DS-3-Train-n_k_m_P\n",
            "Saving DS-3-Train-mHeights to DS-3-Train-mHeights\n",
            "Using input file:  DS-3-Train-n_k_m_P\n",
            "Using output file: DS-3-Train-mHeights\n",
            "Total samples:     56,365\n",
            "\n",
            "Feature / target summary:\n",
            "  Features shape: (56365, 64)  (FEAT_DIM=64)\n",
            "  y (m-height) clamp>=1: min=2.0000  max=5570861.3750\n",
            "  z = log2(y):           min=1.0000  max=22.4095  mean=8.7467  std=3.2520\n",
            "\n",
            "Per-(k,m) counts in Project 3 train set:\n",
            "  (k=4, m=2):   5708\n",
            "  (k=4, m=3):   5593\n",
            "  (k=4, m=4):   5161\n",
            "  (k=4, m=5):   3352\n",
            "  (k=5, m=2):   6297\n",
            "  (k=5, m=3):   5859\n",
            "  (k=5, m=4):   3714\n",
            "  (k=6, m=2):  13365\n",
            "  (k=6, m=3):   7316\n",
            "  TOTAL: 56,365 (should match 56,365)\n",
            "\n",
            "Base group IDs prepared (one group per original sample).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 4 — Group-Aware 60/20/20 TVT Splits (per (k, m))\n",
        "\n",
        "In this phase, I create **deterministic Train/Validation/Test splits** for each \\((k, m)\\) bucket using **GroupShuffleSplit**, with explicit protection against data leakage under augmentation.\n",
        "\n",
        "### 4.1 Per-bucket splitting\n",
        "\n",
        "- For each valid pair \\((k, m)\\) in:\n",
        "  \\[\n",
        "    (4,2), (4,3), (4,4), (4,5),\n",
        "    (5,2), (5,3), (5,4),\n",
        "    (6,2), (6,3),\n",
        "  \\]\n",
        "  I collect all indices \\(\\{i : (K_i, M_i) = (k, m)\\}\\) into `PAIR_TO_IDX[(k,m)]`.\n",
        "- Splits are performed **independently per bucket**, so every \\((k, m)\\) has its own:\n",
        "  - Train set (`train`),\n",
        "  - Validation set (`val`),\n",
        "  - Test set (`test`),\n",
        "  stored under `pair_splits[(k, m)]`.\n",
        "\n",
        "This matches the professor’s emphasis on **per-(k, m) performance** in the grading rubric.\n",
        "\n",
        "### 4.2 Group-aware splitting for leakage safety\n",
        "\n",
        "- I use **GroupShuffleSplit** twice:\n",
        "  1. First split: **Train vs (Val+Test)** using `TRAIN_FRAC = 0.60`\n",
        "  2. Second split: **Val vs Test** inside the temporary set with  \n",
        "     \\[\n",
        "       \\text{val\\_frac\\_rel} = \\frac{\\text{VAL\\_FRAC}}{\\text{VAL\\_FRAC} + \\text{TEST\\_FRAC}} = 0.5\n",
        "     \\]\n",
        "- The `groups` array is derived from `BASE_GROUP_IDS`:\n",
        "  - Each original sample (before any augmentation) is its own group.\n",
        "  - This is the hook that will later ensure **all augmented copies** of a sample remain in the **same split**, so Train/Val/Test never share permutations of the same base example.\n",
        "\n",
        "Even though DS-3 itself is not yet augmented, this design is **augmentation-safe by construction** and prevents the kind of leakage that the project slides explicitly warn against.\n",
        "\n",
        "### 4.3 Deterministic and reproducible\n",
        "\n",
        "- I use fixed random seeds (`SEED` and `SEED + 1`) for:\n",
        "  - The first GroupShuffleSplit (Train vs Val+Test),\n",
        "  - The second GroupShuffleSplit (Val vs Test),\n",
        "- This makes the **60/20/20** splits:\n",
        "  - **Deterministic** — same splits every time,\n",
        "  - **Reproducible** across reruns and environments.\n"
      ],
      "metadata": {
        "id": "ByQCibq0zdWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 4 — Group-Aware 60/20/20 TVT Splits (per (k,m))\n",
        "\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "os.makedirs(\"splits\", exist_ok=True)\n",
        "SPLIT_PATH = os.path.join(\"splits\", \"DS3_pair_splits_grouped_60_20_20.pkl\")\n",
        "\n",
        "PAIR_TO_IDX = defaultdict(list)\n",
        "for i, (k, m) in enumerate(zip(KS, MS)):\n",
        "    PAIR_TO_IDX[(int(k), int(m))].append(i)\n",
        "\n",
        "pair_splits = {}\n",
        "rng_seed_1 = SEED\n",
        "rng_seed_2 = SEED + 1\n",
        "\n",
        "print(\"Building group-aware splits per (k,m) with GroupShuffleSplit ...\\n\")\n",
        "\n",
        "tot_tr = tot_va = tot_te = 0\n",
        "\n",
        "for (k, m) in sorted(PAIR_TO_IDX.keys()):\n",
        "    idxs = np.asarray(PAIR_TO_IDX[(k, m)], dtype=np.int64)\n",
        "    groups = BASE_GROUP_IDS[idxs]  # each original sample is its own group (for now)\n",
        "\n",
        "    # First: train vs (val+test)\n",
        "    gss1 = GroupShuffleSplit(\n",
        "        n_splits=1, train_size=TRAIN_FRAC, random_state=rng_seed_1\n",
        "    )\n",
        "    train_mask, tmp_mask = next(gss1.split(idxs, groups=groups))\n",
        "    tr_idx = idxs[train_mask]\n",
        "    tmp_idx = idxs[tmp_mask]\n",
        "    tmp_groups = groups[tmp_mask]\n",
        "\n",
        "    # Second: val vs test within tmp\n",
        "    val_frac_rel = VAL_FRAC / (VAL_FRAC + TEST_FRAC)\n",
        "    gss2 = GroupShuffleSplit(\n",
        "        n_splits=1, train_size=val_frac_rel, random_state=rng_seed_2\n",
        "    )\n",
        "    val_mask, test_mask = next(gss2.split(tmp_idx, groups=tmp_groups))\n",
        "    va_idx = tmp_idx[val_mask]\n",
        "    te_idx = tmp_idx[test_mask]\n",
        "\n",
        "    pair_splits[(k, m)] = {\n",
        "        \"train\": np.sort(tr_idx),\n",
        "        \"val\":   np.sort(va_idx),\n",
        "        \"test\":  np.sort(te_idx),\n",
        "    }\n",
        "\n",
        "    tot_tr += len(tr_idx)\n",
        "    tot_va += len(va_idx)\n",
        "    tot_te += len(te_idx)\n",
        "\n",
        "# Persist splits\n",
        "with open(SPLIT_PATH, \"wb\") as f:\n",
        "    pickle.dump(pair_splits, f)\n",
        "\n",
        "print(f\"Saved group-aware deterministic splits to: {SPLIT_PATH}\")\n",
        "print(\"(Counts per pair)\")\n",
        "\n",
        "for (k, m) in sorted(pair_splits.keys()):\n",
        "    tr = len(pair_splits[(k, m)][\"train\"])\n",
        "    va = len(pair_splits[(k, m)][\"val\"])\n",
        "    te = len(pair_splits[(k, m)][\"test\"])\n",
        "    print(f\"\\n(k={k}, m={m})  train={tr:6d}  val={va:6d}  test={te:6d}\")\n",
        "\n",
        "print(f\"\\nTotals: train={tot_tr:,}  val={tot_va:,}  test={tot_te:,}\")\n",
        "print(\"\\nLeakage protection: each original sample (group) lives in exactly one split\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhjJ-Gq9zML_",
        "outputId": "852dfb4c-b5d5-4167-c680-aecc223e28d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building group-aware splits per (k,m) with GroupShuffleSplit ...\n",
            "\n",
            "Saved group-aware deterministic splits to: splits/DS3_pair_splits_grouped_60_20_20.pkl\n",
            "(Counts per pair)\n",
            "\n",
            "(k=4, m=2)  train=  3424  val=  1142  test=  1142\n",
            "\n",
            "(k=4, m=3)  train=  3355  val=  1119  test=  1119\n",
            "\n",
            "(k=4, m=4)  train=  3096  val=  1032  test=  1033\n",
            "\n",
            "(k=4, m=5)  train=  2011  val=   670  test=   671\n",
            "\n",
            "(k=5, m=2)  train=  3778  val=  1259  test=  1260\n",
            "\n",
            "(k=5, m=3)  train=  3515  val=  1172  test=  1172\n",
            "\n",
            "(k=5, m=4)  train=  2228  val=   743  test=   743\n",
            "\n",
            "(k=6, m=2)  train=  8019  val=  2673  test=  2673\n",
            "\n",
            "(k=6, m=3)  train=  4389  val=  1463  test=  1464\n",
            "\n",
            "Totals: train=33,815  val=11,273  test=11,277\n",
            "\n",
            "Leakage protection: each original sample (group) lives in exactly one split\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 5 — Global Train Augmentation (Per-Bucket Oversampling)\n",
        "\n",
        "In this phase, I **expand the effective training set** using a **per-(k, m) oversampling policy**, while keeping **Validation and Test splits completely clean**. The goal is to (1) give the model more signal where m-height is hardest to predict, and (2) respect the professor’s constraints on data leakage and fair evaluation.\n",
        "\n",
        "### 5.1 Difficulty tiers and oversampling policy\n",
        "\n",
        "From earlier experiments (Projects 1 & 2 and the DS-3 MoE), I observed that some \\((k, m)\\) buckets are much harder than others. I explicitly encode this as:\n",
        "\n",
        "- **Easy:** \\((4,2), (4,3), (5,2), (6,2)\\)  \n",
        "- **Medium:** \\((4,4), (5,3)\\)  \n",
        "- **Hard:** \\((4,5), (5,4), (6,3)\\)\n",
        "\n",
        "Then I assign **per-sample oversampling factors**:\n",
        "\n",
        "- Easy buckets → `extra_per_sample = 1` (≈2× total samples)\n",
        "- Medium buckets → `extra_per_sample = 3` (≈4× total samples)\n",
        "- Hard buckets → `extra_per_sample = 10` (≈11× total samples, strong focus)\n",
        "\n",
        "This directly implements the “**more data where the model struggles**” idea from the project slides, but in a controlled, per-bucket way.\n",
        "\n",
        "### 5.2 Augmentation via symmetric permutations of \\(P\\)\n",
        "\n",
        "For each original TRAIN index in a given \\((k, m)\\) bucket:\n",
        "\n",
        "- I generate `n_aug = extra_per_sample[(k, m)]` **augmented copies** by:\n",
        "  - Randomly permuting the **rows** and **columns** of \\(P\\) via `permute_P`.\n",
        "  - Re-featurizing using the **permutation-invariant SVD-64 featurizer**.\n",
        "\n",
        "Because the feature map is explicitly invariant to row/column permutations:\n",
        "\n",
        "- These augmented examples are **label-preserving** (same m-height).\n",
        "- In feature space, they behave like **oversampling** of the original examples.\n",
        "- This keeps the model balanced across buckets **without changing the underlying distribution of m-heights**.\n",
        "\n",
        "### 5.3 Train vs Val/Test isolation\n",
        "\n",
        "- **Only the TRAIN indices** in each \\((k, m)\\) bucket are augmented.\n",
        "- Validation (`val`) and Test (`test`) splits come directly from the **clean DS-3** set:\n",
        "  - No permutations,\n",
        "  - No oversampling,\n",
        "  - No shared groups between splits (from Phase 4).\n",
        "\n",
        "This ensures:\n",
        "\n",
        "- **Model selection** (early stopping + calibration) is based on **unbiased VAL metrics**.\n",
        "- The **internal Test log₂-MSE** is a fair estimate of how the model will perform on the professor’s hidden test set.\n",
        "\n",
        "### 5.4 Resulting train sizes and cache structure\n",
        "\n",
        "For each \\((k, m)\\), I store:\n",
        "\n",
        "- `TRAIN_AUG_CACHE[(k, m)][\"X\"]`: augmented feature matrix \\([N_{\\text{tr,aug}}, 64]\\)\n",
        "- `TRAIN_AUG_CACHE[(k, m)][\"z\"]`: corresponding log₂ m-heights \\([N_{\\text{tr,aug}}]\\)\n",
        "- `CLEAN_SPLITS[(k, m)]`: the original `{train, val, test}` index sets (for later evaluation)\n",
        "\n",
        "These are serialized to:\n",
        "\n",
        "- `aug/DS3_train_aug_cache.pkl`  — per-bucket TRAIN(+aug) features/targets  \n",
        "- `splits/DS3_clean_splits.pkl`  — per-bucket clean TVT indices\n",
        "\n",
        "Finally, the summary printout reports:\n",
        "\n",
        "- Base vs augmented TRAIN sizes for each \\((k, m)\\),\n",
        "- The global TRAIN size and oversampling factor (≈100k effective examples),\n",
        "- An explicit reminder that **VAL/TEST remain clean** for grading-aligned evaluation.\n",
        "\n"
      ],
      "metadata": {
        "id": "iG4eHHjE0axd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 5 — Global Train Augmentation (Per-Bucket Oversampling)\n",
        "\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Reload splits to be safe\n",
        "with open(os.path.join(\"splits\", \"DS3_pair_splits_grouped_60_20_20.pkl\"), \"rb\") as f:\n",
        "    pair_splits = pickle.load(f)\n",
        "\n",
        "# Difficulty tiers (based on historical error behaviour)\n",
        "EASY_PAIRS   = {(4,2), (4,3), (5,2), (6,2)}\n",
        "MEDIUM_PAIRS = {(4,4), (5,3)}\n",
        "HARD_PAIRS   = {(4,5), (5,4), (6,3)}\n",
        "\n",
        "# Oversampling/augmentation multipliers:\n",
        "# per_sample = how many \"extra copies\" per TRAIN example (via symmetric permutations of P)\n",
        "# Note: with permutation-invariant features, this is equivalent to oversampling.\n",
        "PER_SAMPLE_TRAIN = {}\n",
        "for pair in EASY_PAIRS:\n",
        "    PER_SAMPLE_TRAIN[pair] = 1   # easy: 2x total\n",
        "for pair in MEDIUM_PAIRS:\n",
        "    PER_SAMPLE_TRAIN[pair] = 3   # medium: 4x total\n",
        "for pair in HARD_PAIRS:\n",
        "    PER_SAMPLE_TRAIN[pair] = 10   # hard: 11x total (heavy focus)\n",
        "\n",
        "# Safety cap (if we later want to tune more aggressively)\n",
        "PER_SAMPLE_CAP = 10\n",
        "for p in list(PER_SAMPLE_TRAIN.keys()):\n",
        "    PER_SAMPLE_TRAIN[p] = min(PER_SAMPLE_TRAIN[p], PER_SAMPLE_CAP)\n",
        "\n",
        "# Simple row+column permutation function (keeps m-height invariant)\n",
        "_rng_aug = np.random.default_rng(SEED + 11)\n",
        "\n",
        "def permute_P(P: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Return a symmetrically permuted version of P (rows+cols permuted).\"\"\"\n",
        "    P = np.asarray(P)\n",
        "    k, nk = P.shape\n",
        "    r_perm = _rng_aug.permutation(k)\n",
        "    c_perm = _rng_aug.permutation(nk)\n",
        "    return P[r_perm][:, c_perm]\n",
        "\n",
        "def build_augmented_train_cache(X_list, y_arr, KS, MS, pair_splits, per_sample_by_pair):\n",
        "    \"\"\"\n",
        "    Build per-(k,m) TRAIN(+aug) features and targets z=log2(y>=1).\n",
        "    Returns:\n",
        "      TRAIN_AUG[(k,m)] = {\"X\": [N_tr_aug, FEAT_DIM], \"z\": [N_tr_aug]}\n",
        "      CLEAN_SPLITS[(k,m)] = {\"train\": idx, \"val\": idx, \"test\": idx}\n",
        "    \"\"\"\n",
        "    train_aug_cache = {}\n",
        "    clean_splits = {}\n",
        "    total_added = 0\n",
        "\n",
        "    for (k, m), splits in sorted(pair_splits.items()):\n",
        "        tr_idx = np.asarray(splits[\"train\"], dtype=np.int64)\n",
        "        va_idx = np.asarray(splits[\"val\"],   dtype=np.int64)\n",
        "        te_idx = np.asarray(splits[\"test\"],  dtype=np.int64)\n",
        "\n",
        "        clean_splits[(k, m)] = {\n",
        "            \"train\": tr_idx,\n",
        "            \"val\":   va_idx,\n",
        "            \"test\":  te_idx,\n",
        "        }\n",
        "\n",
        "        if tr_idx.size == 0:\n",
        "            continue\n",
        "\n",
        "        # Base TRAIN features/targets\n",
        "        X_tr_base = ALL_FEATURES[tr_idx].astype(np.float32)\n",
        "        z_tr_base = z_arr[tr_idx].astype(np.float32)\n",
        "\n",
        "        feats_list = [X_tr_base]\n",
        "        z_list     = [z_tr_base]\n",
        "\n",
        "        n_aug = int(per_sample_by_pair.get((k, m), 0))\n",
        "        if n_aug > 0:\n",
        "            # We re-featurize permuted P for conceptual clarity, even though\n",
        "            # featurize_sample is permutation-invariant (so features repeat).\n",
        "            aug_feats = []\n",
        "            aug_z     = []\n",
        "\n",
        "            for idx in tr_idx:\n",
        "                n0, k0, m0, P0 = X_list[idx]\n",
        "                z0 = float(np.log2(max(1.0, y_arr[idx])))\n",
        "\n",
        "                for _ in range(n_aug):\n",
        "                    P_new = permute_P(P0)\n",
        "                    aug_feats.append(featurize_sample(n0, k0, m0, P_new))\n",
        "                    aug_z.append(z0)\n",
        "\n",
        "            if aug_feats:\n",
        "                aug_feats = np.asarray(aug_feats, dtype=np.float32)\n",
        "                aug_z     = np.asarray(aug_z,     dtype=np.float32)\n",
        "                feats_list.append(aug_feats)\n",
        "                z_list.append(aug_z)\n",
        "                total_added += len(aug_z)\n",
        "\n",
        "        X_tr_full = np.vstack(feats_list)\n",
        "        z_tr_full = np.concatenate(z_list)\n",
        "\n",
        "        train_aug_cache[(k, m)] = {\n",
        "            \"X\": X_tr_full,\n",
        "            \"z\": z_tr_full,\n",
        "        }\n",
        "\n",
        "    print(f\"Augmentation/oversampling complete. Added {total_added:,} augmented train samples overall.\")\n",
        "    return train_aug_cache, clean_splits\n",
        "\n",
        "# ---- Build caches ----\n",
        "TRAIN_AUG_CACHE, CLEAN_SPLITS = build_augmented_train_cache(\n",
        "    X_list=X_list,\n",
        "    y_arr=y_arr,\n",
        "    KS=KS,\n",
        "    MS=MS,\n",
        "    pair_splits=pair_splits,\n",
        "    per_sample_by_pair=PER_SAMPLE_TRAIN,\n",
        ")\n",
        "\n",
        "# Persist caches for later phases\n",
        "os.makedirs(\"aug\", exist_ok=True)\n",
        "with open(os.path.join(\"aug\", \"DS3_train_aug_cache.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(TRAIN_AUG_CACHE, f)\n",
        "with open(os.path.join(\"splits\", \"DS3_clean_splits.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(CLEAN_SPLITS, f)\n",
        "\n",
        "# Summary printout\n",
        "print(\"\\nPer-(k,m) TRAIN sizes (base → with aug/oversampling):\")\n",
        "total_base = total_aug = 0\n",
        "for (k, m) in sorted(CLEAN_SPLITS.keys()):\n",
        "    base = len(CLEAN_SPLITS[(k, m)][\"train\"])\n",
        "    aug  = TRAIN_AUG_CACHE[(k, m)][\"X\"].shape[0]\n",
        "    total_base += base\n",
        "    total_aug  += aug\n",
        "    print(f\"  (k={k}, m={m})  {base:6d} → {aug:7d}  (+{aug-base:6d})\")\n",
        "\n",
        "print(f\"\\nGlobal TRAIN size: {total_base:,} → {total_aug:,} (×{total_aug/total_base:.1f})\")\n",
        "print(\"VAL/TEST remain clean (no augmentation) for unbiased model selection and internal evaluation.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RQYWNJH0Aci",
        "outputId": "cedb5a01-5c3d-48be-e77d-5f292069b6c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmentation/oversampling complete. Added 124,689 augmented train samples overall.\n",
            "\n",
            "Per-(k,m) TRAIN sizes (base → with aug/oversampling):\n",
            "  (k=4, m=2)    3424 →    6848  (+  3424)\n",
            "  (k=4, m=3)    3355 →    6710  (+  3355)\n",
            "  (k=4, m=4)    3096 →   12384  (+  9288)\n",
            "  (k=4, m=5)    2011 →   22121  (+ 20110)\n",
            "  (k=5, m=2)    3778 →    7556  (+  3778)\n",
            "  (k=5, m=3)    3515 →   14060  (+ 10545)\n",
            "  (k=5, m=4)    2228 →   24508  (+ 22280)\n",
            "  (k=6, m=2)    8019 →   16038  (+  8019)\n",
            "  (k=6, m=3)    4389 →   48279  (+ 43890)\n",
            "\n",
            "Global TRAIN size: 33,815 → 158,504 (×4.7)\n",
            "VAL/TEST remain clean (no augmentation) for unbiased model selection and internal evaluation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 6 — Per-(k,m) Expert Training with Global-Aug + Ensembles\n",
        "\n",
        "In this phase, I train the **main Mixture-of-Experts (MoE)** model that achieves an internal **TEST log₂-MSE ≈ 0.84** on the DS-3 splits. Each \\((k,m)\\) bucket gets its own **specialized dense network**, trained on the **globally augmented** train set from Phase 5 and evaluated on **clean VAL data**.\n",
        "\n",
        "### 6.1 Expert architecture by difficulty\n",
        "\n",
        "For each valid pair \\((k,m)\\), I instantiate a separate **expert MLP** on top of the 64-D SVD features:\n",
        "\n",
        "- **Easy / Medium pairs** \\((4,2),(4,3),(5,2),(6,2),(4,4),(5,3)\\)  \n",
        "  - 3 dense blocks: 320 → 160 → 80 with **GELU** activations  \n",
        "  - Each block: `Dense → LayerNorm → Dropout`\n",
        "- **Hard pairs** \\((4,5),(5,4),(6,3)\\)  \n",
        "  - 4 dense blocks: 512 → 256 → 128 → 64 (wider + deeper)  \n",
        "  - Same `Dense → LayerNorm → Dropout` pattern\n",
        "\n",
        "Common heads & optimization:\n",
        "\n",
        "- Final layer: `Dense(1)` predicting **log₂(m-height)** (`z_hat`).\n",
        "- Optimizer: **AdamW** with weight decay and **gradient clipping** (`clipnorm=1.0`) for stability under heavy augmentation.\n",
        "- Loss:\n",
        "  - **MSE** for easy/medium buckets.\n",
        "  - **Huber loss** (δ=0.75) for hard buckets to robustify against rare extreme m-heights.\n",
        "\n",
        "This matches the Project 3 guidance: **simple but strong dense DNNs**, with **hard buckets getting extra capacity and robustness**.\n",
        "\n",
        "### 6.2 Training protocol (per-bucket ensembles)\n",
        "\n",
        "For each \\((k,m)\\):\n",
        "\n",
        "1. **Inputs**  \n",
        "   - `X_tr`: globally augmented TRAIN features from `TRAIN_AUG_CACHE[(k,m)]`.\n",
        "   - `z_tr`: corresponding log₂ m-heights.  \n",
        "   - `X_val`, `z_val`: **clean VAL** features/targets from `ALL_FEATURES` / `z_arr` using `CLEAN_SPLITS[(k,m)]`.\n",
        "\n",
        "2. **Scaling**  \n",
        "   - Fit a **StandardScaler** on `X_tr` only.  \n",
        "   - Apply it to both `X_tr` and `X_val` → `X_tr_s`, `X_val_s`.  \n",
        "   - This keeps VAL statistics “unseen” during scaling.\n",
        "\n",
        "3. **Ensemble training**  \n",
        "   - Hard buckets: seeds = `[41, 1337, 9001, 2027, 7]` → **5-model ensemble**.  \n",
        "   - Easy/medium buckets: seeds = `[41, 1337, 9001]` → **3-model ensemble**.  \n",
        "   - For each seed:\n",
        "     - Reset RNGs for reproducibility.\n",
        "     - Train with **EarlyStopping** on `val_loss` (patience = 25) and **ReduceLROnPlateau** (patience = 10, min LR = 1e-6).\n",
        "     - Max 300 epochs, batch size 256.\n",
        "\n",
        "The **ensemble mean** prediction on VAL reduces variance and gives more stable log₂-MSE, which is critical when the professor grades purely on this metric.\n",
        "\n",
        "### 6.3 VAL-time linear calibration\n",
        "\n",
        "After training the ensemble for a given \\((k,m)\\):\n",
        "\n",
        "1. Compute **uncalibrated VAL predictions**:\n",
        "   \\[\n",
        "   \\hat{z}_{\\text{val}} = \\frac{1}{M} \\sum_{i=1}^M \\hat{z}^{(i)}_{\\text{val}}\n",
        "   \\]\n",
        "   where \\(M\\) is the ensemble size.\n",
        "\n",
        "2. Fit a **1D LinearRegression**:\n",
        "   - Input: \\(\\hat{z}_{\\text{val}}\\)\n",
        "   - Target: \\(z_{\\text{val}}\\)\n",
        "   - Learn scalar **slope \\(a\\)** and **intercept \\(b\\)**.\n",
        "\n",
        "3. Apply calibration:\n",
        "   \\[\n",
        "   \\hat{z}_{\\text{val,cal}} = a \\cdot \\hat{z}_{\\text{val}} + b\n",
        "   \\]\n",
        "\n",
        "4. Report **VAL log₂-MSE**:\n",
        "   - **Uncalibrated**: `mse(z_val, z_val_hat)`  \n",
        "   - **Calibrated**: `mse(z_val, z_val_hat_cal)`\n",
        "\n",
        "This gives a **small but consistent improvement** per bucket, and aligns with the grading metric (log₂-MSE) without touching the m-height labels themselves.\n",
        "\n",
        "### 6.4 Saved artifacts (for later test + submission)\n",
        "\n",
        "For each \\((k,m)\\), the code creates a directory:\n",
        "\n",
        "- `Proj3_SVD64_GlobalAug/k{k}_m{m}/`\n",
        "\n",
        "and stores:\n",
        "\n",
        "- `model_*.keras` — all ensemble members for this bucket.\n",
        "- `scaler_X.pkl` — StandardScaler fitted on TRAIN(+aug) features.\n",
        "- `calibration.pkl` — dict with `{ \"a\": slope, \"b\": intercept }`.\n",
        "- Split indices are saved globally in `CLEAN_SPLITS`, and referenced via `ARTIFACTS`.\n",
        "\n",
        "The global `ARTIFACTS` index is serialized to:\n",
        "\n",
        "- `Proj3_SVD64_GlobalAug/artifacts_index.pkl`\n",
        "\n",
        "This structure is what the later **Phase 7 (Test evaluation)** and **Final Submission Cell** use to:\n",
        "\n",
        "- Reconstruct each bucket’s ensemble,\n",
        "- Apply the correct scaler and calibration,\n",
        "- And compute predictions on the professor’s sample test set.\n",
        "\n",
        "Overall, Phase 6 is where the **main graded model** is actually learned: a **bucket-wise ensemble of dense experts**, trained on **heavily augmented DS-3**, and calibrated on a **clean validation set** to match the log₂-MSE evaluation standard used for grading.\n"
      ],
      "metadata": {
        "id": "fG9xGK1k1uOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 6 — Train Per-(k,m) Experts (Global-Aug + Ensembles)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "SAVE_ROOT = \"Proj3_SVD64_GlobalAug\"\n",
        "os.makedirs(SAVE_ROOT, exist_ok=True)\n",
        "\n",
        "# Difficulty tiers (reuse from Phase 5)\n",
        "EASY_PAIRS   = {(4,2), (4,3), (5,2), (6,2)}\n",
        "MEDIUM_PAIRS = {(4,4), (5,3)}\n",
        "HARD_PAIRS   = {(4,5), (5,4), (6,3)}\n",
        "ALL_PAIRS    = sorted(list(EASY_PAIRS | MEDIUM_PAIRS | HARD_PAIRS))\n",
        "\n",
        "# Reload caches/splits from disk (in case of runtime reset)\n",
        "with open(os.path.join(\"aug\", \"DS3_train_aug_cache.pkl\"), \"rb\") as f:\n",
        "    TRAIN_AUG_CACHE = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(\"splits\", \"DS3_clean_splits.pkl\"), \"rb\") as f:\n",
        "    CLEAN_SPLITS = pickle.load(f)\n",
        "\n",
        "def make_expert_model(input_dim: int, seed: int, hard: bool) -> keras.Model:\n",
        "    \"\"\"\n",
        "    Per-(k,m) dense expert:\n",
        "      - Easy/medium: 3-layer MLP\n",
        "      - Hard: 4-layer wider MLP with Huber loss\n",
        "    \"\"\"\n",
        "    tf.keras.utils.set_random_seed(seed)\n",
        "\n",
        "    x_in = keras.Input(shape=(input_dim,), name=\"x\")\n",
        "\n",
        "    if hard:\n",
        "        x = layers.Dense(512, activation=\"gelu\", kernel_initializer=\"he_normal\")(x_in)\n",
        "        x = layers.LayerNormalization()(x); x = layers.Dropout(0.25)(x)\n",
        "        x = layers.Dense(256, activation=\"gelu\", kernel_initializer=\"he_normal\")(x)\n",
        "        x = layers.LayerNormalization()(x); x = layers.Dropout(0.25)(x)\n",
        "        x = layers.Dense(128, activation=\"gelu\", kernel_initializer=\"he_normal\")(x)\n",
        "        x = layers.LayerNormalization()(x); x = layers.Dropout(0.20)(x)\n",
        "        x = layers.Dense(64,  activation=\"gelu\", kernel_initializer=\"he_normal\")(x)\n",
        "        x = layers.LayerNormalization()(x); x = layers.Dropout(0.15)(x)\n",
        "    else:\n",
        "        x = layers.Dense(320, activation=\"gelu\", kernel_initializer=\"he_normal\")(x_in)\n",
        "        x = layers.LayerNormalization()(x); x = layers.Dropout(0.20)(x)\n",
        "        x = layers.Dense(160, activation=\"gelu\", kernel_initializer=\"he_normal\")(x)\n",
        "        x = layers.LayerNormalization()(x); x = layers.Dropout(0.20)(x)\n",
        "        x = layers.Dense(80,  activation=\"gelu\", kernel_initializer=\"he_normal\")(x)\n",
        "        x = layers.LayerNormalization()(x); x = layers.Dropout(0.15)(x)\n",
        "\n",
        "    out = layers.Dense(1, name=\"z_hat\")(x)\n",
        "\n",
        "    model = keras.Model(x_in, out, name=f\"Expert_{'hard' if hard else 'base'}\")\n",
        "\n",
        "    opt = keras.optimizers.AdamW(\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "        clipnorm=GRAD_CLIP_NORM,\n",
        "    )\n",
        "\n",
        "    if hard and USE_HUBER_FOR_HARD:\n",
        "        loss_fn = keras.losses.Huber(delta=HUBER_DELTA)\n",
        "    else:\n",
        "        loss_fn = \"mse\"\n",
        "\n",
        "    model.compile(optimizer=opt, loss=loss_fn, metrics=[\"mae\"])\n",
        "    return model\n",
        "\n",
        "def mse_np(a, b):\n",
        "    a = np.asarray(a).ravel()\n",
        "    b = np.asarray(b).ravel()\n",
        "    return float(np.mean((a - b) ** 2))\n",
        "\n",
        "# ---- Training loop over all (k,m) ----\n",
        "\n",
        "ARTIFACTS = {}\n",
        "input_dim = ALL_FEATURES.shape[1]\n",
        "\n",
        "print(f\"Training per-(k,m) experts into: {SAVE_ROOT}\\n\")\n",
        "\n",
        "for (k, m) in ALL_PAIRS:\n",
        "    splits = CLEAN_SPLITS[(k, m)]\n",
        "    tr_idx = np.asarray(splits[\"train\"], dtype=np.int64)\n",
        "    va_idx = np.asarray(splits[\"val\"],   dtype=np.int64)\n",
        "\n",
        "    # TRAIN (+global aug/oversampling)\n",
        "    X_tr = TRAIN_AUG_CACHE[(k, m)][\"X\"].astype(np.float32)\n",
        "    z_tr = TRAIN_AUG_CACHE[(k, m)][\"z\"].astype(np.float32)\n",
        "\n",
        "    # VAL (clean)\n",
        "    X_val = ALL_FEATURES[va_idx].astype(np.float32)\n",
        "    z_val = z_arr[va_idx].astype(np.float32)\n",
        "\n",
        "    # Standardize on TRAIN only\n",
        "    sx = StandardScaler().fit(X_tr)\n",
        "    X_tr_s  = sx.transform(X_tr)\n",
        "    X_val_s = sx.transform(X_val)\n",
        "\n",
        "    hard  = (k, m) in HARD_PAIRS\n",
        "    seeds = ENSEMBLE_SEEDS_HARD if hard else ENSEMBLE_SEEDS_EASYMED\n",
        "\n",
        "    print(f\"\\n=== (k={k}, m={m}) | {'HARD' if hard else 'BASE'} pair ===\")\n",
        "    print(f\"  Train(+aug): {X_tr_s.shape[0]:6d}  |  Val: {X_val_s.shape[0]:6d}\")\n",
        "    print(f\"  Ensemble size: {len(seeds)}\")\n",
        "\n",
        "    models = []\n",
        "    for i, s in enumerate(seeds, start=1):\n",
        "        print(f\"    -> Model {i}/{len(seeds)} (seed={s})\")\n",
        "        model = make_expert_model(input_dim=input_dim, seed=s, hard=hard)\n",
        "\n",
        "        cbs = [\n",
        "            keras.callbacks.EarlyStopping(\n",
        "                monitor=\"val_loss\",\n",
        "                patience=PATIENCE,\n",
        "                restore_best_weights=True,\n",
        "                verbose=1,\n",
        "            ),\n",
        "            keras.callbacks.ReduceLROnPlateau(\n",
        "                monitor=\"val_loss\",\n",
        "                factor=0.5,\n",
        "                patience=LR_PATIENCE,\n",
        "                min_lr=1e-6,\n",
        "                verbose=1,\n",
        "            ),\n",
        "        ]\n",
        "\n",
        "        model.fit(\n",
        "            X_tr_s, z_tr,\n",
        "            validation_data=(X_val_s, z_val),\n",
        "            epochs=MAX_EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            verbose=0,\n",
        "            callbacks=cbs,\n",
        "        )\n",
        "        models.append(model)\n",
        "\n",
        "    # ---- VAL ensemble + linear calibration ----\n",
        "    z_val_hat = np.mean(\n",
        "        [m_.predict(X_val_s, verbose=0).ravel() for m_ in models],\n",
        "        axis=0,\n",
        "    )\n",
        "    cal = LinearRegression().fit(z_val_hat.reshape(-1, 1), z_val)\n",
        "    a, b = float(cal.coef_[0]), float(cal.intercept_)\n",
        "    z_val_hat_cal = a * z_val_hat + b\n",
        "\n",
        "    uncal_mse = mse_np(z_val, z_val_hat)\n",
        "    cal_mse   = mse_np(z_val, z_val_hat_cal)\n",
        "\n",
        "    print(f\"  VAL log2-MSE  uncal={uncal_mse:.5f}  |  cal={cal_mse:.5f}\")\n",
        "\n",
        "    # ---- Save artifacts for this pair ----\n",
        "    pair_dir = os.path.join(SAVE_ROOT, f\"k{k}_m{m}\")\n",
        "    os.makedirs(pair_dir, exist_ok=True)\n",
        "\n",
        "    # Clean any old contents\n",
        "    for fn in os.listdir(pair_dir):\n",
        "        try:\n",
        "            os.remove(os.path.join(pair_dir, fn))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    model_paths = []\n",
        "    for i, model in enumerate(models, start=1):\n",
        "        mp = os.path.join(pair_dir, f\"model_{i}.keras\")\n",
        "        model.save(mp)\n",
        "        model_paths.append(mp)\n",
        "\n",
        "    # Save scaler + calibration\n",
        "    with open(os.path.join(pair_dir, \"scaler_X.pkl\"), \"wb\") as f:\n",
        "        pickle.dump(sx, f)\n",
        "\n",
        "    with open(os.path.join(pair_dir, \"calibration.pkl\"), \"wb\") as f:\n",
        "        pickle.dump({\"a\": a, \"b\": b}, f)\n",
        "\n",
        "    # Record in ARTIFACTS index\n",
        "    ARTIFACTS[(k, m)] = {\n",
        "        \"model_paths\": model_paths,\n",
        "        \"scaler_X\":   os.path.join(pair_dir, \"scaler_X.pkl\"),\n",
        "        \"calib\":      os.path.join(pair_dir, \"calibration.pkl\"),\n",
        "        \"splits\":     splits,\n",
        "        \"hard\":       hard,\n",
        "    }\n",
        "\n",
        "# Save global artifact index\n",
        "with open(os.path.join(SAVE_ROOT, \"artifacts_index.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(ARTIFACTS, f)\n",
        "\n",
        "print(\"\\n=== Training complete ===\")\n",
        "print(\"Artifacts saved under:\", SAVE_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur0liPWj0qQ6",
        "outputId": "63c19599-919f-4c5f-dc24-d172d2fddd89"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training per-(k,m) experts into: Proj3_SVD64_GlobalAug\n",
            "\n",
            "\n",
            "=== (k=4, m=2) | BASE pair ===\n",
            "  Train(+aug):   6848  |  Val:   1142\n",
            "  Ensemble size: 3\n",
            "    -> Model 1/3 (seed=41)\n",
            "\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 102: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 107: early stopping\n",
            "Restoring model weights from the end of the best epoch: 82.\n",
            "    -> Model 2/3 (seed=1337)\n",
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 98: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 108: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "Epoch 113: early stopping\n",
            "Restoring model weights from the end of the best epoch: 88.\n",
            "    -> Model 3/3 (seed=9001)\n",
            "\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 107: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 117: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 122: early stopping\n",
            "Restoring model weights from the end of the best epoch: 97.\n",
            "  VAL log2-MSE  uncal=0.11451  |  cal=0.11359\n",
            "\n",
            "=== (k=4, m=3) | BASE pair ===\n",
            "  Train(+aug):   6710  |  Val:   1119\n",
            "  Ensemble size: 3\n",
            "    -> Model 1/3 (seed=41)\n",
            "\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 102: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 107: early stopping\n",
            "Restoring model weights from the end of the best epoch: 82.\n",
            "    -> Model 2/3 (seed=1337)\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 82: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 103: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 113: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "Epoch 118: early stopping\n",
            "Restoring model weights from the end of the best epoch: 93.\n",
            "    -> Model 3/3 (seed=9001)\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 96: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 101: early stopping\n",
            "Restoring model weights from the end of the best epoch: 76.\n",
            "  VAL log2-MSE  uncal=0.22494  |  cal=0.22162\n",
            "\n",
            "=== (k=4, m=4) | BASE pair ===\n",
            "  Train(+aug):  12384  |  Val:   1032\n",
            "  Ensemble size: 3\n",
            "    -> Model 1/3 (seed=41)\n",
            "\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 107: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 132: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 143: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 171: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "Epoch 176: early stopping\n",
            "Restoring model weights from the end of the best epoch: 151.\n",
            "    -> Model 2/3 (seed=1337)\n",
            "\n",
            "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 130: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 140: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 145: early stopping\n",
            "Restoring model weights from the end of the best epoch: 120.\n",
            "    -> Model 3/3 (seed=9001)\n",
            "\n",
            "Epoch 114: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 134: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 144: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 149: early stopping\n",
            "Restoring model weights from the end of the best epoch: 124.\n",
            "  VAL log2-MSE  uncal=0.56763  |  cal=0.56734\n",
            "\n",
            "=== (k=4, m=5) | HARD pair ===\n",
            "  Train(+aug):  22121  |  Val:    670\n",
            "  Ensemble size: 5\n",
            "    -> Model 1/5 (seed=41)\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 31: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "    -> Model 2/5 (seed=1337)\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "    -> Model 3/5 (seed=9001)\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 34: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "    -> Model 4/5 (seed=2027)\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "    -> Model 5/5 (seed=7)\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "  VAL log2-MSE  uncal=2.55004  |  cal=2.53440\n",
            "\n",
            "=== (k=5, m=2) | BASE pair ===\n",
            "  Train(+aug):   7556  |  Val:   1259\n",
            "  Ensemble size: 3\n",
            "    -> Model 1/3 (seed=41)\n",
            "\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 62: early stopping\n",
            "Restoring model weights from the end of the best epoch: 37.\n",
            "    -> Model 2/3 (seed=1337)\n",
            "\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 122: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 144: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 154: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 159: early stopping\n",
            "Restoring model weights from the end of the best epoch: 134.\n",
            "    -> Model 3/3 (seed=9001)\n",
            "\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 81: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 86: early stopping\n",
            "Restoring model weights from the end of the best epoch: 61.\n",
            "  VAL log2-MSE  uncal=0.17244  |  cal=0.17096\n",
            "\n",
            "=== (k=5, m=3) | BASE pair ===\n",
            "  Train(+aug):  14060  |  Val:   1172\n",
            "  Ensemble size: 3\n",
            "    -> Model 1/3 (seed=41)\n",
            "\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 90: early stopping\n",
            "Restoring model weights from the end of the best epoch: 65.\n",
            "    -> Model 2/3 (seed=1337)\n",
            "\n",
            "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 94: early stopping\n",
            "Restoring model weights from the end of the best epoch: 69.\n",
            "    -> Model 3/3 (seed=9001)\n",
            "\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 71: early stopping\n",
            "Restoring model weights from the end of the best epoch: 46.\n",
            "  VAL log2-MSE  uncal=0.65964  |  cal=0.65182\n",
            "\n",
            "=== (k=5, m=4) | HARD pair ===\n",
            "  Train(+aug):  24508  |  Val:    743\n",
            "  Ensemble size: 5\n",
            "    -> Model 1/5 (seed=41)\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 27: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "    -> Model 2/5 (seed=1337)\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 33: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "    -> Model 3/5 (seed=9001)\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "    -> Model 4/5 (seed=2027)\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 33: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "    -> Model 5/5 (seed=7)\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "  VAL log2-MSE  uncal=2.43807  |  cal=2.43190\n",
            "\n",
            "=== (k=6, m=2) | BASE pair ===\n",
            "  Train(+aug):  16038  |  Val:   2673\n",
            "  Ensemble size: 3\n",
            "    -> Model 1/3 (seed=41)\n",
            "\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 95: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 100: early stopping\n",
            "Restoring model weights from the end of the best epoch: 75.\n",
            "    -> Model 2/3 (seed=1337)\n",
            "\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 77: early stopping\n",
            "Restoring model weights from the end of the best epoch: 52.\n",
            "    -> Model 3/3 (seed=9001)\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 116: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 121: early stopping\n",
            "Restoring model weights from the end of the best epoch: 96.\n",
            "  VAL log2-MSE  uncal=0.43271  |  cal=0.43158\n",
            "\n",
            "=== (k=6, m=3) | HARD pair ===\n",
            "  Train(+aug):  48279  |  Val:   1463\n",
            "  Ensemble size: 5\n",
            "    -> Model 1/5 (seed=41)\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "    -> Model 2/5 (seed=1337)\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 31: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "    -> Model 3/5 (seed=9001)\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 30: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "    -> Model 4/5 (seed=2027)\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 34: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "    -> Model 5/5 (seed=7)\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "  VAL log2-MSE  uncal=1.97524  |  cal=1.97319\n",
            "\n",
            "=== Training complete ===\n",
            "Artifacts saved under: Proj3_SVD64_GlobalAug\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 7 — Held-Out TEST Evaluation for the MoE Model\n",
        "\n",
        "In this phase, I **freeze the trained per-(k,m) experts** from `Proj3_SVD64_GlobalAug` and evaluate them on the **clean held-out TEST split** defined in Phase 4. This gives an **unbiased estimate** of how the final submission model is expected to perform on the professor’s hidden test set.\n",
        "\n",
        "### What this phase does\n",
        "\n",
        "For each \\((k,m)\\) bucket:\n",
        "\n",
        "1. **Load artifacts**\n",
        "   - `artifacts_index.pkl` from `Proj3_SVD64_GlobalAug/`\n",
        "   - Per-bucket:\n",
        "     - `model_*.keras` ensemble members  \n",
        "     - `scaler_X.pkl` (feature StandardScaler)  \n",
        "     - `calibration.pkl` with slope `a` and intercept `b` for log₂ calibration  \n",
        "   - Clean TVT splits from `DS3_clean_splits.pkl`.\n",
        "\n",
        "2. **Select TEST subset**\n",
        "   - Use the stored indices `splits[\"test\"]` = `test_idx` for this \\((k,m)\\).\n",
        "   - Extract:\n",
        "     - `X_te` = SVD-64 features for these samples from `ALL_FEATURES`.\n",
        "     - `z_te` = log₂(m-height) targets from `z_arr`.\n",
        "\n",
        "3. **Apply scaler + ensemble**\n",
        "   - Standardize: `X_te_s = scaler_X.transform(X_te)`.\n",
        "   - Load each saved expert model `model_i.keras` and predict:\n",
        "     \\[\n",
        "       \\hat{z}^{(i)}_{\\text{test}} = f_i(X_{\\text{te,s}})\n",
        "     \\]\n",
        "   - Average across ensemble:\n",
        "     \\[\n",
        "       \\hat{z}_{\\text{test}} = \\frac{1}{M} \\sum_{i=1}^M \\hat{z}^{(i)}_{\\text{test}}\n",
        "     \\]\n",
        "\n",
        "4. **Apply VAL-time linear calibration**\n",
        "   - For this bucket, Phase 6 learned a linear map\n",
        "     \\[\n",
        "       \\hat{z}_{\\text{cal}} = a \\cdot \\hat{z}_{\\text{test}} + b\n",
        "     \\]\n",
        "     using only **VAL** data.\n",
        "   - Here we apply the same \\((a,b)\\) to TEST predictions and compute:\n",
        "     - **Uncalibrated** TEST log₂-MSE: `mse(z_te, z_hat)`\n",
        "     - **Calibrated** TEST log₂-MSE: `mse(z_te, z_hat_cal)`\n",
        "\n",
        "5. **Record per-bucket performance**\n",
        "   - For each \\((k,m)\\), store:\n",
        "     - `n_test` (number of test samples),\n",
        "     - uncalibrated log₂-MSE,\n",
        "     - calibrated log₂-MSE.\n",
        "\n"
      ],
      "metadata": {
        "id": "V0sX-iIy2hJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 7 — TEST Evaluation (Proj3_SVD64_GlobalAug)\n",
        "\n",
        "SAVE_ROOT = \"Proj3_SVD64_GlobalAug\"\n",
        "\n",
        "def mse_np(a, b):\n",
        "    a = np.asarray(a).ravel()\n",
        "    b = np.asarray(b).ravel()\n",
        "    return float(np.mean((a - b) ** 2))\n",
        "\n",
        "# Load artifacts index and clean splits\n",
        "with open(os.path.join(SAVE_ROOT, \"artifacts_index.pkl\"), \"rb\") as f:\n",
        "    ARTIFACTS = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(\"splits\", \"DS3_clean_splits.pkl\"), \"rb\") as f:\n",
        "    CLEAN_SPLITS = pickle.load(f)\n",
        "\n",
        "per_pair = []\n",
        "num_uncal = 0.0\n",
        "num_cal   = 0.0\n",
        "den       = 0\n",
        "\n",
        "for (k, m) in sorted(ARTIFACTS.keys()):\n",
        "    art = ARTIFACTS[(k, m)]\n",
        "    splits = CLEAN_SPLITS[(k, m)]\n",
        "\n",
        "    test_idx = np.asarray(splits[\"test\"], dtype=np.int64)\n",
        "    if test_idx.size == 0:\n",
        "        print(f\"(k={k}, m={m}) — no test samples, skipping.\")\n",
        "        continue\n",
        "\n",
        "    X_te = ALL_FEATURES[test_idx].astype(np.float32)\n",
        "    z_te = z_arr[test_idx].astype(np.float32)\n",
        "\n",
        "    # Load scaler + calibration\n",
        "    with open(art[\"scaler_X\"], \"rb\") as f:\n",
        "        sx = pickle.load(f)\n",
        "    with open(art[\"calib\"], \"rb\") as f:\n",
        "        calib = pickle.load(f)\n",
        "    a, b = float(calib[\"a\"]), float(calib[\"b\"])\n",
        "\n",
        "    X_te_s = sx.transform(X_te)\n",
        "\n",
        "    # Ensemble predictions\n",
        "    preds = []\n",
        "    i = 1\n",
        "    while True:\n",
        "        mp = os.path.join(SAVE_ROOT, f\"k{k}_m{m}\", f\"model_{i}.keras\")\n",
        "        if not os.path.exists(mp):\n",
        "            break\n",
        "        model = keras.models.load_model(mp)\n",
        "        preds.append(model.predict(X_te_s, verbose=0).ravel())\n",
        "        i += 1\n",
        "\n",
        "    if not preds:\n",
        "        print(f\"(k={k}, m={m}) — no models found, skipping.\")\n",
        "        continue\n",
        "\n",
        "    z_hat = np.mean(preds, axis=0)\n",
        "    z_hat_cal = a * z_hat + b\n",
        "\n",
        "    uncal = mse_np(z_te, z_hat)\n",
        "    cal   = mse_np(z_te, z_hat_cal)\n",
        "    n_te  = len(z_te)\n",
        "\n",
        "    per_pair.append(((k, m), n_te, uncal, cal))\n",
        "    num_uncal += uncal * n_te\n",
        "    num_cal   += cal   * n_te\n",
        "    den       += n_te\n",
        "\n",
        "print(\"Per-pair TEST log2-MSE (weighted by #test samples):\")\n",
        "for (k, m), n_te, uncal, cal in sorted(per_pair):\n",
        "    print(f\"  (k={k}, m={m})  n_test={n_te:5d}  uncal={uncal:.5f}  |  cal={cal:.5f}\")\n",
        "\n",
        "if den > 0:\n",
        "    print(\"\\n=== OVERALL TEST log2-MSE ===\")\n",
        "    print(f\"uncal={num_uncal / den:.5f}  |  cal={num_cal / den:.5f}  |  total_test={den}\")\n",
        "else:\n",
        "    print(\"No test data aggregated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVw8PeMa1-xz",
        "outputId": "faec3f1a-e5ed-46f6-8a58-02c5c04a2926"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per-pair TEST log2-MSE (weighted by #test samples):\n",
            "  (k=4, m=2)  n_test= 1142  uncal=0.09715  |  cal=0.09577\n",
            "  (k=4, m=3)  n_test= 1119  uncal=0.19256  |  cal=0.19016\n",
            "  (k=4, m=4)  n_test= 1033  uncal=0.55000  |  cal=0.55111\n",
            "  (k=4, m=5)  n_test=  671  uncal=2.42459  |  cal=2.42753\n",
            "  (k=5, m=2)  n_test= 1260  uncal=0.17743  |  cal=0.17562\n",
            "  (k=5, m=3)  n_test= 1172  uncal=0.58965  |  cal=0.58657\n",
            "  (k=5, m=4)  n_test=  743  uncal=2.56951  |  cal=2.56925\n",
            "  (k=6, m=2)  n_test= 2673  uncal=0.43630  |  cal=0.43646\n",
            "  (k=6, m=3)  n_test= 1464  uncal=2.02269  |  cal=2.01539\n",
            "\n",
            "=== OVERALL TEST log2-MSE ===\n",
            "uncal=0.84000  |  cal=0.83845  |  total_test=11277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ---- Extract dynamically from per_pair ----\n",
        "pairs   = [pair for (pair, n, uncal, cal) in per_pair]\n",
        "n_tests = [n     for (pair, n, uncal, cal) in per_pair]\n",
        "uncal   = [uncal for (pair, n, uncal, cal) in per_pair]\n",
        "cal     = [cal   for (pair, n, uncal, cal) in per_pair]\n",
        "\n",
        "labels = [f\"({k},{m})\" for (k, m) in pairs]\n",
        "\n",
        "# ---- Plot ----\n",
        "x = np.arange(len(pairs))\n",
        "w = 0.35\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(x - w/2, uncal, width=w, label=\"Uncalibrated\", alpha=0.75)\n",
        "plt.bar(x + w/2, cal,   width=w, label=\"Calibrated\", alpha=0.75)\n",
        "\n",
        "plt.xticks(x, labels, fontsize=10)\n",
        "plt.ylabel(\"TEST log$_2$-MSE\")\n",
        "plt.title(\"Per-(k,m) TEST log$_2$-MSE — Uncalibrated vs Calibrated\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "nH6hUn4rGphm",
        "outputId": "9e495790-cbd3-4ebd-9fb5-d1f702fcfb4a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---- Extract from per_pair ----\n",
        "pairs = [pair for (pair, n, uncal, cal) in per_pair]\n",
        "cal   = [cal   for (pair, n, uncal, cal) in per_pair]\n",
        "\n",
        "# Unique k,m values present\n",
        "ks = sorted({k for (k, m) in pairs})\n",
        "ms = sorted({m for (k, m) in pairs})\n",
        "\n",
        "# Build grid of calibrated MSE: shape = (len(ks), len(ms))\n",
        "grid_cal = np.full((len(ks), len(ms)), np.nan)\n",
        "for (k, m), v in zip(pairs, cal):\n",
        "    i = ks.index(k)\n",
        "    j = ms.index(m)\n",
        "    grid_cal[i, j] = v\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "im = plt.imshow(grid_cal, origin=\"lower\", cmap=\"viridis\")\n",
        "cbar = plt.colorbar(im)\n",
        "cbar.set_label(\"TEST log$_2$-MSE (calibrated)\")\n",
        "\n",
        "plt.xticks(range(len(ms)), ms)\n",
        "plt.yticks(range(len(ks)), ks)\n",
        "plt.xlabel(\"m\")\n",
        "plt.ylabel(\"k\")\n",
        "plt.title(\"Difficulty Map by (k,m) — Calibrated TEST log$_2$-MSE\")\n",
        "\n",
        "# Annotate each cell with value + difficulty tier (E/M/H)\n",
        "for i, k in enumerate(ks):\n",
        "    for j, m in enumerate(ms):\n",
        "        if np.isnan(grid_cal[i, j]):\n",
        "            continue\n",
        "        val = grid_cal[i, j]\n",
        "\n",
        "        if (k, m) in EASY_PAIRS:\n",
        "            tier = \"E\"\n",
        "        elif (k, m) in MEDIUM_PAIRS:\n",
        "            tier = \"M\"\n",
        "        elif (k, m) in HARD_PAIRS:\n",
        "            tier = \"H\"\n",
        "        else:\n",
        "            tier = \"\"\n",
        "\n",
        "        plt.text(\n",
        "            j, i,\n",
        "            f\"{val:.2f}\\n{tier}\",\n",
        "            ha=\"center\", va=\"center\",\n",
        "            color=\"white\", fontsize=8,\n",
        "        )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "ELOEK-8hHRXo",
        "outputId": "a968ac96-cd5f-4577-c0e0-3f5332d84851"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 7 — Visualization & Performance Summary\n",
        "\n",
        "To better understand where the model performs strongly and where additional difficulty remains, we visualize the **per-(k,m) TEST log₂-MSE** for both uncalibrated and calibrated ensemble predictions.\n",
        "\n",
        "### Key observations:\n",
        "- **Easy buckets** \\((k=4,2), (4,3), (5,2), (6,2)\\) achieve extremely low errors (≈ 0.09–0.19), confirming that the SVD-64 featurizer captures matrix structure well for low-m regimes.\n",
        "- **Medium buckets** \\((4,4)\\) and \\((5,3)\\) remain moderate (≈ 0.55–0.59), consistent with historical behavior.\n",
        "- **Hard buckets** \\((4,5), (5,4), (6,3)\\) remain the bottleneck, with errors in the 2.0–2.6 range due to inherent structural variability and high m-heights.\n",
        "- Calibration marginally improves overall error but does *not meaningfully reduce* the hardest buckets — showing that the limiting factor is representational, not scaling.\n",
        "\n",
        "### Overall Takeaway\n",
        "The **global test log₂-MSE = 0.83845** places this model solidly in the high-performing tier for Project 3.  \n",
        "The model generalizes extremely well on **8 out of 9 buckets**, and the overall average is driven primarily by the high difficulty of the three hard buckets — a pattern consistent with known problem difficulty and the professor’s slides.\n",
        "\n",
        "The next phase will integrate this into the Final Submission Cell and compare with the Transformer baseline.\n"
      ],
      "metadata": {
        "id": "ezXnBPqSHTun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Phase 8 / Phase T1 — Global Transformer + 64-D Feature Hybrid\n",
        "Here we experiment on two major ideas for improving m-height prediction:\n",
        "\n",
        "1. **Model the generator matrix \\(P\\) more directly**, rather than relying only on hand-crafted global features.  \n",
        "2. **Explore new deep learning architectures** (e.g., deeper DNNs, attention-style models) that might better capture structure and invariances across all valid \\((k,m)\\) pairs.\n",
        "\n",
        "To follow this guidance for Project 3, I implemented a **global Transformer-based model** that:\n",
        "\n",
        "- Treats each **column of \\(P\\)** as a “token” and processes them with a small **Transformer encoder** (self-attention over columns).\n",
        "- Combines that learned representation with my existing **64-D permutation-invariant SVD feature vector** (from the per-\\((k,m)\\) expert model).\n",
        "- Uses \\((k,m)\\) as explicit inputs (via embeddings) so the model is aware of the bucket it is predicting for.\n",
        "- Outputs a **single global DNN** that predicts \\(\\log_2(\\text{m-height})\\) for *all* \\((k,m)\\) pairs jointly (instead of training 9 separate experts).\n",
        "\n",
        "This section implements and evaluates that hybrid model.  \n",
        "Later, I compare its performance to the per-\\((k,m)\\) ensemble (log\\(_2\\)-MSE ≈ **0.838**) and explain why I keep the expert ensemble as the **final submission model**.\n"
      ],
      "metadata": {
        "id": "BL5SpcJPIOyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer + Feature Hybrid Model\n",
        "\n",
        "# Constants (match your setup)\n",
        "MAX_K        = 6      # max rows of P\n",
        "MAX_TOKENS   = 5      # max columns (n-k, with n=9)\n",
        "FEAT_DIM     = 64     # your invariant feature dimension\n",
        "D_MODEL      = 128    # transformer hidden size\n",
        "NUM_HEADS    = 4\n",
        "FF_DIM       = 256\n",
        "DROPOUT      = 0.10\n",
        "EPS          = 1e-6\n",
        "\n",
        "# Reuse global training knobs if already defined\n",
        "try:\n",
        "    LR = LEARNING_RATE\n",
        "    WD = WEIGHT_DECAY\n",
        "except NameError:\n",
        "    LR = 1e-3\n",
        "    WD = 1e-4\n",
        "\n",
        "def transformer_block(x, name_prefix: str):\n",
        "    \"\"\"Single transformer encoder block with pre-norm residual.\"\"\"\n",
        "    # Self-attention\n",
        "    attn = layers.MultiHeadAttention(\n",
        "        num_heads=NUM_HEADS,\n",
        "        key_dim=D_MODEL // NUM_HEADS,\n",
        "        name=f\"{name_prefix}_mha\"\n",
        "    )(x, x)\n",
        "    x = layers.Add(name=f\"{name_prefix}_attn_add\")([x, attn])\n",
        "    x = layers.LayerNormalization(name=f\"{name_prefix}_attn_ln\")(x)\n",
        "\n",
        "    # Feed-forward\n",
        "    ff = layers.Dense(FF_DIM, activation=\"gelu\", name=f\"{name_prefix}_ffn_1\")(x)\n",
        "    ff = layers.Dropout(DROPOUT, name=f\"{name_prefix}_ffn_dropout\")(ff)\n",
        "    ff = layers.Dense(D_MODEL, name=f\"{name_prefix}_ffn_2\")(ff)\n",
        "\n",
        "    x = layers.Add(name=f\"{name_prefix}_ffn_add\")([x, ff])\n",
        "    x = layers.LayerNormalization(name=f\"{name_prefix}_ffn_ln\")(x)\n",
        "    return x\n",
        "\n",
        "def _masked_mean_P(inputs):\n",
        "    \"\"\"\n",
        "    inputs: [x, mask]\n",
        "      x:    (B, T, D_MODEL)\n",
        "      mask: (B, T, 1) with 0/1 values\n",
        "    returns:\n",
        "      (B, D_MODEL) masked average over tokens\n",
        "    \"\"\"\n",
        "    x, m = inputs\n",
        "    # m: (B, T)\n",
        "    m = tf.squeeze(m, axis=-1)\n",
        "    m = tf.cast(m, x.dtype)\n",
        "\n",
        "    # denom: (B, 1)\n",
        "    denom = tf.reduce_sum(m, axis=1, keepdims=True)\n",
        "    denom = tf.clip_by_value(denom, EPS, 1e9)\n",
        "\n",
        "    # expand back to (B, T, 1) for broadcasting\n",
        "    m_exp = tf.expand_dims(m, axis=-1)\n",
        "    x_masked = x * m_exp  # (B, T, D_MODEL)\n",
        "\n",
        "    num = tf.reduce_sum(x_masked, axis=1)  # (B, D_MODEL)\n",
        "    return num / denom                     # (B, D_MODEL)\n",
        "\n",
        "def build_global_transformer_model(\n",
        "    feat_dim: int = FEAT_DIM,\n",
        "    d_model: int = D_MODEL,\n",
        "    num_heads: int = NUM_HEADS,\n",
        "    ff_dim: int = FF_DIM,\n",
        "    dropout: float = DROPOUT,\n",
        "    lr: float = LR,\n",
        "    weight_decay: float = WD,\n",
        "    huber_delta: float = 0.75,\n",
        "):\n",
        "    \"\"\"\n",
        "    Global model:\n",
        "      Inputs:\n",
        "        - P_tokens: (B, MAX_TOKENS, MAX_K+1), last channel is valid_flag ∈ {0,1}\n",
        "        - feat_64:  (B, FEAT_DIM)  — your invariant SVD-rich features\n",
        "        - k_in:     (B,) int32     — k ∈ {4,5,6}\n",
        "        - m_in:     (B,) int32     — m ∈ {2,...}\n",
        "      Output:\n",
        "        - z_hat:    (B,1)         — predicted log2(m-height)\n",
        "    \"\"\"\n",
        "\n",
        "    # ---- Inputs ----\n",
        "    P_in   = layers.Input(shape=(MAX_TOKENS, MAX_K + 1), name=\"P_tokens\")\n",
        "    F_in   = layers.Input(shape=(feat_dim,), name=\"feat_64\")\n",
        "    k_in   = layers.Input(shape=(), dtype=\"int32\", name=\"k_in\")\n",
        "    m_in   = layers.Input(shape=(), dtype=\"int32\", name=\"m_in\")\n",
        "\n",
        "    # ---- Split P values and validity mask ----\n",
        "    # P_vals: (B, T, MAX_K), mask_raw: (B, T, 1)\n",
        "    P_vals = layers.Lambda(\n",
        "        lambda x: x[..., :MAX_K],\n",
        "        name=\"P_vals\"\n",
        "    )(P_in)\n",
        "\n",
        "    mask_raw = layers.Lambda(\n",
        "        lambda x: x[..., -1:],\n",
        "        name=\"mask_raw\"\n",
        "    )(P_in)\n",
        "\n",
        "    # Binarize mask to {0,1} float; shape (B, T, 1)\n",
        "    mask = layers.Lambda(\n",
        "        lambda m: tf.where(m > 0.5, tf.ones_like(m), tf.zeros_like(m)),\n",
        "        name=\"mask_bin\"\n",
        "    )(mask_raw)\n",
        "\n",
        "    # ---- Token projection (per-column embedding from P) ----\n",
        "    # Shape: (B, T, D_MODEL)\n",
        "    tok = layers.Dense(d_model, activation=\"gelu\", name=\"tok_proj\")(P_vals)\n",
        "\n",
        "    # Apply mask so padded tokens become zero vectors\n",
        "    tok = layers.Multiply(name=\"tok_apply_mask\")([tok, mask])\n",
        "\n",
        "    # ---- Transformer encoder stack ----\n",
        "    x = tok\n",
        "    x = transformer_block(x, name_prefix=\"enc1\")\n",
        "    x = transformer_block(x, name_prefix=\"enc2\")\n",
        "    # Optional extra depth:\n",
        "    # x = transformer_block(x, name_prefix=\"enc3\")\n",
        "\n",
        "    # ---- Masked mean pooling over tokens → h_P (B, D_MODEL) ----\n",
        "    h_P = layers.Lambda(\n",
        "        _masked_mean_P,\n",
        "        name=\"pooled_P\"\n",
        "    )([x, mask])\n",
        "\n",
        "    # ---- Meta branch: feat_64 + embeddings for k and m ----\n",
        "    k_emb = layers.Embedding(\n",
        "        input_dim=7,     # k ∈ {0..6}, we only use 4–6\n",
        "        output_dim=8,\n",
        "        name=\"k_emb\"\n",
        "    )(k_in)\n",
        "    k_emb = layers.Reshape((8,), name=\"k_emb_flat\")(k_emb)\n",
        "\n",
        "    m_emb = layers.Embedding(\n",
        "        input_dim=10,    # enough capacity for m range\n",
        "        output_dim=8,\n",
        "        name=\"m_emb\"\n",
        "    )(m_in)\n",
        "    m_emb = layers.Reshape((8,), name=\"m_emb_flat\")(m_emb)\n",
        "\n",
        "    meta = layers.Concatenate(name=\"meta_concat\")([F_in, k_emb, m_emb])\n",
        "\n",
        "    # Small MLP on meta\n",
        "    meta_h = layers.Dense(128, activation=\"gelu\", name=\"meta_dense1\")(meta)\n",
        "    meta_h = layers.LayerNormalization(name=\"meta_ln1\")(meta_h)\n",
        "    meta_h = layers.Dropout(dropout, name=\"meta_do1\")(meta_h)\n",
        "\n",
        "    meta_h = layers.Dense(64, activation=\"gelu\", name=\"meta_dense2\")(meta_h)\n",
        "    meta_h = layers.LayerNormalization(name=\"meta_ln2\")(meta_h)\n",
        "    meta_h = layers.Dropout(dropout, name=\"meta_do2\")(meta_h)\n",
        "\n",
        "    # ---- Fusion: P representation + meta representation ----\n",
        "    fused = layers.Concatenate(name=\"fusion_concat\")([h_P, meta_h])  # (B, D_MODEL+64)\n",
        "\n",
        "    # Head MLP\n",
        "    h = layers.Dense(256, activation=\"gelu\", name=\"head_dense1\")(fused)\n",
        "    h = layers.LayerNormalization(name=\"head_ln1\")(h)\n",
        "    h = layers.Dropout(dropout, name=\"head_do1\")(h)\n",
        "\n",
        "    h = layers.Dense(128, activation=\"gelu\", name=\"head_dense2\")(h)\n",
        "    h = layers.LayerNormalization(name=\"head_ln2\")(h)\n",
        "    h = layers.Dropout(dropout, name=\"head_do2\")(h)\n",
        "\n",
        "    # Final scalar log2(m-height)\n",
        "    z_hat = layers.Dense(1, name=\"z_hat\")(h)\n",
        "\n",
        "    # ---- Build & compile model ----\n",
        "    model = keras.Model(\n",
        "        inputs=[P_in, F_in, k_in, m_in],\n",
        "        outputs=z_hat,\n",
        "        name=\"GlobalTransformer_mHeight\"\n",
        "    )\n",
        "\n",
        "    opt = keras.optimizers.AdamW(\n",
        "        learning_rate=lr,\n",
        "        weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    loss = keras.losses.Huber(delta=huber_delta)\n",
        "    model.compile(optimizer=opt, loss=loss, metrics=[\"mae\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instantiate and show summary (sanity check)\n",
        "transformer_model = build_global_transformer_model()\n",
        "transformer_model.summary(line_length=120)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EaCmB5tWJAN3",
        "outputId": "48ddffc0-f223-4b42-93ab-162b4dd77af4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"GlobalTransformer_mHeight\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"GlobalTransformer_mHeight\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
              "│ P_tokens (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m7\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ P_vals (\u001b[38;5;33mLambda\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m6\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ P_tokens[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ mask_raw (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ P_tokens[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ tok_proj (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m896\u001b[0m │ P_vals[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ mask_bin (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ mask_raw[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ tok_apply_mask (\u001b[38;5;33mMultiply\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ tok_proj[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           \n",
              "│                                   │                              │                   │ mask_bin[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_mha (\u001b[38;5;33mMultiHeadAttention\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m66,048\u001b[0m │ tok_apply_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
              "│                                   │                              │                   │ tok_apply_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_attn_add (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ tok_apply_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
              "│                                   │                              │                   │ enc1_mha[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_attn_ln (\u001b[38;5;33mLayerNormalization\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m256\u001b[0m │ enc1_attn_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_ffn_1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │            \u001b[38;5;34m33,024\u001b[0m │ enc1_attn_ln[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_ffn_dropout (\u001b[38;5;33mDropout\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ enc1_ffn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_ffn_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m32,896\u001b[0m │ enc1_ffn_dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_ffn_add (\u001b[38;5;33mAdd\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ enc1_attn_ln[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              "│                                   │                              │                   │ enc1_ffn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_ffn_ln (\u001b[38;5;33mLayerNormalization\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m256\u001b[0m │ enc1_ffn_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ k_in (\u001b[38;5;33mInputLayer\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m)                       │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ m_in (\u001b[38;5;33mInputLayer\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m)                       │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_mha (\u001b[38;5;33mMultiHeadAttention\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m66,048\u001b[0m │ enc1_ffn_ln[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
              "│                                   │                              │                   │ enc1_ffn_ln[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ k_emb (\u001b[38;5;33mEmbedding\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                    │                \u001b[38;5;34m56\u001b[0m │ k_in[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ m_emb (\u001b[38;5;33mEmbedding\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                    │                \u001b[38;5;34m80\u001b[0m │ m_in[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_attn_add (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ enc1_ffn_ln[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
              "│                                   │                              │                   │ enc2_mha[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ feat_64 (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ k_emb_flat (\u001b[38;5;33mReshape\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                    │                 \u001b[38;5;34m0\u001b[0m │ k_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ m_emb_flat (\u001b[38;5;33mReshape\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                    │                 \u001b[38;5;34m0\u001b[0m │ m_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_attn_ln (\u001b[38;5;33mLayerNormalization\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m256\u001b[0m │ enc2_attn_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_concat (\u001b[38;5;33mConcatenate\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ feat_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            \n",
              "│                                   │                              │                   │ k_emb_flat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         \n",
              "│                                   │                              │                   │ m_emb_flat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_ffn_1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │            \u001b[38;5;34m33,024\u001b[0m │ enc2_attn_ln[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_dense1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │            \u001b[38;5;34m10,368\u001b[0m │ meta_concat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_ffn_dropout (\u001b[38;5;33mDropout\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ enc2_ffn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_ln1 (\u001b[38;5;33mLayerNormalization\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │               \u001b[38;5;34m256\u001b[0m │ meta_dense1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_ffn_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m32,896\u001b[0m │ enc2_ffn_dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_do1 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ meta_ln1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_ffn_add (\u001b[38;5;33mAdd\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ enc2_attn_ln[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n",
              "│                                   │                              │                   │ enc2_ffn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_dense2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │             \u001b[38;5;34m8,256\u001b[0m │ meta_do1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_ffn_ln (\u001b[38;5;33mLayerNormalization\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m256\u001b[0m │ enc2_ffn_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_ln2 (\u001b[38;5;33mLayerNormalization\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │               \u001b[38;5;34m128\u001b[0m │ meta_dense2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ pooled_P (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ enc2_ffn_ln[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
              "│                                   │                              │                   │ mask_bin[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_do2 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ meta_ln2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ fusion_concat (\u001b[38;5;33mConcatenate\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ pooled_P[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           \n",
              "│                                   │                              │                   │ meta_do2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_dense1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  │            \u001b[38;5;34m49,408\u001b[0m │ fusion_concat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_ln1 (\u001b[38;5;33mLayerNormalization\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  │               \u001b[38;5;34m512\u001b[0m │ head_dense1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_do1 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ head_ln1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_dense2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │            \u001b[38;5;34m32,896\u001b[0m │ head_do1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_ln2 (\u001b[38;5;33mLayerNormalization\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │               \u001b[38;5;34m256\u001b[0m │ head_dense2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_do2 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ head_ln2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ z_hat (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │               \u001b[38;5;34m129\u001b[0m │ head_do2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
              "│ P_tokens (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ P_vals (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ P_tokens[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ mask_raw (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ P_tokens[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ tok_proj (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ P_vals[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ mask_bin (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mask_raw[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ tok_apply_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tok_proj[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           \n",
              "│                                   │                              │                   │ mask_bin[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_mha (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ tok_apply_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
              "│                                   │                              │                   │ tok_apply_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_attn_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tok_apply_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
              "│                                   │                              │                   │ enc1_mha[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_attn_ln (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ enc1_attn_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_ffn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ enc1_attn_ln[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_ffn_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc1_ffn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_ffn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ enc1_ffn_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_ffn_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc1_attn_ln[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              "│                                   │                              │                   │ enc1_ffn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc1_ffn_ln (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ enc1_ffn_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ k_in (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                       │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ m_in (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                       │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_mha (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ enc1_ffn_ln[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
              "│                                   │                              │                   │ enc1_ffn_ln[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ k_emb (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                    │                <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │ k_in[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ m_emb (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                    │                <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │ m_in[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_attn_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc1_ffn_ln[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
              "│                                   │                              │                   │ enc2_mha[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ feat_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ k_emb_flat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ k_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ m_emb_flat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                    │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ m_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_attn_ln (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ enc2_attn_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_concat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ feat_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            \n",
              "│                                   │                              │                   │ k_emb_flat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         \n",
              "│                                   │                              │                   │ m_emb_flat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_ffn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ enc2_attn_ln[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │ meta_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_ffn_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc2_ffn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_ln1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ meta_dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_ffn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ enc2_ffn_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_do1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ meta_ln1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_ffn_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc2_attn_ln[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n",
              "│                                   │                              │                   │ enc2_ffn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ meta_do1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ enc2_ffn_ln (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ enc2_ffn_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_ln2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ meta_dense2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ pooled_P (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ enc2_ffn_ln[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
              "│                                   │                              │                   │ mask_bin[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta_do2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ meta_ln2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ fusion_concat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pooled_P[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           \n",
              "│                                   │                              │                   │ meta_do2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ fusion_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_ln1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ head_dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_do1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ head_ln1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ head_do1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_ln2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ head_dense2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_do2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ head_ln2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ z_hat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ head_do2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m368,201\u001b[0m (1.40 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">368,201</span> (1.40 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m368,201\u001b[0m (1.40 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">368,201</span> (1.40 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase T2 — Column-Token Representation of \\(P\\) + Global TVT Splits\n",
        "\n",
        "To feed \\(P\\) into a Transformer, I represent each sample as a short “sequence” of column-tokens:\n",
        "\n",
        "- For each sample \\((n,k,m,P)\\), with \\(n = 9\\) and \\(P \\in \\mathbb{R}^{k \\times (n-k)}\\):\n",
        "  - Each **column of \\(P\\)** is treated as one token.\n",
        "  - I pad rows up to `MAX_K = 6` and columns up to `MAX_TOKENS = 5`, since:\n",
        "    - \\(k \\in \\{4,5,6\\}\\) → at most 6 rows.\n",
        "    - \\(n - k \\in \\{3,4,5\\}\\) → at most 5 columns.\n",
        "  - The tensor `P_tokens_all` therefore has shape:\n",
        "    - \\((N, \\text{MAX_TOKENS}, \\text{MAX_K} + 1)\\)\n",
        "    - Last channel is a **valid flag** ∈ {0,1} indicating which token positions correspond to real columns.\n",
        "\n",
        "This phase also:\n",
        "\n",
        "- Reuses the **group-aware TVT splits** from Project 3 (the same ones used for the SVD-64 expert model).\n",
        "- Builds **global train/val/test indices** by concatenating per-\\((k,m)\\) indices so that:\n",
        "  - The Transformer model sees exactly the same **60/20/20 split** as the expert ensemble.\n",
        "  - There is **no leakage**: each original sample (and its m-height) appears in only one of train, val, or test.\n"
      ],
      "metadata": {
        "id": "qBJb01XRJAQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build global P-tokens & TVT splits for Transformer model\n",
        "\n",
        "# These must match what we used when defining the transformer\n",
        "MAX_K      = 6          # max rows of P\n",
        "MAX_TOKENS = 5          # max columns (n-k) since n=9 and k∈{4,5,6}\n",
        "\n",
        "# We assume X_list, ALL_FEATURES, KS, MS, z_arr already exist\n",
        "N = len(X_list)\n",
        "print(f\"Total DS3 samples (X_list): {N}\")\n",
        "\n",
        "# Allocate token tensor:\n",
        "#   P_tokens_all[i] has shape (MAX_TOKENS, MAX_K+1)\n",
        "#   - first MAX_K entries: column values (padded with zeros)\n",
        "#   - last entry: valid_flag ∈ {0,1}\n",
        "P_tokens_all = np.zeros((N, MAX_TOKENS, MAX_K + 1), dtype=np.float32)\n",
        "k_arr = np.zeros(N, dtype=np.int32)\n",
        "m_arr = np.zeros(N, dtype=np.int32)\n",
        "\n",
        "for i, (n, k, m, P) in enumerate(X_list):\n",
        "    P = np.asarray(P, dtype=np.float32)\n",
        "    k_arr[i] = int(k)\n",
        "    m_arr[i] = int(m)\n",
        "    nk = n - k\n",
        "    assert n == 9, f\"Unexpected n={n} at index {i}\"\n",
        "    assert 3 <= nk <= MAX_TOKENS, f\"Unexpected n-k={nk} at index {i}\"\n",
        "    assert P.shape == (k, nk), f\"Bad P shape {P.shape} at index {i}\"\n",
        "\n",
        "    # Treat each column of P as a token\n",
        "    for j in range(nk):\n",
        "        col_vec = np.zeros(MAX_K, dtype=np.float32)\n",
        "        col_vec[:k] = P[:, j]              # place k entries, rest stay 0\n",
        "        P_tokens_all[i, j, :MAX_K] = col_vec\n",
        "        P_tokens_all[i, j, -1]    = 1.0    # valid flag = 1\n",
        "\n",
        "print(\"\\nP_tokens_all built:\")\n",
        "print(\"  shape:\", P_tokens_all.shape)     # (N, MAX_TOKENS, MAX_K+1)\n",
        "\n",
        "# -----------------------------\n",
        "# Load DS3 group-aware splits\n",
        "# -----------------------------\n",
        "SPLIT_PATH_DS3 = os.path.join(\"splits\", \"DS3_pair_splits_grouped_60_20_20.pkl\")\n",
        "if not os.path.exists(SPLIT_PATH_DS3):\n",
        "    raise FileNotFoundError(f\"Could not find DS3 splits at {SPLIT_PATH_DS3}\")\n",
        "\n",
        "with open(SPLIT_PATH_DS3, \"rb\") as f:\n",
        "    pair_splits_DS3 = pickle.load(f)\n",
        "\n",
        "# Build global index arrays by unioning per-(k,m) splits\n",
        "train_idx, val_idx, test_idx = [], [], []\n",
        "for (k, m), splits in sorted(pair_splits_DS3.items()):\n",
        "    train_idx.extend(splits[\"train\"])\n",
        "    val_idx.extend(splits[\"val\"])\n",
        "    test_idx.extend(splits[\"test\"])\n",
        "\n",
        "train_idx = np.array(sorted(train_idx), dtype=np.int32)\n",
        "val_idx   = np.array(sorted(val_idx),   dtype=np.int32)\n",
        "test_idx  = np.array(sorted(test_idx),  dtype=np.int32)\n",
        "\n",
        "print(\"\\nGlobal index sizes (from DS3 grouped splits):\")\n",
        "print(f\"  train: {train_idx.shape[0]}\")\n",
        "print(f\"  val  : {val_idx.shape[0]}\")\n",
        "print(f\"  test : {test_idx.shape[0]}\")\n",
        "\n",
        "# Consistency checks\n",
        "assert train_idx.shape[0] + val_idx.shape[0] + test_idx.shape[0] == N, \"TVT counts do not sum to N\"\n",
        "assert np.intersect1d(train_idx, val_idx).size == 0\n",
        "assert np.intersect1d(train_idx, test_idx).size == 0\n",
        "assert np.intersect1d(val_idx, test_idx).size == 0\n",
        "\n",
        "print(\"\\nTransformer data prep OK \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KgvlHCSTdV7",
        "outputId": "31c85fae-a716-4b8d-be40-265e21f6fbec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total DS3 samples (X_list): 56365\n",
            "\n",
            "P_tokens_all built:\n",
            "  shape: (56365, 5, 7)\n",
            "\n",
            "Global index sizes (from DS3 grouped splits):\n",
            "  train: 33815\n",
            "  val  : 11273\n",
            "  test : 11277\n",
            "\n",
            "Transformer data prep OK \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase T3 — Column & Row Masks for Structured Attention\n",
        "\n",
        "Even though the Transformer architecture can handle padding, it is helpful to explicitly encode which parts of each tensor are “real” vs “padded”. In this phase I construct two masks:\n",
        "\n",
        "1. **Column mask (`col_mask_all`)**\n",
        "   - Extracted from the last channel of `P_tokens_all`.\n",
        "   - Shape: \\((N, \\text{MAX_TOKENS})\\)\n",
        "   - `1.0` for valid columns of \\(P\\), `0.0` for padded column positions.\n",
        "   - Used conceptually to indicate how many column-tokens are truly active per sample.\n",
        "\n",
        "2. **Row mask (`row_mask_all`)**\n",
        "   - Shape: \\((N, \\text{MAX_K})\\)\n",
        "   - For each sample, the first `k` entries are set to 1.0, remaining entries to 0.0.\n",
        "   - This is primarily useful if we want to design future models that attend over **rows** as well as columns.\n",
        "\n",
        "For the simple Transformer baseline implemented later, I mainly use the **column structure** (number and content of tokens). The masks are split using the same global `train_idx`, `val_idx`, and `test_idx` so the Transformer’s data pipeline is perfectly aligned with the SVD-64 ensemble.\n"
      ],
      "metadata": {
        "id": "SNCmdgxuJO3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Build column & row masks for Transformer\n",
        "\n",
        "N = P_tokens_all.shape[0]\n",
        "MAX_TOKENS = P_tokens_all.shape[1]\n",
        "MAX_K = 6  # as before\n",
        "\n",
        "# Column mask: use the last channel of P_tokens_all as \"valid flag\"\n",
        "# P_tokens_all[..., -1] is 1.0 for valid tokens, 0.0 for padded ones\n",
        "col_mask_all = (P_tokens_all[..., -1] > 0.5).astype(np.float32)   # (N, MAX_TOKENS)\n",
        "\n",
        "# Row mask: 1 for first k rows, 0 after that\n",
        "row_mask_all = np.zeros((N, MAX_K), dtype=np.float32)\n",
        "for i, k in enumerate(k_arr):\n",
        "    row_mask_all[i, :int(k)] = 1.0\n",
        "\n",
        "print(\"col_mask_all shape:\", col_mask_all.shape)\n",
        "print(\"row_mask_all shape:\", row_mask_all.shape)\n",
        "\n",
        "# Split into train/val/test using the same indices\n",
        "Cm_tr = col_mask_all[train_idx]\n",
        "Cm_val = col_mask_all[val_idx]\n",
        "Cm_te = col_mask_all[test_idx]\n",
        "\n",
        "Rm_tr = row_mask_all[train_idx]\n",
        "Rm_val = row_mask_all[val_idx]\n",
        "Rm_te = row_mask_all[test_idx]\n",
        "\n",
        "print(\"\\nMask split shapes:\")\n",
        "print(\"  Cm_tr:\", Cm_tr.shape, \"Rm_tr:\", Rm_tr.shape)\n",
        "print(\"  Cm_val:\", Cm_val.shape, \"Rm_val:\", Rm_val.shape)\n",
        "print(\"  Cm_te:\", Cm_te.shape, \"Rm_te:\", Rm_te.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PMdgiT5YAI_",
        "outputId": "0e8dca63-cf73-4eec-8ff6-05e03412462c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "col_mask_all shape: (56365, 5)\n",
            "row_mask_all shape: (56365, 6)\n",
            "\n",
            "Mask split shapes:\n",
            "  Cm_tr: (33815, 5) Rm_tr: (33815, 6)\n",
            "  Cm_val: (11273, 5) Rm_val: (11273, 6)\n",
            "  Cm_te: (11277, 5) Rm_te: (11277, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase T4 — Simple Global Transformer (Column Tokens + 64-D Features)\n",
        "\n",
        "The first hybrid architecture (4-input version with explicit \\(k, m\\) embeddings) turned out to be **more complex than necessary** and harder to debug in Colab.  \n",
        "In the spirit of the professor’s slides (try new architectures but keep them trainable and stable), I distilled it into a **simpler 2-input Transformer model**:\n",
        "\n",
        "**Inputs:**\n",
        "\n",
        "1. `P_tokens` — \\((\\text{batch}, \\text{max\\_nk}, d_p)\\)  \n",
        "   - Each row is one sample’s sequence of column-tokens (padded to `max_nk = 5`).\n",
        "   - Each token is the padded column vector from \\(P\\) (plus a simple positional encoding).\n",
        "\n",
        "2. `meta` — \\((\\text{batch}, 64)\\)  \n",
        "   - The same **64-D permutation-invariant SVD feature vector** used in the per-\\((k,m)\\) experts.\n",
        "\n",
        "**Architecture:**\n",
        "\n",
        "- Project tokens → \\(d_{\\text{model}} = 128\\).\n",
        "- Add a small learned positional embedding across the 5 token positions (professor’s slides mention leveraging structural patterns across rows/columns).\n",
        "- Stack **3 Transformer encoder blocks**:\n",
        "  - Multi-head self-attention + residual + LayerNorm.\n",
        "  - Feed-forward network + residual + LayerNorm.\n",
        "- Apply **GlobalAveragePooling1D** over tokens → a single representation of the matrix \\(P\\).\n",
        "- Concatenate this pooled vector with the **64-D meta features**.\n",
        "- Pass through a small MLP head (128 → 64 → 1) to predict \\(\\hat{z} = \\log_2(\\text{m-height})\\).\n",
        "- Train with **MSE loss** on \\(\\log_2(\\text{m-height})\\) and Adam optimizer.\n",
        "\n",
        "This gives a **single global model** that:\n",
        "- Sees the raw generator matrix structure via attention over columns.\n",
        "- Retains the strong **SVD-64 invariant features** that worked well in Project 2.\n"
      ],
      "metadata": {
        "id": "JHv5LIhMJWxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Global transformer model (2-input version: P_tokens + meta features)\n",
        "\n",
        "def build_global_transformer_model_simple(\n",
        "    max_nk: int,\n",
        "    d_p: int,\n",
        "    meta_dim: int = 64,\n",
        "    d_model: int = 128,\n",
        "    num_heads: int = 4,\n",
        "    ff_dim: int = 256,\n",
        "    num_layers: int = 3,\n",
        "    dropout_rate: float = 0.1,\n",
        "    learning_rate: float = 1e-3,\n",
        "):\n",
        "    \"\"\"\n",
        "    Global transformer over column tokens of P + 64-D permutation-invariant meta features.\n",
        "\n",
        "    Inputs:\n",
        "      - P_tokens: (batch, max_nk, d_p)  e.g. (None, 5, 7)\n",
        "      - meta:     (batch, meta_dim)     e.g. (None, 64)\n",
        "\n",
        "    Output:\n",
        "      - z_hat: (batch, 1), predicting z = log2(m-height)\n",
        "    \"\"\"\n",
        "\n",
        "    # ---- Inputs ----\n",
        "    P_in = keras.Input(shape=(max_nk, d_p), name=\"P_tokens\")   # (B, T, d_p)\n",
        "    meta_in = keras.Input(shape=(meta_dim,), name=\"meta\")      # (B, meta_dim)\n",
        "\n",
        "    # ---- Project tokens to d_model ----\n",
        "    x = layers.Dense(d_model, activation=\"linear\", name=\"proj_tokens\")(P_in)  # (B, T, d_model)\n",
        "\n",
        "    # Optional learned positional bias (since T is tiny = 5)\n",
        "    pos_emb = layers.Embedding(input_dim=max_nk, output_dim=d_model, name=\"pos_emb\")\n",
        "    positions = tf.range(start=0, limit=max_nk, delta=1)\n",
        "    pos_encoding = pos_emb(positions)     # (T, d_model)\n",
        "    pos_encoding = tf.expand_dims(pos_encoding, axis=0)  # (1, T, d_model)\n",
        "    x = x + pos_encoding                  # broadcast over batch\n",
        "\n",
        "    # ---- Transformer encoder blocks ----\n",
        "    for i in range(num_layers):\n",
        "        # Multi-head self-attention\n",
        "        attn_out = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=d_model // num_heads,\n",
        "            dropout=dropout_rate,\n",
        "            name=f\"mha_{i}\"\n",
        "        )(x, x)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6, name=f\"ln_attn_{i}\")(x + attn_out)\n",
        "\n",
        "        # Feed-forward\n",
        "        ff = layers.Dense(ff_dim, activation=\"gelu\", name=f\"ff_{i}_1\")(x)\n",
        "        ff = layers.Dropout(dropout_rate, name=f\"drop_ff_{i}\")(ff)\n",
        "        ff = layers.Dense(d_model, activation=\"linear\", name=f\"ff_{i}_2\")(ff)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6, name=f\"ln_ff_{i}\")(x + ff)\n",
        "\n",
        "    # ---- Pool over tokens ----\n",
        "    pooled = layers.GlobalAveragePooling1D(name=\"pool_tokens\")(x)  # (B, d_model)\n",
        "\n",
        "    # ---- Fuse with meta features ----\n",
        "    h = layers.Concatenate(name=\"concat_meta\")([pooled, meta_in])\n",
        "    h = layers.Dense(128, activation=\"gelu\", name=\"head_1\")(h)\n",
        "    h = layers.Dropout(0.1, name=\"head_drop_1\")(h)\n",
        "    h = layers.Dense(64, activation=\"gelu\", name=\"head_2\")(h)\n",
        "    h = layers.Dropout(0.1, name=\"head_drop_2\")(h)\n",
        "\n",
        "    out = layers.Dense(1, name=\"z_hat\")(h)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[P_in, meta_in],\n",
        "        outputs=out,\n",
        "        name=\"GlobalTransformer_mHeight_simple\"\n",
        "    )\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=opt, loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "gdVrujyKYGhd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase T5 — Training & Evaluating the Global Transformer vs. Expert Ensemble\n",
        "\n",
        "In this final Transformer phase, I:\n",
        "\n",
        "1. **Standardize** the 64-D meta features:\n",
        "   - Fit a `StandardScaler` on TRAIN only.\n",
        "   - Transform TRAIN/VAL/TEST meta features accordingly.\n",
        "2. Use the pre-built:\n",
        "   - `P_tokens_all[train/val/test_idx]` as the token sequences.\n",
        "   - `z_arr[train/val/test_idx]` as the \\(\\log_2(\\text{m-height})\\) targets.\n",
        "3. Train the global Transformer:\n",
        "   - Batch size: 512  \n",
        "   - Epochs: up to 150, with:\n",
        "     - Early stopping on validation loss (patience = 20).\n",
        "     - ReduceLROnPlateau on validation loss.\n",
        "     - ModelCheckpoint saving the **best** model.\n",
        "\n",
        "After training, I reload the best checkpoint and report:\n",
        "\n",
        "- **VAL log\\(_2\\)-MSE**\n",
        "- **TEST log\\(_2\\)-MSE**\n",
        "\n",
        "On my Project 3 data:\n",
        "\n",
        "- Per-\\((k,m)\\) SVD-64 expert ensemble achieved  \n",
        "  **TEST log\\(_2\\)-MSE ≈ 0.838**.\n",
        "- The **global Transformer hybrid** converged to a **higher** TEST log\\(_2\\)-MSE (around 0.90 in my runs).\n",
        "\n",
        "Despite being more sophisticated architecturally and closer in spirit to “end-to-end matrix modeling”, the Transformer:\n",
        "\n",
        "- Did **not outperform** the carefully tuned per-\\((k,m)\\) expert ensemble (with targeted augmentation and Huber loss on hard buckets).\n",
        "- Likely needs either a much larger dataset, more careful regularization/tuning, or a more advanced architectural bias tailored to generator matrices.\n",
        "\n",
        "For Project 3 grading, based on the **log\\(_2\\)-MSE metric**, I therefore:\n",
        "\n",
        "> **Choose the SVD-64 MoE ensemble (TEST log\\(_2\\)-MSE ≈ 0.838) as my final submission model**,  \n",
        "> while including this Transformer experiment to demonstrate exploration of new architectures and matrix-aware modeling ideas.\n"
      ],
      "metadata": {
        "id": "tddyoROgJksa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train + Evaluate Simple Global Transformer on DS3\n",
        "\n",
        "\n",
        "print(\" Global Transformer (simple 2-input) on DS3 \")\n",
        "\n",
        "# Sanity: check shapes\n",
        "print(\"P_tokens_all shape:\", P_tokens_all.shape)  # (N, max_nk, d_p)\n",
        "print(\"ALL_FEATURES shape:\", ALL_FEATURES.shape)  # (N, 64)\n",
        "print(\"z_arr shape:\", z_arr.shape)                # (N,)\n",
        "\n",
        "N, MAX_NK, D_P = P_tokens_all.shape\n",
        "assert ALL_FEATURES.shape[0] == N == z_arr.shape[0]\n",
        "\n",
        "# Use existing global indices from DS3 grouped splits\n",
        "print(f\"Train idx: {train_idx.shape[0]}, Val idx: {val_idx.shape[0]}, Test idx: {test_idx.shape[0]}\")\n",
        "\n",
        "# Meta features & targets\n",
        "Xmeta_all = ALL_FEATURES.astype(np.float32)\n",
        "z_all     = z_arr.astype(np.float32)\n",
        "\n",
        "# Standardize meta features using TRAIN only\n",
        "scaler_meta = StandardScaler().fit(Xmeta_all[train_idx])\n",
        "Xmeta_tr = scaler_meta.transform(Xmeta_all[train_idx])\n",
        "Xmeta_val = scaler_meta.transform(Xmeta_all[val_idx])\n",
        "Xmeta_te = scaler_meta.transform(Xmeta_all[test_idx])\n",
        "\n",
        "# P tokens (already padded for variable nk)\n",
        "P_tr  = P_tokens_all[train_idx]\n",
        "P_val = P_tokens_all[val_idx]\n",
        "P_te  = P_tokens_all[test_idx]\n",
        "\n",
        "z_tr  = z_all[train_idx]\n",
        "z_val = z_all[val_idx]\n",
        "z_te  = z_all[test_idx]\n",
        "\n",
        "print(\"\\nShapes:\")\n",
        "print(\"  P_tr      :\", P_tr.shape)\n",
        "print(\"  P_val     :\", P_val.shape)\n",
        "print(\"  P_te      :\", P_te.shape)\n",
        "print(\"  Xmeta_tr  :\", Xmeta_tr.shape)\n",
        "print(\"  Xmeta_val :\", Xmeta_val.shape)\n",
        "print(\"  Xmeta_te  :\", Xmeta_te.shape)\n",
        "print(\"  z_tr      :\", z_tr.shape)\n",
        "print(\"  z_val     :\", z_val.shape)\n",
        "print(\"  z_te      :\", z_te.shape)\n",
        "\n",
        "# --------- Build & train model ---------\n",
        "SAVE_ROOT_TRANS = \"Proj3_GlobalTransformer_simple\"\n",
        "os.makedirs(SAVE_ROOT_TRANS, exist_ok=True)\n",
        "\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "\n",
        "transformer_model = build_global_transformer_model_simple(\n",
        "    max_nk=MAX_NK,\n",
        "    d_p=D_P,\n",
        "    meta_dim=Xmeta_tr.shape[1],\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    ff_dim=256,\n",
        "    num_layers=3,\n",
        "    dropout_rate=0.1,\n",
        "    learning_rate=1e-3,\n",
        ")\n",
        "transformer_model.summary(line_length=120)\n",
        "\n",
        "ckpt_path = os.path.join(SAVE_ROOT_TRANS, \"transformer_best.keras\")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=20,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1,\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        factor=0.5,\n",
        "        patience=8,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1,\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        ckpt_path,\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        verbose=1,\n",
        "    ),\n",
        "]\n",
        "\n",
        "BATCH_SIZE_TRANS = 512\n",
        "MAX_EPOCHS_TRANS = 150\n",
        "\n",
        "print(\"\\n=== Fitting simple global transformer ===\")\n",
        "history = transformer_model.fit(\n",
        "    [P_tr, Xmeta_tr],\n",
        "    z_tr,\n",
        "    validation_data=([P_val, Xmeta_val], z_val),\n",
        "    epochs=MAX_EPOCHS_TRANS,\n",
        "    batch_size=BATCH_SIZE_TRANS,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "# --------- Reload best & evaluate ---------\n",
        "print(\"\\nReloading best transformer checkpoint from:\", ckpt_path)\n",
        "best_model = keras.models.load_model(ckpt_path)\n",
        "\n",
        "def mse_np(a, b):\n",
        "    a = np.asarray(a).ravel()\n",
        "    b = np.asarray(b).ravel()\n",
        "    return float(np.mean((a - b) ** 2))\n",
        "\n",
        "z_val_hat = best_model.predict([P_val, Xmeta_val], verbose=0).ravel()\n",
        "z_te_hat  = best_model.predict([P_te, Xmeta_te],   verbose=0).ravel()\n",
        "\n",
        "val_log2_mse  = mse_np(z_val, z_val_hat)\n",
        "test_log2_mse = mse_np(z_te,  z_te_hat)\n",
        "\n",
        "print(f\"\\n=== Simple Global Transformer Performance (log2-MSE) ===\")\n",
        "print(f\"  VAL  log2-MSE: {val_log2_mse:.5f}\")\n",
        "print(f\"  TEST log2-MSE: {test_log2_mse:.5f}\")\n",
        "print(\"  (Comparable to MoE 0.838 — if this is lower, we win.)\")\n",
        "\n",
        "# Save scaler + indices for future submission cell, if you keep this model\n",
        "meta_path = os.path.join(SAVE_ROOT_TRANS, \"meta_scaler_and_indices.pkl\")\n",
        "with open(meta_path, \"wb\") as f:\n",
        "    pickle.dump(\n",
        "        {\n",
        "            \"scaler_meta\": scaler_meta,\n",
        "            \"train_idx\": train_idx,\n",
        "            \"val_idx\": val_idx,\n",
        "            \"test_idx\": test_idx,\n",
        "        },\n",
        "        f,\n",
        "    )\n",
        "\n",
        "print(\"\\nSaved meta scaler + indices to:\", meta_path)\n",
        "print(\"Simple global transformer training + evaluation complete \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iX_ba9_raphL",
        "outputId": "e4346492-f332-4ed8-eae0-47ff339a7926"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Global Transformer (simple 2-input) on DS3 \n",
            "P_tokens_all shape: (56365, 5, 7)\n",
            "ALL_FEATURES shape: (56365, 64)\n",
            "z_arr shape: (56365,)\n",
            "Train idx: 33815, Val idx: 11273, Test idx: 11277\n",
            "\n",
            "Shapes:\n",
            "  P_tr      : (33815, 5, 7)\n",
            "  P_val     : (11273, 5, 7)\n",
            "  P_te      : (11277, 5, 7)\n",
            "  Xmeta_tr  : (33815, 64)\n",
            "  Xmeta_val : (11273, 64)\n",
            "  Xmeta_te  : (11277, 64)\n",
            "  z_tr      : (33815,)\n",
            "  z_val     : (11273,)\n",
            "  z_te      : (11277,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"GlobalTransformer_mHeight_simple\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"GlobalTransformer_mHeight_simple\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
              "│ P_tokens (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m7\u001b[0m)                 │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ proj_tokens (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m1,024\u001b[0m │ P_tokens[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ proj_tokens[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ mha_0 (\u001b[38;5;33mMultiHeadAttention\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m66,048\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], mha_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ln_attn_0 (\u001b[38;5;33mLayerNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m256\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ff_0_1 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │            \u001b[38;5;34m33,024\u001b[0m │ ln_attn_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ drop_ff_0 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ ff_0_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ff_0_2 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m32,896\u001b[0m │ drop_ff_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ ln_attn_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], ff_0_2[\u001b[38;5;34m0\u001b[0m]\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ln_ff_0 (\u001b[38;5;33mLayerNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m256\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ mha_1 (\u001b[38;5;33mMultiHeadAttention\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m66,048\u001b[0m │ ln_ff_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], ln_ff_0[\u001b[38;5;34m0\u001b[0m][\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ ln_ff_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], mha_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ln_attn_1 (\u001b[38;5;33mLayerNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m256\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ff_1_1 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │            \u001b[38;5;34m33,024\u001b[0m │ ln_attn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ drop_ff_1 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ ff_1_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ff_1_2 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m32,896\u001b[0m │ drop_ff_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ ln_attn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], ff_1_2[\u001b[38;5;34m0\u001b[0m]\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ln_ff_1 (\u001b[38;5;33mLayerNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m256\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ mha_2 (\u001b[38;5;33mMultiHeadAttention\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m66,048\u001b[0m │ ln_ff_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], ln_ff_1[\u001b[38;5;34m0\u001b[0m][\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ ln_ff_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], mha_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ln_attn_2 (\u001b[38;5;33mLayerNormalization\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m256\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ff_2_1 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │            \u001b[38;5;34m33,024\u001b[0m │ ln_attn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ drop_ff_2 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ ff_2_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ff_2_2 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │            \u001b[38;5;34m32,896\u001b[0m │ drop_ff_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │                 \u001b[38;5;34m0\u001b[0m │ ln_attn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], ff_2_2[\u001b[38;5;34m0\u001b[0m]\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ln_ff_2 (\u001b[38;5;33mLayerNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m256\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ pool_tokens                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ ln_ff_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             \n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)          │                              │                   │                           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta (\u001b[38;5;33mInputLayer\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ -                         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ concat_meta (\u001b[38;5;33mConcatenate\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ pool_tokens[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], meta[\u001b[38;5;34m0\u001b[0m]\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_1 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │            \u001b[38;5;34m24,704\u001b[0m │ concat_meta[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_drop_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  │                 \u001b[38;5;34m0\u001b[0m │ head_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_2 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │             \u001b[38;5;34m8,256\u001b[0m │ head_drop_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_drop_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   │                 \u001b[38;5;34m0\u001b[0m │ head_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ z_hat (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                    │                \u001b[38;5;34m65\u001b[0m │ head_drop_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape                 </span>┃<span style=\"font-weight: bold\">           Param # </span>┃<span style=\"font-weight: bold\"> Connected to              </span>\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
              "│ P_tokens (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                 │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ proj_tokens (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ P_tokens[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ proj_tokens[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ mha_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], mha_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ln_attn_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ff_0_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ ln_attn_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ drop_ff_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ff_0_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ff_0_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ drop_ff_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ln_attn_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], ff_0_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ln_ff_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ mha_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ ln_ff_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], ln_ff_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ln_ff_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], mha_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ln_attn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ff_1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ ln_attn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ drop_ff_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ff_1_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ff_1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ drop_ff_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ln_attn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], ff_1_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ln_ff_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ mha_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ ln_ff_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], ln_ff_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ln_ff_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], mha_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ln_attn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ff_2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ ln_attn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ drop_ff_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ff_2_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ff_2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ drop_ff_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ln_attn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], ff_2_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ ln_ff_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ pool_tokens                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ln_ff_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             \n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)          │                              │                   │                           \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ meta (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ concat_meta (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pool_tokens[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], meta[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]\n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ concat_meta[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_drop_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ head_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ head_drop_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ head_drop_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ head_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              \n",
              "├───────────────────────────────────┼──────────────────────────────┼───────────────────┼───────────────────────────\n",
              "│ z_hat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                    │                <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ head_drop_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "└───────────────────────────────────┴──────────────────────────────┴───────────────────┴───────────────────────────\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m431,489\u001b[0m (1.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,489</span> (1.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m431,489\u001b[0m (1.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,489</span> (1.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fitting simple global transformer ===\n",
            "Epoch 1/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 930ms/step - loss: 19.5763 - mae: 3.1551\n",
            "Epoch 1: val_loss improved from inf to 1.41304, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 970ms/step - loss: 19.2329 - mae: 3.1188 - val_loss: 1.4130 - val_mae: 0.9079 - learning_rate: 0.0010\n",
            "Epoch 2/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 2.2536 - mae: 1.1349\n",
            "Epoch 2: val_loss improved from 1.41304 to 1.12493, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - loss: 2.2490 - mae: 1.1334 - val_loss: 1.1249 - val_mae: 0.7782 - learning_rate: 0.0010\n",
            "Epoch 3/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 930ms/step - loss: 1.8034 - mae: 0.9987\n",
            "Epoch 3: val_loss improved from 1.12493 to 1.07124, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 953ms/step - loss: 1.8019 - mae: 0.9981 - val_loss: 1.0712 - val_mae: 0.7526 - learning_rate: 0.0010\n",
            "Epoch 4/150\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934ms/step - loss: 1.6549 - mae: 0.9462\n",
            "Epoch 4: val_loss did not improve from 1.07124\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - loss: 1.6544 - mae: 0.9460 - val_loss: 1.1720 - val_mae: 0.8063 - learning_rate: 0.0010\n",
            "Epoch 5/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.6221 - mae: 0.9330\n",
            "Epoch 5: val_loss improved from 1.07124 to 0.99745, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - loss: 1.6207 - mae: 0.9324 - val_loss: 0.9974 - val_mae: 0.7309 - learning_rate: 0.0010\n",
            "Epoch 6/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 920ms/step - loss: 1.5398 - mae: 0.9035\n",
            "Epoch 6: val_loss did not improve from 0.99745\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 935ms/step - loss: 1.5396 - mae: 0.9033 - val_loss: 1.1292 - val_mae: 0.7994 - learning_rate: 0.0010\n",
            "Epoch 7/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 921ms/step - loss: 1.5494 - mae: 0.9083\n",
            "Epoch 7: val_loss did not improve from 0.99745\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 943ms/step - loss: 1.5483 - mae: 0.9077 - val_loss: 1.0423 - val_mae: 0.7543 - learning_rate: 0.0010\n",
            "Epoch 8/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.5467 - mae: 0.9018\n",
            "Epoch 8: val_loss did not improve from 0.99745\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 1s/step - loss: 1.5459 - mae: 0.9013 - val_loss: 1.0715 - val_mae: 0.7799 - learning_rate: 0.0010\n",
            "Epoch 9/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.4806 - mae: 0.8780\n",
            "Epoch 9: val_loss did not improve from 0.99745\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - loss: 1.4796 - mae: 0.8776 - val_loss: 1.0900 - val_mae: 0.7764 - learning_rate: 0.0010\n",
            "Epoch 10/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 925ms/step - loss: 1.4773 - mae: 0.8819\n",
            "Epoch 10: val_loss improved from 0.99745 to 0.97273, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 943ms/step - loss: 1.4764 - mae: 0.8816 - val_loss: 0.9727 - val_mae: 0.7204 - learning_rate: 0.0010\n",
            "Epoch 11/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 968ms/step - loss: 1.4009 - mae: 0.8551\n",
            "Epoch 11: val_loss improved from 0.97273 to 0.95649, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 985ms/step - loss: 1.4012 - mae: 0.8551 - val_loss: 0.9565 - val_mae: 0.7013 - learning_rate: 0.0010\n",
            "Epoch 12/150\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 1.3792 - mae: 0.8474\n",
            "Epoch 12: val_loss did not improve from 0.95649\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - loss: 1.3792 - mae: 0.8474 - val_loss: 0.9804 - val_mae: 0.7145 - learning_rate: 0.0010\n",
            "Epoch 13/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.3581 - mae: 0.8431\n",
            "Epoch 13: val_loss did not improve from 0.95649\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - loss: 1.3580 - mae: 0.8429 - val_loss: 0.9894 - val_mae: 0.7276 - learning_rate: 0.0010\n",
            "Epoch 14/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 973ms/step - loss: 1.3813 - mae: 0.8482\n",
            "Epoch 14: val_loss improved from 0.95649 to 0.94416, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 990ms/step - loss: 1.3813 - mae: 0.8481 - val_loss: 0.9442 - val_mae: 0.7012 - learning_rate: 0.0010\n",
            "Epoch 15/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.3709 - mae: 0.8455\n",
            "Epoch 15: val_loss did not improve from 0.94416\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - loss: 1.3707 - mae: 0.8454 - val_loss: 1.0290 - val_mae: 0.7558 - learning_rate: 0.0010\n",
            "Epoch 16/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 917ms/step - loss: 1.3467 - mae: 0.8419\n",
            "Epoch 16: val_loss did not improve from 0.94416\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 939ms/step - loss: 1.3462 - mae: 0.8415 - val_loss: 0.9843 - val_mae: 0.7390 - learning_rate: 0.0010\n",
            "Epoch 17/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 958ms/step - loss: 1.3744 - mae: 0.8436\n",
            "Epoch 17: val_loss improved from 0.94416 to 0.93822, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 976ms/step - loss: 1.3735 - mae: 0.8432 - val_loss: 0.9382 - val_mae: 0.6829 - learning_rate: 0.0010\n",
            "Epoch 18/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 958ms/step - loss: 1.3302 - mae: 0.8256\n",
            "Epoch 18: val_loss improved from 0.93822 to 0.91998, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 985ms/step - loss: 1.3300 - mae: 0.8255 - val_loss: 0.9200 - val_mae: 0.6778 - learning_rate: 0.0010\n",
            "Epoch 19/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 960ms/step - loss: 1.2978 - mae: 0.8167\n",
            "Epoch 19: val_loss did not improve from 0.91998\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 975ms/step - loss: 1.2981 - mae: 0.8167 - val_loss: 0.9984 - val_mae: 0.7325 - learning_rate: 0.0010\n",
            "Epoch 20/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 962ms/step - loss: 1.3046 - mae: 0.8199\n",
            "Epoch 20: val_loss did not improve from 0.91998\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 977ms/step - loss: 1.3044 - mae: 0.8198 - val_loss: 0.9221 - val_mae: 0.6777 - learning_rate: 0.0010\n",
            "Epoch 21/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 959ms/step - loss: 1.3020 - mae: 0.8169\n",
            "Epoch 21: val_loss did not improve from 0.91998\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 975ms/step - loss: 1.3016 - mae: 0.8168 - val_loss: 0.9935 - val_mae: 0.7285 - learning_rate: 0.0010\n",
            "Epoch 22/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 956ms/step - loss: 1.3270 - mae: 0.8251\n",
            "Epoch 22: val_loss did not improve from 0.91998\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 975ms/step - loss: 1.3266 - mae: 0.8250 - val_loss: 0.9368 - val_mae: 0.6847 - learning_rate: 0.0010\n",
            "Epoch 23/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.2912 - mae: 0.8136\n",
            "Epoch 23: val_loss did not improve from 0.91998\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - loss: 1.2911 - mae: 0.8134 - val_loss: 0.9879 - val_mae: 0.7252 - learning_rate: 0.0010\n",
            "Epoch 24/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.2967 - mae: 0.8139\n",
            "Epoch 24: val_loss did not improve from 0.91998\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.2964 - mae: 0.8138 - val_loss: 1.0029 - val_mae: 0.7442 - learning_rate: 0.0010\n",
            "Epoch 25/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.2680 - mae: 0.8098\n",
            "Epoch 25: val_loss did not improve from 0.91998\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.2683 - mae: 0.8097 - val_loss: 0.9521 - val_mae: 0.7022 - learning_rate: 0.0010\n",
            "Epoch 26/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.2935 - mae: 0.8124\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.91998\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.2931 - mae: 0.8122 - val_loss: 0.9870 - val_mae: 0.7302 - learning_rate: 0.0010\n",
            "Epoch 27/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.2706 - mae: 0.8050\n",
            "Epoch 27: val_loss improved from 0.91998 to 0.90611, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.2702 - mae: 0.8048 - val_loss: 0.9061 - val_mae: 0.6676 - learning_rate: 5.0000e-04\n",
            "Epoch 28/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.2199 - mae: 0.7885\n",
            "Epoch 28: val_loss did not improve from 0.90611\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.2201 - mae: 0.7885 - val_loss: 0.9373 - val_mae: 0.6882 - learning_rate: 5.0000e-04\n",
            "Epoch 29/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.2505 - mae: 0.7983\n",
            "Epoch 29: val_loss improved from 0.90611 to 0.90387, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.2503 - mae: 0.7981 - val_loss: 0.9039 - val_mae: 0.6650 - learning_rate: 5.0000e-04\n",
            "Epoch 30/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.2306 - mae: 0.7903\n",
            "Epoch 30: val_loss did not improve from 0.90387\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.2309 - mae: 0.7903 - val_loss: 0.9042 - val_mae: 0.6625 - learning_rate: 5.0000e-04\n",
            "Epoch 31/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1836 - mae: 0.7768\n",
            "Epoch 31: val_loss did not improve from 0.90387\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.1841 - mae: 0.7768 - val_loss: 0.9062 - val_mae: 0.6661 - learning_rate: 5.0000e-04\n",
            "Epoch 32/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.2044 - mae: 0.7840\n",
            "Epoch 32: val_loss did not improve from 0.90387\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 1.2047 - mae: 0.7839 - val_loss: 0.9382 - val_mae: 0.6873 - learning_rate: 5.0000e-04\n",
            "Epoch 33/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.2008 - mae: 0.7803\n",
            "Epoch 33: val_loss did not improve from 0.90387\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.2006 - mae: 0.7802 - val_loss: 0.9233 - val_mae: 0.6824 - learning_rate: 5.0000e-04\n",
            "Epoch 34/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1994 - mae: 0.7803\n",
            "Epoch 34: val_loss did not improve from 0.90387\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.1996 - mae: 0.7803 - val_loss: 0.9173 - val_mae: 0.6796 - learning_rate: 5.0000e-04\n",
            "Epoch 35/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.2152 - mae: 0.7882\n",
            "Epoch 35: val_loss did not improve from 0.90387\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.2152 - mae: 0.7881 - val_loss: 0.9294 - val_mae: 0.6846 - learning_rate: 5.0000e-04\n",
            "Epoch 36/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.2061 - mae: 0.7838\n",
            "Epoch 36: val_loss did not improve from 0.90387\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.2060 - mae: 0.7837 - val_loss: 0.9196 - val_mae: 0.6722 - learning_rate: 5.0000e-04\n",
            "Epoch 37/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1944 - mae: 0.7776\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.90387\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.1948 - mae: 0.7776 - val_loss: 0.9040 - val_mae: 0.6607 - learning_rate: 5.0000e-04\n",
            "Epoch 38/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1553 - mae: 0.7633\n",
            "Epoch 38: val_loss improved from 0.90387 to 0.89552, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.1556 - mae: 0.7633 - val_loss: 0.8955 - val_mae: 0.6422 - learning_rate: 2.5000e-04\n",
            "Epoch 39/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1278 - mae: 0.7570\n",
            "Epoch 39: val_loss did not improve from 0.89552\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.1283 - mae: 0.7571 - val_loss: 0.9007 - val_mae: 0.6537 - learning_rate: 2.5000e-04\n",
            "Epoch 40/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1567 - mae: 0.7617\n",
            "Epoch 40: val_loss improved from 0.89552 to 0.89454, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - loss: 1.1571 - mae: 0.7619 - val_loss: 0.8945 - val_mae: 0.6493 - learning_rate: 2.5000e-04\n",
            "Epoch 41/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1524 - mae: 0.7625\n",
            "Epoch 41: val_loss did not improve from 0.89454\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.1528 - mae: 0.7625 - val_loss: 0.8955 - val_mae: 0.6448 - learning_rate: 2.5000e-04\n",
            "Epoch 42/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1391 - mae: 0.7592\n",
            "Epoch 42: val_loss improved from 0.89454 to 0.89161, saving model to Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.1394 - mae: 0.7592 - val_loss: 0.8916 - val_mae: 0.6514 - learning_rate: 2.5000e-04\n",
            "Epoch 43/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1329 - mae: 0.7597\n",
            "Epoch 43: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.1334 - mae: 0.7597 - val_loss: 0.8937 - val_mae: 0.6462 - learning_rate: 2.5000e-04\n",
            "Epoch 44/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1209 - mae: 0.7533\n",
            "Epoch 44: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 1.1213 - mae: 0.7534 - val_loss: 0.8948 - val_mae: 0.6530 - learning_rate: 2.5000e-04\n",
            "Epoch 45/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1260 - mae: 0.7582\n",
            "Epoch 45: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 1.1263 - mae: 0.7583 - val_loss: 0.8997 - val_mae: 0.6529 - learning_rate: 2.5000e-04\n",
            "Epoch 46/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1066 - mae: 0.7500\n",
            "Epoch 46: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.1072 - mae: 0.7501 - val_loss: 0.8925 - val_mae: 0.6501 - learning_rate: 2.5000e-04\n",
            "Epoch 47/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1180 - mae: 0.7525\n",
            "Epoch 47: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.1182 - mae: 0.7526 - val_loss: 0.8986 - val_mae: 0.6435 - learning_rate: 2.5000e-04\n",
            "Epoch 48/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0985 - mae: 0.7445\n",
            "Epoch 48: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.0988 - mae: 0.7447 - val_loss: 0.8980 - val_mae: 0.6532 - learning_rate: 2.5000e-04\n",
            "Epoch 49/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1186 - mae: 0.7507\n",
            "Epoch 49: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: 1.1188 - mae: 0.7507 - val_loss: 0.9035 - val_mae: 0.6637 - learning_rate: 2.5000e-04\n",
            "Epoch 50/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0993 - mae: 0.7465\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.0997 - mae: 0.7466 - val_loss: 0.9025 - val_mae: 0.6636 - learning_rate: 2.5000e-04\n",
            "Epoch 51/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0940 - mae: 0.7474\n",
            "Epoch 51: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.0942 - mae: 0.7474 - val_loss: 0.9042 - val_mae: 0.6378 - learning_rate: 1.2500e-04\n",
            "Epoch 52/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0840 - mae: 0.7398\n",
            "Epoch 52: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.0846 - mae: 0.7400 - val_loss: 0.8944 - val_mae: 0.6409 - learning_rate: 1.2500e-04\n",
            "Epoch 53/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0615 - mae: 0.7381\n",
            "Epoch 53: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.0622 - mae: 0.7382 - val_loss: 0.9142 - val_mae: 0.6412 - learning_rate: 1.2500e-04\n",
            "Epoch 54/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0644 - mae: 0.7371\n",
            "Epoch 54: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.0647 - mae: 0.7371 - val_loss: 0.9029 - val_mae: 0.6412 - learning_rate: 1.2500e-04\n",
            "Epoch 55/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0769 - mae: 0.7394\n",
            "Epoch 55: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.0768 - mae: 0.7394 - val_loss: 0.8983 - val_mae: 0.6408 - learning_rate: 1.2500e-04\n",
            "Epoch 56/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0556 - mae: 0.7297\n",
            "Epoch 56: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.0559 - mae: 0.7299 - val_loss: 0.8998 - val_mae: 0.6417 - learning_rate: 1.2500e-04\n",
            "Epoch 57/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0621 - mae: 0.7337\n",
            "Epoch 57: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.0627 - mae: 0.7339 - val_loss: 0.8973 - val_mae: 0.6390 - learning_rate: 1.2500e-04\n",
            "Epoch 58/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0447 - mae: 0.7304\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.0449 - mae: 0.7305 - val_loss: 0.9052 - val_mae: 0.6421 - learning_rate: 1.2500e-04\n",
            "Epoch 59/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0252 - mae: 0.7214\n",
            "Epoch 59: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.0258 - mae: 0.7217 - val_loss: 0.9061 - val_mae: 0.6510 - learning_rate: 6.2500e-05\n",
            "Epoch 60/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0486 - mae: 0.7298\n",
            "Epoch 60: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 1.0489 - mae: 0.7299 - val_loss: 0.9059 - val_mae: 0.6423 - learning_rate: 6.2500e-05\n",
            "Epoch 61/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0292 - mae: 0.7246\n",
            "Epoch 61: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - loss: 1.0294 - mae: 0.7247 - val_loss: 0.8985 - val_mae: 0.6457 - learning_rate: 6.2500e-05\n",
            "Epoch 62/150\n",
            "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0343 - mae: 0.7268\n",
            "Epoch 62: val_loss did not improve from 0.89161\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - loss: 1.0345 - mae: 0.7269 - val_loss: 0.9006 - val_mae: 0.6430 - learning_rate: 6.2500e-05\n",
            "Epoch 62: early stopping\n",
            "Restoring model weights from the end of the best epoch: 42.\n",
            "\n",
            "Reloading best transformer checkpoint from: Proj3_GlobalTransformer_simple/transformer_best.keras\n",
            "\n",
            "=== Simple Global Transformer Performance (log2-MSE) ===\n",
            "  VAL  log2-MSE: 0.89161\n",
            "  TEST log2-MSE: 0.89775\n",
            "  (Comparable to MoE 0.838 — if this is lower, we win.)\n",
            "\n",
            "Saved meta scaler + indices to: Proj3_GlobalTransformer_simple/meta_scaler_and_indices.pkl\n",
            "Simple global transformer training + evaluation complete \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformer Diagnostics — True vs Predicted log₂(m-height)\n",
        "\n",
        "To better understand the global Transformer’s behavior, I plot true vs. predicted\n",
        "log₂(m-height) for both VAL and TEST splits. The diagonal line is the ideal\n",
        "`y = x`; spread away from that line indicates prediction error.\n"
      ],
      "metadata": {
        "id": "YNhZZMJXLAQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Transformer diagnostics: true vs predicted (VAL / TEST) ===\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def scatter_true_pred(true, pred, title, ax):\n",
        "    true = np.asarray(true).ravel()\n",
        "    pred = np.asarray(pred).ravel()\n",
        "    ax.scatter(true, pred, alpha=0.25, s=8)\n",
        "    lim_min = min(true.min(), pred.min())\n",
        "    lim_max = max(true.max(), pred.max())\n",
        "    ax.plot([lim_min, lim_max], [lim_min, lim_max], linestyle=\"--\")\n",
        "    ax.set_xlabel(\"True log2(m-height)\")\n",
        "    ax.set_ylabel(\"Predicted log2(m-height)\")\n",
        "    ax.set_title(title)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "scatter_true_pred(z_val, z_val_hat,\n",
        "                  \"Transformer (VAL set)\", axes[0])\n",
        "scatter_true_pred(z_te, z_te_hat,\n",
        "                  \"Transformer (TEST set)\", axes[1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "pHrLbfPdCiiq",
        "outputId": "1caeb50a-cbb9-445e-ee76-ccecc6bd05c8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MoE Ensemble vs Global Transformer — VAL/TEST log₂-MSE\n",
        "\n",
        "Here I recompute the MoE ensemble’s predictions on the same VAL/TEST splits\n",
        "used by the Transformer, and compare their log₂-MSE. The bar chart summarizes\n",
        "which model is better for grading (lower is better), and supports my choice of\n",
        "the SVD-64 MoE ensemble as the final submitted model.\n"
      ],
      "metadata": {
        "id": "ciCuTB8rLKFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === MoE ensemble vs Transformer: VAL/TEST comparison ===\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import pickle, os\n",
        "\n",
        "def mse_np(a, b):\n",
        "    a = np.asarray(a).ravel()\n",
        "    b = np.asarray(b).ravel()\n",
        "    return float(np.mean((a - b) ** 2))\n",
        "\n",
        "# Sanity: we assume these are already defined from earlier phases:\n",
        "# - SAVE_ROOT (e.g., \"Proj3_SVD64_GlobalAug\")\n",
        "# - ARTIFACTS (per-(k,m) model info)\n",
        "# - CLEAN_SPLITS (per-(k,m) val/test indices)\n",
        "# - ALL_FEATURES, z_arr\n",
        "# - train_idx, val_idx, test_idx (global)\n",
        "\n",
        "print(\"Recomputing MoE ensemble predictions on VAL/TEST ...\")\n",
        "\n",
        "# Build index → position maps so we can align to (z_val, z_te)\n",
        "idx_to_pos_val = {int(i): pos for pos, i in enumerate(val_idx)}\n",
        "idx_to_pos_te  = {int(i): pos for pos, i in enumerate(test_idx)}\n",
        "\n",
        "# Allocate arrays\n",
        "z_val_moe = np.zeros_like(z_val, dtype=np.float32)\n",
        "z_te_moe  = np.zeros_like(z_te,  dtype=np.float32)\n",
        "\n",
        "for (k, m), art in sorted(ARTIFACTS.items()):\n",
        "    splits = CLEAN_SPLITS[(k, m)]\n",
        "    val_idx_pair = np.asarray(splits[\"val\"], dtype=np.int64)\n",
        "    test_idx_pair = np.asarray(splits[\"test\"], dtype=np.int64)\n",
        "\n",
        "    # Load scaler + calibration\n",
        "    with open(art[\"scaler_X\"], \"rb\") as f:\n",
        "        sx = pickle.load(f)\n",
        "    with open(art[\"calib\"], \"rb\") as f:\n",
        "        calib = pickle.load(f)\n",
        "    a_cal, b_cal = float(calib[\"a\"]), float(calib[\"b\"])\n",
        "\n",
        "    # Helper to ensemble-predict for a given index set\n",
        "    def ensemble_predict(idx_array):\n",
        "        if idx_array.size == 0:\n",
        "            return np.array([], dtype=np.float32)\n",
        "        X = ALL_FEATURES[idx_array].astype(np.float32)\n",
        "        Xs = sx.transform(X)\n",
        "        preds = []\n",
        "        i = 1\n",
        "        while True:\n",
        "            mp = os.path.join(SAVE_ROOT, f\"k{k}_m{m}\", f\"model_{i}.keras\")\n",
        "            if not os.path.exists(mp):\n",
        "                break\n",
        "            model = keras.models.load_model(mp)\n",
        "            preds.append(model.predict(Xs, verbose=0).ravel())\n",
        "            i += 1\n",
        "        if not preds:\n",
        "            return np.zeros(idx_array.shape[0], dtype=np.float32)\n",
        "        z_hat = np.mean(preds, axis=0)\n",
        "        z_hat_cal = a_cal * z_hat + b_cal\n",
        "        return z_hat_cal.astype(np.float32)\n",
        "\n",
        "    # VAL predictions for this (k,m)\n",
        "    if val_idx_pair.size > 0:\n",
        "        z_val_hat_pair = ensemble_predict(val_idx_pair)\n",
        "        for gi, zh in zip(val_idx_pair, z_val_hat_pair):\n",
        "            pos = idx_to_pos_val[int(gi)]\n",
        "            z_val_moe[pos] = zh\n",
        "\n",
        "    # TEST predictions for this (k,m)\n",
        "    if test_idx_pair.size > 0:\n",
        "        z_te_hat_pair = ensemble_predict(test_idx_pair)\n",
        "        for gi, zh in zip(test_idx_pair, z_te_hat_pair):\n",
        "            pos = idx_to_pos_te[int(gi)]\n",
        "            z_te_moe[pos] = zh\n",
        "\n",
        "# --- Compute metrics ---\n",
        "moe_val_mse  = mse_np(z_val, z_val_moe)\n",
        "moe_test_mse = mse_np(z_te,  z_te_moe)\n",
        "\n",
        "trans_val_mse  = mse_np(z_val, z_val_hat)\n",
        "trans_test_mse = mse_np(z_te,  z_te_hat)\n",
        "\n",
        "print(\"\\n=== Global Comparison (log2-MSE) ===\")\n",
        "print(f\"MoE ensemble     — VAL:  {moe_val_mse:.5f} | TEST: {moe_test_mse:.5f}\")\n",
        "print(f\"Transformer (global) — VAL:  {trans_val_mse:.5f} | TEST: {trans_test_mse:.5f}\")\n",
        "\n",
        "# --- Bar plot: MoE vs Transformer on VAL/TEST ---\n",
        "labels = [\"VAL\", \"TEST\"]\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "moe_vals  = [moe_val_mse,  moe_test_mse]\n",
        "trans_vals = [trans_val_mse, trans_test_mse]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "ax.bar(x - width/2, moe_vals,  width, label=\"MoE Ensemble\")\n",
        "ax.bar(x + width/2, trans_vals, width, label=\"Transformer\")\n",
        "\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_ylabel(\"log2-MSE\")\n",
        "ax.set_title(\"MoE Ensemble vs Global Transformer (Project 3)\")\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "i4YUB8gGK8Q7",
        "outputId": "8de54ac4-7513-4691-e1ed-c48505509b13"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recomputing MoE ensemble predictions on VAL/TEST ...\n",
            "\n",
            "=== Global Comparison (log2-MSE) ===\n",
            "MoE ensemble     — VAL:  0.84163 | TEST: 0.83845\n",
            "Transformer (global) — VAL:  0.89161 | TEST: 0.89775\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGGCAYAAACNCg6xAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARxNJREFUeJzt3XdUFNffBvBnQdgFaSJNkAhWRAUiCMEeg2JDTTSgJgpYY4mFRCMWwIrGhiYqxh5jQYw/o9FgQU2sMdbEXgk2QCyAIkV23j98mbjuggMCi/J8ztlz3Dt3Zr6zzu4+zNyZlQmCIICIiIiIXktH2wUQERERvS0YnIiIiIgkYnAiIiIikojBiYiIiEgiBiciIiIiiRiciIiIiCRicCIiIiKSiMGJiIiISCIGJyIiIiKJGJyIysCBAwcgk8mwefPm1/YNCgqCg4ND6RelRa1bt0br1q2LPF9CQgJkMhnmzJlTYrWsXr0aMpkMCQkJJbbM8iIuLg5ubm5QKBSQyWR4/PixtksqE5s2bYK5uTmePHlS5ut+W/enBw8eoHLlyti5c6e2Syn3GJwqiPw3s0wmw6FDh9SmC4IAe3t7yGQydO7cuVjrcHBwENfx6qN9+/aFzpsfLAp6bNy4sVg1Udk5ePAg/P39YWdnB319fZiamsLLywtTpkxBcnKytssrtvywJuVRnr4sHzx4AH9/fxgYGGDRokVYu3YtKleurO2ySl1eXh7Cw8Px5ZdfwsjISGx/9fPJysoKLVq0wP/+9z8tVlt0R44cQUREhOQQ/L///Q++vr6wtbWFXC5H9erV0aNHD5w7d06lX9WqVTFgwABMmjSpFKp+t1TSdgFUthQKBdavX4/mzZurtP/++++4ffs25HL5Gy3fzc0NX331lVq7ra2tpPlHjBiBJk2aqLV7e3u/UV1UusLCwjB16lTUrFkTQUFBqFmzJrKysnDy5EnMnTsXa9aswfXr17VdZrFYWlpi7dq1Km1z587F7du3MX/+fLW+5cVff/2FjIwMTJ06FT4+Ptoup8xs374dly9fxqBBg9Smvfz5dPfuXSxduhSffPIJlixZgi+++KJE1t+nTx/07NnzjT9LC3LkyBFMnjwZQUFBMDMze23/f/75B1WqVMHIkSNhYWGBpKQkrFy5Ep6enjh69ChcXV3Fvl988QUWLlyIffv2oU2bNqVS/7uAwamC6dixI2JjY7Fw4UJUqvTff//69evh7u6O1NTUN1q+nZ0dPv/882LP36JFC/To0eONaqCyFRMTg6lTp8Lf3x9r166Fvr6+yvT58+erBYy3SeXKldX26Y0bN+LRo0eF7uuCICArKwsGBgalXaJGKSkpACDpy1Wqp0+fav2o1etqWLVqFZo1awY7Ozu1aa9+PvXt2xe1a9fG/PnzCwxOz58/h1KpVNuvC6KrqwtdXV1JfctCWFiYWtuAAQNQvXp1LFmyBNHR0WJ7/fr10bBhQ6xevZrBqRA8VVfB9OrVCw8ePMCePXvEtpycHGzevBm9e/fWOM/Tp0/x1Vdfwd7eHnK5HPXq1cOcOXMgCEJZla1CJpNh+PDh2Lp1Kxo2bAi5XI4GDRogLi5OpV9GRgZGjRoFBwcHyOVyWFlZoW3btjh16pRKvz///BPt27eHqakpDA0N0apVKxw+fFilT0REBGQyGa5cuYLPP/8cpqamsLS0xKRJkyAIAm7duoWuXbvCxMQENjY2mDt3rsba8/LyMH78eNjY2KBy5cro0qULbt269dptViqViIqKQoMGDaBQKGBtbY3Bgwfj0aNHhc43Z84cyGQy/Pvvv2rTQkNDoa+vLy7j6tWr6N69O2xsbKBQKFC9enX07NkTaWlpha4jLCwMFhYWWLFihcYvF1NTU0RERLx2G1NSUtC/f39YW1tDoVDA1dUVa9asKbD//PnzUaNGDRgYGKBVq1Zqpx7+/vtv8eiXQqGAjY0N+vXrhwcPHry2luJwcHBA586dsWvXLnh4eMDAwABLly4F8OLLvE2bNrCysoJcLoezszOWLFlS4DIOHToET09PKBQK1KxZEz/++KNKv9zcXEyePBl16tSBQqFA1apV0bx5c/F93bp1awQGBgIAmjRpAplMhqCgIHH+2NhYuLu7w8DAABYWFvj8889x584dlXUEBQXByMgI169fR8eOHWFsbIzPPvsMwH/vwdjYWDg7O8PAwADe3t74559/AABLly5F7dq1oVAo0Lp1a42nMIvyvrtw4QJ69+6NKlWqqB0tf1lWVhbi4uIkH2GzsbFB/fr1cfPmTQCqY+iioqJQq1YtyOVyXLhwAQCwb98+tGjRApUrV4aZmRm6du2KixcvqiyzoDFOv/32mzivsbExOnXqhPPnz6vVdOnSJfj7+8PS0hIGBgaoV68eJkyYIL4eY8aMAQA4OjoW+xSxlZUVDA0NNZ7ua9u2LbZv3661z/e3AY84VTAODg7w9vbGhg0b0KFDBwAv3tBpaWno2bMnFi5cqNJfEAR06dIF+/fvR//+/eHm5oZdu3ZhzJgxuHPnjtqRhNzcXI1HrSpXrizpL++MjAyN81etWhUymUx8fujQIWzZsgVDhw6FsbExFi5ciO7duyMxMRFVq1YF8OKw8+bNmzF8+HA4OzvjwYMHOHToEC5evIjGjRsDePFB2KFDB7i7uyM8PBw6Ojril9zBgwfh6empUkdAQADq16+PmTNnYseOHZg2bRrMzc2xdOlStGnTBrNmzcK6devw9ddfo0mTJmjZsqXK/NOnT4dMJsM333yDlJQUREVFwcfHB2fOnCn09Rk8eDBWr16N4OBgjBgxAjdv3sT333+P06dP4/Dhw9DT09M4n7+/P8aOHYtNmzaJH7j5Nm3ahHbt2qFKlSrIycmBr68vsrOz8eWXX8LGxgZ37tzBr7/+isePH8PU1FTj8q9cuYIrV65gwIABKuNJiurZs2do3bo1rl27huHDh8PR0RGxsbEICgrC48ePMXLkSJX+P/74IzIyMjBs2DBkZWVhwYIFaNOmDf755x9YW1sDAPbs2YMbN24gODgYNjY2OH/+PH744QecP38ex44dU9mfSsrly5fRq1cvDB48GAMHDkS9evUAAEuWLEGDBg3QpUsXVKpUCdu3b8fQoUOhVCoxbNgwlWVcu3YNPXr0QP/+/REYGIiVK1ciKCgI7u7uaNCgAYAXX6CRkZEYMGAAPD09kZ6ejhMnTuDUqVNo27YtJkyYgHr16uGHH37AlClT4OjoiFq1agGAuB81adIEkZGRSE5OxoIFC3D48GGcPn1a5QjV8+fP4evri+bNm2POnDkwNDQUpx08eBDbtm0T64+MjETnzp0xduxYLF68GEOHDsWjR4/w7bffol+/fti3b584b1Hfd59++inq1KmDGTNmFPqFfvLkSeTk5Ijv79fJzc3FrVu3xM+MfKtWrUJWVhYGDRoEuVwOc3Nz7N27Fx06dEDNmjURERGBZ8+e4bvvvkOzZs1w6tSpQi/oWLt2LQIDA+Hr64tZs2YhMzMTS5YsQfPmzXH69Glx3r///hstWrSAnp4eBg0aBAcHB1y/fh3bt2/H9OnT8cknn+DKlSvYsGED5s+fDwsLCwDSThE/fvwYubm5SEpKQlRUFNLT0/HRRx+p9XN3d8f8+fNx/vx5NGzYUNLrWOEIVCGsWrVKACD89ddfwvfffy8YGxsLmZmZgiAIwqeffip8+OGHgiAIQo0aNYROnTqJ823dulUAIEybNk1leT169BBkMplw7do1sa1GjRoCAI2PyMjIQuvbv39/gfMCEO7duyf2BSDo6+urrPvs2bMCAOG7774T20xNTYVhw4YVuE6lUinUqVNH8PX1FZRKpdiemZkpODo6Cm3bthXbwsPDBQDCoEGDxLbnz58L1atXF2QymTBz5kyx/dGjR4KBgYEQGBiotn12dnZCenq62L5p0yYBgLBgwQKxLTAwUKhRo4b4/ODBgwIAYd26dSr1x8XFaWx/lbe3t+Du7q7Sdvz4cQGA8OOPPwqCIAinT58WAAixsbGFLutVv/zyiwBAiIqKUmlXKpXC/fv3VR65ubni9FatWgmtWrUSn0dFRQkAhJ9++klsy8nJEby9vQUjIyPxNbt586YAQDAwMBBu374t9v3zzz8FAMLo0aPFtvz9+2UbNmwQAAh//PGH2Jb/3rh586bk7e7UqZPK/5Eg/Lf/x8XFqfXXVIuvr69Qs2ZNjct4ub6UlBRBLpcLX331ldjm6uqq8j7V5OX3fL6cnBzByspKaNiwofDs2TOx/ddffxUACGFhYWJbYGCgAEAYN26c2rIBCHK5XOU1W7p0qQBAsLGxUdnHQ0NDVV7f4rzvevXqVei25lu+fLkAQPjnn3/UptWoUUNo166duD+ePXtW6NmzpwBA+PLLLwVB+G//MjExEVJSUlTmd3NzE6ysrIQHDx6IbWfPnhV0dHSEvn37im2v7k8ZGRmCmZmZMHDgQJXlJSUlCaampirtLVu2FIyNjYV///1Xpe/Lr9Ps2bOLvL8KgiDUq1dP/Dw1MjISJk6cKOTl5an1O3LkiABAiImJKdLyKxKeqquA/P398ezZM/z666/IyMjAr7/+WuBpup07d0JXVxcjRoxQaf/qq68gCAJ+++03lXYvLy/s2bNH7dGrVy9JtYWFhWmc39zcXKWfj4+P+Bc0ALi4uMDExAQ3btwQ28zMzPDnn3/i7t27Gtd15swZXL16Fb1798aDBw+QmpqK1NRUPH36FB999BH++OMPKJVKlXkGDBgg/ltXVxceHh4QBAH9+/dXWW+9evVUasnXt29fGBsbi8979OiBatWqFXoJcGxsLExNTdG2bVuxxtTUVLi7u8PIyAj79+8vcF7gxVGykydPqgzOjomJgVwuR9euXQFAPKK0a9cuZGZmFrq8l6WnpwOA2tGmtLQ0WFpaqjzOnDlT4HJ27twJGxsblf1ET08PI0aMwJMnT/D777+r9O/WrZvKGBZPT094eXmpvI4vH8HLyspCamoqPvjgAwBQO11bUhwdHeHr66vW/nItaWlpSE1NRatWrXDjxg21U6HOzs5o0aKF+NzS0lJtfzIzM8P58+dx9erVItV34sQJpKSkYOjQoVAoFGJ7p06d4OTkhB07dqjNM2TIEI3L+uijj1SOsnh5eQEAunfvrrKP57fn11+c953Ugdv5p2GrVKmicfru3bvF/dHV1RWxsbHo06cPZs2apdKve/fuKkdx7t27hzNnziAoKEjls8jFxQVt27Yt9P27Z88ePH78GL169VJ5/+rq6sLLy0t8/96/fx9//PEH+vXrh/fee09lGSVxdHTVqlWIi4vD4sWLUb9+fTx79gx5eXlq/fJfuzcd7/ou46m6CsjS0hI+Pj5Yv349MjMzkZeXV+CA7H///Re2trYqH4TAi0GE+dNfZmFh8UZX8DRq1EjS/K9+sAAv3vAvj/n59ttvERgYCHt7e7i7u6Njx47o27cvatasCQDil07+WBBN0tLSVD6EX12vqakpFAqFeMj85XZNY2nq1Kmj8lwmk6F27dqFjlG4evUq0tLSYGVlpXF6/iDggnz66acICQlBTEwMxo8fD0EQEBsbiw4dOsDExATAiy/8kJAQzJs3D+vWrUOLFi3QpUsXcTxXQfL3i1fvl2NkZCSOt9m9ezdmz55daI3//vsv6tSpAx0d1b/lCtrPXn0dAaBu3brYtGmT+Pzhw4eYPHkyNm7cqPYavW7cVnE5OjpqbD98+DDCw8Nx9OhRtWCalpam8hpL2benTJmCrl27om7dumjYsCHat2+PPn36wMXFpdD68l/H/FOIL3NyclK7VUmlSpVQvXp1jcvS9F4AAHt7e43tL4+lA4r2vivodS2IUMDpPC8vL0ybNg0ymQyGhoaoX7++xsHzr66vsNetfv362LVrV4GD1vO3t6DB1vnvwfxgWVqnx16+Mrlnz57ie+vVe6Llv3alcSr7XcHgVEH17t0bAwcORFJSEjp06FCiV96UhYKuWnn5A9Pf31+8T0v+l/esWbOwZcsWdOjQQfyrdvbs2XBzc9O4vFePpGhar5Ra3oRSqYSVlRXWrVuncfrrxjfY2tqiRYsW2LRpE8aPH49jx44hMTFR7a/suXPnIigoCL/88gt2796NESNGIDIyEseOHSvwy9PJyQkA1AZmV6pUSQzAt2/flrSdJc3f3x9HjhzBmDFj4ObmBiMjIyiVSrRv317tiEZJ0TRO7fr16/joo4/g5OSEefPmwd7eHvr6+ti5cyfmz5+vVouU/ally5a4fv26+H+1fPlyzJ8/H9HR0SpHRd+UXC5XC7Ovq/N19RfnfSf1ysT8sUqPHj3SuM9K/cOuJK+EzN/etWvXwsbGRm36y1c3l5UqVaqgTZs2WLdunVpwyg+4r/4xSP9hcKqgPv74YwwePBjHjh1DTExMgf1q1KiBvXv3IiMjQ+Wo06VLl8Tp5Vm1atUwdOhQDB06FCkpKWjcuDGmT5+ODh06iKf6TExMyuw+N6+eWhEEAdeuXSv0SEGtWrWwd+9eNGvWrNgf6AEBARg6dCguX76MmJgYGBoaws/PT61fo0aN0KhRI0ycOBFHjhxBs2bNEB0djWnTpmlcbr169VCnTh1s3boVUVFRxb5UvUaNGvj777+hVCpVvqgL2s80naK6cuWKeOro0aNHiI+Px+TJk1Uuxy7qqa2SsH37dmRnZ2Pbtm0qR2led4r1dczNzREcHIzg4GA8efIELVu2RERERKHBKf91vHz5stoRkMuXL5fJ+7k033f5Qf7mzZto1KhRiS335dftVZcuXYKFhUWB+37+9lpZWRW6vflHwl/9I+RVJXUk6NmzZxqPvOZfYZh/RIrUcYxTBWVkZIQlS5YgIiJC4xdovo4dOyIvLw/ff/+9Svv8+fMhk8nEK/PKm7y8PLUPBSsrK9ja2iI7OxvAi6tHatWqhTlz5mj8aYb79++XeF35V4Pl27x5M+7du1fo6+jv74+8vDxMnTpVbdrz588l3UG4e/fu0NXVxYYNGxAbG4vOnTurfNCnp6fj+fPnKvM0atQIOjo64utVkIiICKSmpmLgwIHIzc1Vmy7lyFvHjh2RlJSkEuKfP3+O7777DkZGRmjVqpVK/61bt6pcPn/8+HH8+eef4uuYf9Tj1XVHRUW9tpaSpqmWtLQ0rFq1qtjLfPU0sJGREWrXrv3a/ysPDw9YWVkhOjpape9vv/2GixcvolOnTsWuSarSfN+5u7tDX18fJ06ceJMS1VSrVg1ubm5Ys2aNyvvt3Llz2L17Nzp27FjgvL6+vjAxMcGMGTM0vj/yt9fS0hItW7bEypUrkZiYqNLn5X0n/30r9c7hmk7lJyQkID4+Hh4eHmrTTp48CVNTU/EKTlLHI04VWGFjDPL5+fnhww8/xIQJE5CQkABXV1fs3r0bv/zyC0aNGqUyQBsA7ty5g59++kltOUZGRujWrdtr13fw4EFkZWWptbu4uLx2/MbLMjIyxJ8WcHV1hZGREfbu3Yu//vpLvMeSjo4Oli9fjg4dOqBBgwYIDg6GnZ0d7ty5g/3798PExATbt2+XvE4pzM3N0bx5cwQHByM5ORlRUVGoXbs2Bg4cWOA8rVq1wuDBgxEZGYkzZ86gXbt20NPTw9WrVxEbG4sFCxa89qahVlZW+PDDDzFv3jxkZGQgICBAZfq+ffswfPhwfPrpp6hbty6eP3+OtWvXQldXF927dy902b1798a5c+cQGRmJ48ePo2fPnnB0dMTTp09x7tw5bNiwAcbGxgUO2AWAQYMGYenSpQgKCsLJkyfh4OCAzZs34/Dhw4iKilIbY1e7dm00b94cQ4YMQXZ2NqKiolC1alWMHTsWwIujGS1btsS3336L3Nxc2NnZYffu3eJf02WpXbt20NfXh5+fHwYPHownT55g2bJlsLKywr1794q1TGdnZ7Ru3Rru7u4wNzfHiRMnxFtvFEZPTw+zZs1CcHAwWrVqhV69eom3I3BwcMDo0aOLVU9RlOb7TqFQoF27dti7dy+mTJlSonXPnj0bHTp0gLe3N/r37y/ejuB19ykzMTHBkiVL0KdPHzRu3Bg9e/aEpaUlEhMTsWPHDjRr1kz8w3ThwoVo3rw5GjdujEGDBsHR0REJCQnYsWOHeHGFu7s7AGDChAno2bMn9PT04OfnV+ARr0aNGuGjjz6Cm5sbqlSpgqtXr2LFihXIzc3FzJkz1frv2bMHfn5+HONUGG1cykdlT9OlyZq8ejsCQXhxOe3o0aMFW1tbQU9PT6hTp44we/ZslUtk8+dFAbcTePXS7Ve97nYE4eHhYl8AGm8zUKNGDfEWANnZ2cKYMWMEV1dXwdjYWKhcubLg6uoqLF68WG2+06dPC5988olQtWpVQS6XCzVq1BD8/f2F+Ph4sU/+ZdH3799XmTcwMFCoXLmy2jJbtWolNGjQQG37NmzYIISGhgpWVlaCgYGB0KlTJ7VLj1+9HUG+H374QXB3dxcMDAwEY2NjoVGjRsLYsWOFu3fvanxNX7Vs2TIBgGBsbKxyKbogCMKNGzeEfv36CbVq1RIUCoVgbm4ufPjhh8LevXslLVsQBOHAgQNCjx49hGrVqgl6enqCiYmJ4OHhIYSHh6vcTkIQ1G9HIAiCkJycLAQHBwsWFhaCvr6+0KhRI2HVqlUqffIvF589e7Ywd+5cwd7eXpDL5UKLFi2Es2fPqvS9ffu28PHHHwtmZmaCqamp8Omnnwp3795V259K8nYEBd0iYNu2bYKLi4ugUCgEBwcHYdasWcLKlSvV1lvQMl59vaZNmyZ4enoKZmZmgoGBgeDk5CRMnz5dyMnJUdsuTe/5mJgY4f333xfkcrlgbm4ufPbZZyq3dxCEgvdtQdD8Hnz5/+Zl+fv+q7e6eJP3XWG2bNkiyGQyITExUaW9sP+f121Dvr179wrNmjUTDAwMBBMTE8HPz0+4cOGCSp+C9qf9+/cLvr6+gqmpqaBQKIRatWoJQUFBwokTJ1T6nTt3TtxvFQqFUK9ePWHSpEkqfaZOnSrY2dkJOjo6r913w8PDBQ8PD6FKlSpCpUqVBFtbW6Fnz57C33//rdb34sWLAoAive8rIpkg8PagRET0bsjLy4OzszP8/f01nt4ubStWrMCAAQNw69atAi+qKK9GjRqFP/74AydPnuQRp0JwjBMREb0zdHV1MWXKFCxatEjjGKrSdu/ePchkMrV7z5V3Dx48wPLly8XbNVDBeMSJiIjoDSUnJ2Pz5s2IjIxEjRo11H53j94dPOJERET0hi5evIgxY8agdu3aWL16tbbLoVLEI05EREREEvGIExEREZFEDE5EREREElW4G2AqlUrcvXsXxsbGvHKAiIiIIAgCMjIyYGtrW+DvM+arcMHp7t27ar/eTURERCTl/lsVLjjl/3TDrVu3YGJiouVqiIiISNvS09Nhb2+v9vNOmlS44JR/es7ExITBiYiIiERShvBwcDgRERGRRAxORERERBIxOBERERFJVOHGOBERUfmnVCqRk5Oj7TLoHaGnpwddXd0SWRaDExERlSs5OTm4efMmlEqltkuhd4iZmRlsbGze+B6ODE5ERFRuCIKAe/fuQVdXF/b29q+9GSHR6wiCgMzMTKSkpAAAqlWr9kbLY3AiIqJy4/nz58jMzIStrS0MDQ21XQ69IwwMDAAAKSkpsLKyeqPTdozyRERUbuTl5QEA9PX1tVwJvWvyg3hubu4bLYfBiYiIyh3+liiVtJLapxiciIiIiCRicCIiIiKtioiIgJubW6F9goKC0K1btzKppzAcHE5EROWew7gdZbq+hJmditQ/KCgIa9asweDBgxEdHa0ybdiwYVi8eDECAwOxevVqaetPSICjo6PGaUePHsUHH3ygcVpBp6M2bNiAnj17Slo3FY7BiYiIqATY29tj48aNmD9/vngVV1ZWFtavX4/33nuvWMvcu3cvGjRooNJWtWrVQudZtWoV2rdvr9JmZmZWrPWTOp6qIyIiep27pwt/ZD5EY+dasK9miS0r5ontW1bMw3vVLPF+/ZpA5kOxPfvmnxjRvxesLMyhUMjR3PN9/LXzp/+Wl3weAFA17z5slPdUHnr3zxVcBwAz5UO1eRQPLwJ3T2P1/MkwMzXGrvWLUL+OI4wqG6L9h01x7/RucRkHNi+D5/sNUdnQAGamxmjWxA3/Ht8hTv9l1Xw0blQfCoUcNWtUx+Svv8DzxL/E6TKZDEtnTUBnnxYwNDBA/TqOOLptNa4d/gWtm3qgsqEBmnq44vqRbf/VnXEPyH2GpbMmwN7WBoYGBvD3a4e0S3+obNvLlEolIiMj4ejoCAMDA7i6umLz5s2lviswOBEREZWQfgFdsCpmm/h85cZfEBzQRa3f2OkL8PPOeKyJmoJTcetR28Eevp8Nw8NHaaVeY+azLMyJXou1C6fhjy3LkXgnCV9PjQLw4j5a3fqHoNUHjfH33hgc3bYagz77RDwFePDPU+g7Mgwj+/fChf2bsXTWBKzetB3TF65QWcfUqOXo26MzzuzeAKfajug9fAIGfzMdocODceK3nyAIAoZPnKUyz7WEW9i0fQ+2r45C3LrvcPrcJQwdP7PA7YiMjMSPP/6I6OhonD9/HqNHj8bnn3+O33//vWRfsFfwVB29myJMtV0BRZT+FwBRefN5904Infk9/r19FwBw+MRZbFwSiQNHT4p9nmY+w5IfY7F6/mR0aNMMALBs9kTs+eAYVmzcijFDAsW+TbsGQ0dHddzSk6uHC62h17Dx0H3ljusXDmzGe3Yv7pidm/sc0TPHo5aDPQBgeFAApkQtAwCkZzxFWvoTdPZpKU6vX6emuJzJ837AuGFBCPT3AwDUrFEdU8cMwdjpCxAeMljsFxzQBf5d2gEAvhkaCO8uQZg0agB8WzcFAIwc0BvBIREqNWZl5+DHBVNhV80KAPDdtLHo1Hck5oaNho2VhUrf7OxszJgxA3v37oW3t/eLWmrWxKFDh7B06VK0atWq0NfoTTA4ERERlRDLqlXQ6aPmWL1pOwRBQKc2zWFhXkWlz/WEW8jNfY5mTVzFNj09PXi6NcTFqzdV+sYsiUT9OpoHiRdkfvhX8GnhqdJma20p/tvQQCGGIgCoZm2BlNSHAADzKqYI8veD72fD0LaFF3xaeMHfry2q/f/8Zy9cweETZ1WOMOUplcjKykbms2cw/P+xXS7164jTrS1fjMlq5PRSm4U5srKykZ7xBCbGRgCA9+xsxNAEAN7uLlAqlbh8/V+14HTt2jVkZmaibdu2Ku05OTl4//33pb5UxcLgREREVIL6BXQVT0Mtmj7ujZZlb2uD2o5FG1huY1W10Hn09FS/+mUyGQRBEJ+vmj8ZI/r3Qtz+I4jZthsTv12MPRsW4wN3FzzJfIbJXw3GJx3aqC1XIZdrXEf+aT69SuptSuV/6y2KJ0+eAAB27NgBOzs7lWnyl+ooDQxOREREJaj9h02Rk5sLGWTwbe2tNr2Wgz309fVw+K+zqFHdFsCLnwH568x5jBrYu6zL1ej9hk54v6ETQr/sB2+/QKzfGocP3F3QuKETLl//t8hhTorEO0m4m3QftjYvjm4dO/UPdHR0UK9WDbW+zs7OkMvlSExMLNXTcpowOBEREZUgXV1dXDzws/jvV1U2NMCQPj0wZloUzM1M8J5dNXy7eA0ys7LQv2c3lb4PHj1GUkqqSpuZiTEUioKPqjxOy1Cbx9ioMiobGry29puJd/DDui3o0rYlbG0scfn6v7h68xb69ugMAAgbPRCdA0fhPTsb9OjkAx0dGc5euIpzl65h2jfDXrv8wijk+ggcFYY5k0Yj/ckTjJg0G/5+bdVO0wGAsbExvv76a4wePRpKpRLNmzdHWloaDh8+DBMTEwQGBmpYQ8lgcCIiIiph+eN2CjJz/AgoBQF9RkxCxtNMeLg4Y9e6RahiZqLSz6fnELV5NyyORM+uvgUu+9VB1wAQGfolxg0Pfm3dhgYKXLqWgDWx2/HgURqqWVlgWNCnGNynOwDAt3VT/LomClPmL8OsRWugp1cJTrUdMKBXt9cu+3VqO9jjkw5t0LHvl3j4OB2dP2qBxTNCC+w/depUWFpaIjIyEjdu3ICZmRkaN26M8ePHv3EthZEJL5/YrADS09NhamqKtLQ0mJiYvH4Gejvxqjrt41V1VAxZWVm4efMmHB0doVAotF3OfzTcR4jKmO2bDfoubN8qSjbgfZyIiIiIJGJwIiIiIpKIwYmIiIhIIgYnIiIiIokYnIiIiIgkYnAiIiIikojBiYiIiEgiBiciIiIiiRiciIiIiCRicCIiInoHJaWkom3PIahcuynM6rfUdjnvDP5WXSlwGLdD2yVUeAnl6JcaiKgElPXPKBXhJ4Nkdo0LnR4eMggRX33xphUV2fxl63AvJRVndm+EqUnhv51H0jE4ERGVcxXpjzE7Y11EfGiFHIN0yCplie0uZVzH37cfqzx3KeT8zL3Tu8V/x2zbjbA50bj8xxaxzaiyofhvQRCQl5eHSpVK/+v3esJtuDeqjzo13yv2MnJycqGvr1eCVRUuNzcXenplt77i4Kk6IiKiN2BjZSE+TI2NIJP913bpWgKM6zbHb/sOw719b8gdvXDo+BlcT7iFrsGjYe3qA6M6zdCk4+fY+8efKst18OqEGQtXoF9IBIzrNsd7TTrih59+Fqfn5ORi+ISZqPZ+OyhqfoAanh0R+d1Kcd6fd8bjx82/QmbXGEGjwgEAiXfuoWvwaBjVaQaTei3gP/gbJN9/IC4zYm403Nr2xPL1/4PjB52hqPkBgBdH1Zau3YzOfUfAsFZT1G/1CY6eOItrNxPRusdAVK7dFE27BOF6wi2Vbfhl1wE09u0NRc0PUNPbD5PnLcXz58/F6TK7xliyJhZdgkahcu2mmL5wRYn+35QGBiciIqJSNm7GQswcPwIXD/wMl/p18OTpM3Rs0wzxMdE4vWsD2rduCr/gUUi8c09lvrlLf4KHizNO71qPoYGfYkhoJC5fSwAALFy5Adt2/4FN0TNx+Y8tWPf9dDjY2wIA/tr5E9p/2BT+fm1x7/RuLJjyNZRKJboGh+Dh4zT8/vMy7NmwGDcSbyNgyDiVdV5LuIWfd8Zjy/I5OLN7g9g+NWo5+vbojDO7N8CptiN6D5+Awd9MR+jwYJz47ScIgoDhE2eJ/Q/+eQp9R4ZhZP9euLB/M5bOmoDVm7arhaOIeUvxcYcP8U/8JvTr2bUkX/ZSwVN1REREpWzKmCFo2/ID8bl5FVO4NqgrPp86dij+F7cf23b/juHBPcX2jm2aYWiQPwDgm2FBmL9sHfYfOYF6tR2QeCcJdRzt0dzzfchkMtSobivOZ1m1CuT6+jBQKGBjZQEA2PPHMfxz6RpuHt0OezsbAMCPC6aiwYc98NeZ82ji1gAAkJObix8XTIVl1Soq2xAc0AX+Xdq9qGVoILy7BGHSqAHwbd0UADByQG8Eh0SI/SfP+wHjhgUh0N8PAFCzRnVMHTMEY6cvQHjIYLFf727tERxQ/gNTPgYnIiKiUubh4qzy/MnTTETMXYod8QdxLyUVz5/n4VlWNhLvJKn0c3GuI/5bJpPBxrIqUh48BAAE+fuhbc+hqNfiY7T/sCk6+7RAu1beBdZw8epN2Ntai6EJAJzr1oSZqTEuXr0pBqcadtXUQhMAuNT/rxZry6oAgEZOL7VZmCMrKxvpGU9gYmyEsxeu4PCJsypHmPKUSmRlZSPz2TMYGhi8eG1cVV+b8o7BiYiIqJRVNjRQef71lPnYc/BPzJk0CrUd7GGgkKPHoLHIyclV6af3yiBymUwGpVIJAGjcqD5uHtuO3/Ydxt5Dx+H/xTfwae6Fzctml2itYi16/9Uik8nU6stvUyoFAMCTzGeY/NVgfNKhjdqyFHL5a9dXXjE4ERERlbHDJ84i6FM/fPz/oeLJ00wk3L4LwL1IyzExNkJAV18EdPVFj04fof1nw/HwURrMq6jfvqF+HUfcupuMW3eSxKNOF67cwOO0DDjXrfnG2/Sqxg2dcPn6v6jtWPyr+sojBiciIqIyVsfRHlt+2we/ti0hk8kwafZi8UiNVPOW/oRq1hZ4v2E96Mh0EPvrXthYWcDM1Fhjf58WXmjkVBuffTkBUZO/xvPneRg6PhKtvN1L5XRZ2OiB6Bw4Cu/Z2aBHJx/o6Mhw9sJVnLt0DdO+GVbi6ysrvKqOiIiojM0L/wpVTI3RtGsw/IJGwbe1Nxo3cirSMoyNDPHt4jXw6PA5mnTqg4Rbd7Fz7ULo6Gj+apfJZPhl1TxUMTVBy08GwKfnENR8rzpilswsiU1S49u6KX5dE4Xdvx9Dk4598IHfi8HtNapXK5X1lRWZIAhFi7glbNGiRZg9ezaSkpLg6uqK7777Dp6engX2j4qKwpIlS5CYmAgLCwv06NEDkZGRUCik3So6PT0dpqamSEtLg4mJSUlthoqKdLO68ipB0VvbJVAR7rxMhatInyn5N8C0sq0OWSV9bZcjctG5qe0SyPb9N5o9KysLN2/ehKOjo1pmKEo20OoRp5iYGISEhCA8PBynTp2Cq6srfH19kZKSorH/+vXrMW7cOISHh+PixYtYsWIFYmJiMH78+DKunIiIiCoirQanefPmYeDAgQgODoazszOio6NhaGiIlStXaux/5MgRNGvWDL1794aDgwPatWuHXr164fjx42VcOREREVVEWgtOOTk5OHnyJHx8fP4rRkcHPj4+OHr0qMZ5mjZtipMnT4pB6caNG9i5cyc6duxY4Hqys7ORnp6u8iAiIiIqDq1dVZeamoq8vDxYW1urtFtbW+PSpUsa5+nduzdSU1PRvHlzCIKA58+f44svvij0VF1kZCQmT55corUTERFRxfRWXVV34MABzJgxA4sXL8apU6ewZcsW7NixA1OnTi1wntDQUKSlpYmPW7duFdiXiIiIqDBaO+JkYWEBXV1dJCcnq7QnJyfDxsZG4zyTJk1Cnz59MGDAAABAo0aN8PTpUwwaNAgTJkzQeAmmXC6H/KU7lBIRUfn14lZGAqDdC77pHZR/x/U3pbXgpK+vD3d3d8THx6Nbt24AXmxUfHw8hg8frnGezMxMtXCkq6sLANDyXRWIiKgEPHqmREZWHswz01HJ0AT4/5/x0LYsHX7HaF1WVrFmEwQBOTk5uH//PnR0dKCv/2a3udDqncNDQkIQGBgIDw8PeHp6IioqCk+fPkVwcDAAoG/fvrCzs0NkZCQAwM/PD/PmzcP7778PLy8vXLt2DZMmTYKfn58YoIiI6O2VlSdgyYnHGOIBGCvSAZSP4KQvu6/tEujpm91Ly9DQEO+9916BNwiVSqvBKSAgAPfv30dYWBiSkpLg5uaGuLg4ccB4YmKiygZOnDgRMpkMEydOxJ07d2BpaQk/Pz9Mnz5dW5tAREQl7OrDXIyPT0UVAx3olI/chHj519ougYafKPasurq6qFSpkvhDxG9C63cOL2u8c3jFwDuHlwO8c3iJ4WeK9vEzpRwoxc+Ut+bO4URERERvEwYnIiIiIokYnIiIiIgkYnAiIiIikojBiYiIiEgiBiciIiIiiRiciIiIiCRicCIiIiKSiMGJiIiISCIGJyIiIiKJGJyIiIiIJGJwIiIiIpKIwYmIiIhIIgYnIiIiIokYnIiIiIgkYnAiIiIikojBiYiIiEgiBiciIiIiiRiciIiIiCRicCIiIiKSiMGJiIiISCIGJyIiIiKJGJyIiIiIJGJwIiIiIpKIwYmIiIhIIgYnIiIiIokYnIiIiIgkYnAiIiIikojBiYiIiEgiBiciIiIiiRiciIiIiCRicCIiIiKSiMGJiIiISCIGJyIiIiKJGJyIiIiIJGJwIiIiIpKIwYmIiIhIIgYnIiIiIokYnIiIiIgkYnAiIiIikojBiYiIiEgiBiciIiIiiRiciIiIiCRicCIiIiKSiMGJiIiISCIGJyIiIiKJGJyIiIiIJGJwIiIiIpKIwYmIiIhIIgYnIiIiIokYnIiIiIgkYnAiIiIikojBiYiIiEgiBiciIiIiiRiciIiIiCRicCIiIiKSiMGJiIiISCIGJyIiIiKJtB6cFi1aBAcHBygUCnh5eeH48eOF9n/8+DGGDRuGatWqQS6Xo27duti5c2cZVUtEREQVWSVtrjwmJgYhISGIjo6Gl5cXoqKi4Ovri8uXL8PKykqtf05ODtq2bQsrKyts3rwZdnZ2+Pfff2FmZlb2xRMREVGFo9XgNG/ePAwcOBDBwcEAgOjoaOzYsQMrV67EuHHj1PqvXLkSDx8+xJEjR6CnpwcAcHBwKMuSiYiIqALT2qm6nJwcnDx5Ej4+Pv8Vo6MDHx8fHD16VOM827Ztg7e3N4YNGwZra2s0bNgQM2bMQF5eXoHryc7ORnp6usqDiIiIqDi0FpxSU1ORl5cHa2trlXZra2skJSVpnOfGjRvYvHkz8vLysHPnTkyaNAlz587FtGnTClxPZGQkTE1NxYe9vX2JbgcRERFVHFofHF4USqUSVlZW+OGHH+Du7o6AgABMmDAB0dHRBc4TGhqKtLQ08XHr1q0yrJiIiIjeJVob42RhYQFdXV0kJyertCcnJ8PGxkbjPNWqVYOenh50dXXFtvr16yMpKQk5OTnQ19dXm0cul0Mul5ds8URERFQhae2Ik76+Ptzd3REfHy+2KZVKxMfHw9vbW+M8zZo1w7Vr16BUKsW2K1euoFq1ahpDExEREVFJ0uqpupCQECxbtgxr1qzBxYsXMWTIEDx9+lS8yq5v374IDQ0V+w8ZMgQPHz7EyJEjceXKFezYsQMzZszAsGHDtLUJREREVIFo9XYEAQEBuH//PsLCwpCUlAQ3NzfExcWJA8YTExOho/NftrO3t8euXbswevRouLi4wM7ODiNHjsQ333yjrU0gIiKiCkSrwQkAhg8fjuHDh2ucduDAAbU2b29vHDt2rJSrIiIiIlL3Vl1VR0RERKRNDE5EREREEjE4EREREUnE4EREREQkEYMTERERkUQMTkREREQSMTgRERERScTgRERERCRRkYLTpk2bkJOTIz6/ffu2yu/GZWZm4ttvvy256oiIiIjKkSIFp169euHx48fic2dnZyQkJIjPMzIyVH5bjoiIiOhdUqTgJAhCoc+JiIiI3mUc40REREQkEYMTERERkUSVijrDrl27YGpqCgBQKpWIj4/HuXPnAEBl/BMRERHRu6bIwSkwMFDl+eDBg1Wey2SyN6uIiIiIqJwqUnB6+dYDRERERBUNxzgRERERSVSk4HTlyhUcP35cpS0+Ph4ffvghPD09MWPGjBItjoiIiKg8KVJw+uabb/Drr7+Kz2/evAk/Pz/o6+vD29sbkZGRiIqKKukaiYiIiMqFIo1xOnHiBMaOHSs+X7duHerWrYtdu3YBAFxcXPDdd99h1KhRJVokERERUXlQpCNOqampqF69uvh8//798PPzE5+3bt1a5SdYiIiIiN4lRQpO5ubmuHfvHoAXV9idOHECH3zwgTg9JyeHP8NCRERE76wiBafWrVtj6tSpuHXrFqKioqBUKtG6dWtx+oULF+Dg4FDCJRIRERGVD0Ua4zR9+nS0bdsWNWrUgK6uLhYuXIjKlSuL09euXYs2bdqUeJFERERE5UGRgpODgwMuXryI8+fPw9LSEra2tirTJ0+erDIGioiIiOhdUuSfXKlUqRJcXV01TiuonYiIiOhdUKTgNGXKFEn9wsLCilUMERERUXlWpOAUEREBW1tbWFlZFXj1nEwmY3AiIiKid1KRglOHDh2wb98+eHh4oF+/fujcuTN0dPhzd0RERFQxFCn17NixA9evX4eXlxfGjBkDOzs7fPPNN7h8+XJp1UdERERUbhT5cJGtrS1CQ0Nx+fJlxMTEICUlBU2aNEGzZs3w7Nmz0qiRiIiIqFwo8lV1L2vSpAkSEhJw4cIFnD59Grm5uTAwMCip2oiIiIjKlWINUDp69CgGDhwIGxsbfPfddwgMDMTdu3dhYmJS0vURERERlRtFOuL07bffYvXq1UhNTcVnn32GgwcPwsXFpbRqIyIiIipXihScxo0bh/feew/+/v6QyWRYvXq1xn7z5s0ridqIiIiIypUiBaeWLVtCJpPh/PnzBfaRyWRvXBQRERFReVSk4HTgwIFSKoOIiIio/Hvju1cePnwY2dnZJVELERERUbn2xsGpQ4cOuHPnTknUQkRERFSuvXFwKug364iIiIjeNfyhOSIiIiKJ3jg4LV26FNbW1iVRCxEREVG59kY/uQIAvXv3Lok6iIiIiMq9Ih9xOnv2LKZNm4bFixcjNTVVZVp6ejr69etXYsURERERlSdFCk67d++Gp6cnNm7ciFmzZsHJyQn79+8Xpz979gxr1qwp8SKJiIiIyoMiBaeIiAh8/fXXOHfuHBISEjB27Fh06dIFcXFxpVUfERERUblRpDFO58+fx9q1awG8+GmVsWPHonr16ujRowc2btyIJk2alEqRREREROVBkYKTXC7H48ePVdp69+4NHR0dBAQEYO7cuSVZGxEREVG5UqTg5Obmhv3798Pd3V2lvWfPnhAEAYGBgSVaHBEREVF5UqTgNGTIEPzxxx8ap/Xq1QuCIGDZsmUlUhgRERFReVOk4PTxxx/j448/LnB67969eV8nIiIiemfxJ1eIiIiIJCrWncOrVKkCmUym1i6TyaBQKFC7dm0EBQUhODj4jQskIiIiKi+KFZzCwsIwffp0dOjQAZ6engCA48ePIy4uDsOGDcPNmzcxZMgQPH/+HAMHDizRgomIiIi0pVjB6dChQ5g2bRq++OILlfalS5di9+7d+Pnnn+Hi4oKFCxcyOBEREdE7o1hjnHbt2gUfHx+19o8++gi7du0CAHTs2BE3btx4s+qIiIiIypFiBSdzc3Ns375drX379u0wNzcHADx9+hTGxsZvVh0RERFROVKs4DRp0iSMGTMGXbp0wbRp0zBt2jR07doVY8eORXh4OABgz549aNWqlaTlLVq0CA4ODlAoFPDy8sLx48clzbdx40bIZDJ069atOJtBREREVCTFGuM0cOBAODs74/vvv8eWLVsAAPXq1cPvv/+Opk2bAgC++uorScuKiYlBSEgIoqOj4eXlhaioKPj6+uLy5cuwsrIqcL6EhAR8/fXXaNGiRXE2gYiIiKjIihWcAKBZs2Zo1qzZGxcwb948DBw4ULx1QXR0NHbs2IGVK1di3LhxGufJy8vDZ599hsmTJ+PgwYNqv59HREREVBqKHZzy8vKwdetWXLx4EQDQoEEDdOnSBbq6upKXkZOTg5MnTyI0NFRs09HRgY+PD44ePVrgfFOmTIGVlRX69++PgwcPFncTiIiIiIqkWMHp2rVr6NixI+7cuYN69eoBACIjI2Fvb48dO3agVq1akpaTmpqKvLw8WFtbq7RbW1vj0qVLGuc5dOgQVqxYgTNnzkhaR3Z2NrKzs8Xn6enpkuYjIiIielWxBoePGDECtWrVwq1bt3Dq1CmcOnUKiYmJcHR0xIgRI0q6RlFGRgb69OmDZcuWwcLCQtI8kZGRMDU1FR/29valVh8RERG924p1xOn333/HsWPHxFsPAEDVqlUxc+bMIo17srCwgK6uLpKTk1Xak5OTYWNjo9b/+vXrSEhIgJ+fn9imVCoBAJUqVcLly5fVjnaFhoYiJCREfJ6ens7wRERERMVSrOAkl8uRkZGh1v7kyRPo6+tLXo6+vj7c3d0RHx8v3lJAqVQiPj4ew4cPV+vv5OSEf/75R6Vt4sSJyMjIwIIFCzQGIrlcDrlcLrkmIiIiooIUKzh17twZgwYNwooVK8Tfqvvzzz/xxRdfoEuXLkVaVkhICAIDA+Hh4QFPT09ERUXh6dOn4lV2ffv2hZ2dHSIjI6FQKNCwYUOV+c3MzABArZ2IiIiopBUrOC1cuBCBgYHw9vaGnp4eACA3Nxddu3ZFVFRUkZYVEBCA+/fvIywsDElJSXBzc0NcXJw4YDwxMRE6OsUaikVERERUomSCIAjFnfnatWvi7Qjq16+P2rVrl1hhpSU9PR2mpqZIS0uDiYlJqazDYdyOUlkuSZeg6K3tEigiTdsVvDP4maJ9/EwpB0rxM6Uo2UDyEaeXB1hrsn//fvHf8+bNk7pYIiIioreG5OB0+vRpSf1kMlmxiyEiIiIqzyQHp5ePKBERERFVRBx1TURERCQRgxMRERGRRAxORERERBIxOBERERFJxOBEREREJBGDExEREZFEDE5EREREEjE4EREREUnE4EREREQkEYMTERERkUQMTkREREQSMTgRERERScTgRERERCQRgxMRERGRRAxORERERBIxOBERERFJxOBEREREJBGDExEREZFEDE5EREREEjE4EREREUnE4EREREQkEYMTERERkUQMTkREREQSMTgRERERScTgRERERCQRgxMRERGRRAxORERERBIxOBERERFJxOBEREREJBGDExEREZFEDE5EREREEjE4EREREUnE4EREREQkEYMTERERkUQMTkREREQSMTgRERERScTgRERERCQRgxMRERGRRAxORERERBIxOBERERFJxOBEREREJBGDExEREZFEDE5EREREEjE4EREREUnE4EREREQkEYMTERERkUQMTkREREQSMTgRERERScTgRERERCQRgxMRERGRRAxORERERBIxOBERERFJxOBEREREJBGDExEREZFEDE5EREREEpWL4LRo0SI4ODhAoVDAy8sLx48fL7DvsmXL0KJFC1SpUgVVqlSBj49Pof2JiIiISorWg1NMTAxCQkIQHh6OU6dOwdXVFb6+vkhJSdHY/8CBA+jVqxf279+Po0ePwt7eHu3atcOdO3fKuHIiIiKqaLQenObNm4eBAwciODgYzs7OiI6OhqGhIVauXKmx/7p16zB06FC4ubnByckJy5cvh1KpRHx8fBlXTkRERBWNVoNTTk4OTp48CR8fH7FNR0cHPj4+OHr0qKRlZGZmIjc3F+bm5qVVJhEREREAoJI2V56amoq8vDxYW1urtFtbW+PSpUuSlvHNN9/A1tZWJXy9LDs7G9nZ2eLz9PT04hdMREREFZrWT9W9iZkzZ2Ljxo343//+B4VCobFPZGQkTE1NxYe9vX0ZV0lERETvCq0GJwsLC+jq6iI5OVmlPTk5GTY2NoXOO2fOHMycORO7d++Gi4tLgf1CQ0ORlpYmPm7dulUitRMREVHFo9XgpK+vD3d3d5WB3fkDvb29vQuc79tvv8XUqVMRFxcHDw+PQtchl8thYmKi8iAiIiIqDq2OcQKAkJAQBAYGwsPDA56enoiKisLTp08RHBwMAOjbty/s7OwQGRkJAJg1axbCwsKwfv16ODg4ICkpCQBgZGQEIyMjrW0HERERvfu0HpwCAgJw//59hIWFISkpCW5uboiLixMHjCcmJkJH578DY0uWLEFOTg569Oihspzw8HBERESUZelERERUwWg9OAHA8OHDMXz4cI3TDhw4oPI8ISGh9AsiIiIi0uCtvqqOiIiIqCwxOBERERFJxOBEREREJBGDExEREZFEDE5EREREEjE4EREREUnE4EREREQkEYMTERERkUQMTkREREQSMTgRERERScTgRERERCQRgxMRERGRRAxORERERBIxOBERERFJxOBEREREJBGDExEREZFEDE5EREREEjE4EREREUnE4EREREQkEYMTERERkUQMTkREREQSMTgRERERScTgRERERCQRgxMRERGRRAxORERERBIxOBERERFJxOBEREREJBGDExEREZFEDE5EREREEjE4EREREUnE4EREREQkEYMTERERkUQMTkREREQSMTgRERERScTgRERERCQRgxMRERGRRAxORERERBIxOBERERFJxOBEREREJBGDExEREZFEDE5EREREEjE4EREREUnE4EREREQkEYMTERERkUQMTkREREQSMTgRERERScTgRERERCQRgxMRERGRRAxORERERBIxOBERERFJxOBEREREJBGDExEREZFEDE5EREREEjE4EREREUnE4EREREQkEYMTERERkUQMTkREREQSMTgRERERSVQugtOiRYvg4OAAhUIBLy8vHD9+vND+sbGxcHJygkKhQKNGjbBz584yqpSIiIgqMq0Hp5iYGISEhCA8PBynTp2Cq6srfH19kZKSorH/kSNH0KtXL/Tv3x+nT59Gt27d0K1bN5w7d66MKyciIqKKRuvBad68eRg4cCCCg4Ph7OyM6OhoGBoaYuXKlRr7L1iwAO3bt8eYMWNQv359TJ06FY0bN8b3339fxpUTERFRRVNJmyvPycnByZMnERoaKrbp6OjAx8cHR48e1TjP0aNHERISotLm6+uLrVu3auyfnZ2N7Oxs8XlaWhoAID09/Q2rL5gyO7PUlk3SpMsEbZdApfgeq2j4maJ9/EwpB0rxMyU/EwjC6/+ftRqcUlNTkZeXB2tra5V2a2trXLp0SeM8SUlJGvsnJSVp7B8ZGYnJkyertdvb2xezanobmGq7AAJm8n+B3h3cm8uBMvhMycjIgKlp4evRanAqC6GhoSpHqJRKJR4+fIiqVatCJpNpsTIqLenp6bC3t8etW7dgYmKi7XKI6C3Hz5R3nyAIyMjIgK2t7Wv7ajU4WVhYQFdXF8nJySrtycnJsLGx0TiPjY1NkfrL5XLI5XKVNjMzs+IXTW8NExMTfsgRUYnhZ8q77XVHmvJpdXC4vr4+3N3dER8fL7YplUrEx8fD29tb4zze3t4q/QFgz549BfYnIiIiKilaP1UXEhKCwMBAeHh4wNPTE1FRUXj69CmCg4MBAH379oWdnR0iIyMBACNHjkSrVq0wd+5cdOrUCRs3bsSJEyfwww8/aHMziIiIqALQenAKCAjA/fv3ERYWhqSkJLi5uSEuLk4cAJ6YmAgdnf8OjDVt2hTr16/HxIkTMX78eNSpUwdbt25Fw4YNtbUJVM7I5XKEh4ernaIlIioOfqbQy2SClGvviIiIiEj7N8AkIiIielswOBERERFJxOBEREREJBGDExEREZFEDE5U7vn5+aF9+/Yapx08eBAymQx///03AGDw4MHQ1dVFbGysWt+IiAi4ubmVZqlEVA7JZLJCHxEREUhISChw+rFjxwAAeXl5mDlzJpycnGBgYABzc3N4eXlh+fLlktdDbz+t346A6HX69++P7t274/bt26hevbrKtFWrVsHDwwMuLi7IzMzExo0bMXbsWKxcuRKffvqpliomovLk3r174r9jYmIQFhaGy5cvi21GRkZITU0FAOzduxcNGjRQmb9q1aoAgMmTJ2Pp0qX4/vvv4eHhgfT0dJw4cQKPHj2SvB56+zE4UbnXuXNnWFpaYvXq1Zg4caLY/uTJE8TGxmL27NkAgNjYWDg7O2PcuHGwtbXFrVu3+GPORKTyk1ympqaQyWRqP9OVH5yqVq1a4E94bdu2DUOHDlX5o8zV1bVI66G3H0/VUblXqVIl9O3bF6tXr8bLtx2LjY1FXl4eevXqBQBYsWIFPv/8c5iamqJDhw5YvXq1liomoneRjY0N9u3bh/v372u7FNIiBid6K/Tr1w/Xr1/H77//LratWrUK3bt3h6mpKa5evYpjx44hICAAAPD5559j1apV4P1diagomjZtCiMjI5VHvnnz5uH+/fuwsbGBi4sLvvjiC/z2229arJa0gcGJ3gpOTk5o2rQpVq5cCQC4du0aDh48iP79+wMAVq5cCV9fX1hYWAAAOnbsiLS0NOzbt09rNRPR2ycmJgZnzpxReeRzdnbGuXPncOzYMfTr1w8pKSnw8/PDgAEDtFcwlTkGJ3pr9O/fHz///DMyMjKwatUq1KpVC61atUJeXh7WrFmDHTt2oFKlSqhUqRIMDQ3x8OFDMWgREUlhb2+P2rVrqzxepqOjgyZNmmDUqFHYsmULVq9ejRUrVuDmzZtaqpjKGgeH01vD398fI0eOxPr16/Hjjz9iyJAhkMlk2LlzJzIyMnD69Gno6uqK/c+dO4fg4GA8fvwYZmZm2iuciN5Zzs7OAICnT59quRIqKwxO9NYwMjJCQEAAQkNDkZ6ejqCgIAAvBoV36tRJ5eoW4MUH2ujRo7Fu3ToMGzYMAPDs2TOVQ+8AYGxsjFq1apXFJhBROffgwQMkJSWptJmZmUGhUKBHjx5o1qwZmjZtChsbG9y8eROhoaGoW7cunJyctFQxlTWeqqO3Sv/+/fHo0SP4+vrC1tYWycnJ2LFjB7p3767WV0dHBx9//DFWrFghtl25cgXvv/++ymPw4MFluQlEVI75+PigWrVqKo+tW7cCAHx9fbF9+3b4+fmhbt26CAwMhJOTE3bv3o1KlXgcoqKQCbzsiIiIiEgSHnEiIiIikojBiYiIiEgiBiciIiIiiRiciIiIiCRicCIiIiKSiMGJiIiISCIGJyIiIiKJGJyIiIiIJGJwIiIiIpKIwYmIiIhIIgYnIiIiIokYnIiIiIgk+j9xlroCRmlUCwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase 9 — Save Submission *Artifacts*\n",
        "\n",
        "In this phase, I bundle the final per-\\(k,m\\) MoE ensemble (all experts, scalers,\n",
        "and calibration parameters) into a single ZIP archive (`Proj3_SVD64_GlobalAug.zip`).\n",
        "This is the model folder I will attach via Google Drive/email for grading.\n",
        "The code verifies that `artifacts_index.pkl` exists, zips the entire directory,\n",
        "and (in Colab) automatically triggers a download.\n"
      ],
      "metadata": {
        "id": "YzUXpn7gLwyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 9 — Save Submission Artifacts\n",
        "\n",
        "\n",
        "\n",
        "MODEL_ROOT = \"Proj3_SVD64_GlobalAug\"           # final MoE model directory\n",
        "ZIP_NAME   = f\"{MODEL_ROOT}.zip\"              # e.g. Proj3_SVD64_GlobalAug.zip\n",
        "\n",
        "print(\"Packaging final MoE model for submission...\")\n",
        "print(f\"  Model root directory: {MODEL_ROOT}\")\n",
        "\n",
        "# ---- Sanity checks ----\n",
        "if not os.path.exists(MODEL_ROOT):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Directory '{MODEL_ROOT}' not found. \"\n",
        "        \"Make sure Phase 6 (training) completed and SAVE_ROOT is correct.\"\n",
        "    )\n",
        "\n",
        "art_index_path = os.path.join(MODEL_ROOT, \"artifacts_index.pkl\")\n",
        "if not os.path.exists(art_index_path):\n",
        "    raise FileNotFoundError(\n",
        "        f\"'artifacts_index.pkl' not found in {MODEL_ROOT}. \"\n",
        "        \"Check that training and artifact saving completed successfully.\"\n",
        "    )\n",
        "\n",
        "print(\"   Found artifacts_index.pkl\")\n",
        "\n",
        "# ---- Remove existing zip if present ----\n",
        "if os.path.exists(ZIP_NAME):\n",
        "    print(f\"  Removing existing zip: {ZIP_NAME}\")\n",
        "    os.remove(ZIP_NAME)\n",
        "\n",
        "# ---- Create fresh zip archive ----\n",
        "print(f\"  Creating zip archive: {ZIP_NAME}\")\n",
        "\n",
        "with zipfile.ZipFile(ZIP_NAME, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for root, dirs, files in os.walk(MODEL_ROOT):\n",
        "        for fname in files:\n",
        "            fpath = os.path.join(root, fname)\n",
        "            # Store relative path inside the zip\n",
        "            arcname = os.path.relpath(fpath, start=\".\")\n",
        "            zf.write(fpath, arcname=arcname)\n",
        "\n",
        "print(\"   Zip creation complete\")\n",
        "\n",
        "# ---- Report rough contents ----\n",
        "num_keras = 0\n",
        "num_pkl   = 0\n",
        "for root, dirs, files in os.walk(MODEL_ROOT):\n",
        "    for fname in files:\n",
        "        if fname.endswith(\".keras\"):\n",
        "            num_keras += 1\n",
        "        elif fname.endswith(\".pkl\"):\n",
        "            num_pkl += 1\n",
        "\n",
        "zip_size = os.path.getsize(ZIP_NAME) / (1024 * 1024)\n",
        "\n",
        "print(\"\\nArchive summary:\")\n",
        "print(f\"  Zip file:      {ZIP_NAME}\")\n",
        "print(f\"  Size:          {zip_size:.2f} MB\")\n",
        "print(f\"  .keras files:  {num_keras}\")\n",
        "print(f\"  .pkl files:    {num_pkl}\")\n",
        "\n",
        "# ---- Trigger download if running in Colab ----\n",
        "try:\n",
        "    from google.colab import files  # type: ignore\n",
        "    print(\"\\nInitiating download...\")\n",
        "    files.download(ZIP_NAME)\n",
        "except Exception:\n",
        "    print(\"\\nDownload step skipped (not running in Google Colab).\")\n",
        "    print(\"You can manually download the zip from the file browser.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "qhv3w5ppLHkc",
        "outputId": "812519f6-4795-4ad7-b056-47593070837b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Packaging final MoE model for submission...\n",
            "  Model root directory: Proj3_SVD64_GlobalAug\n",
            "   Found artifacts_index.pkl\n",
            "  Creating zip archive: Proj3_SVD64_GlobalAug.zip\n",
            "   Zip creation complete\n",
            "\n",
            "Archive summary:\n",
            "  Zip file:      Proj3_SVD64_GlobalAug.zip\n",
            "  Size:          46.89 MB\n",
            "  .keras files:  33\n",
            "  .pkl files:    19\n",
            "\n",
            "Initiating download...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9aa8194a-fba0-479c-8033-7db76d9ebca7\", \"Proj3_SVD64_GlobalAug.zip\", 49164040)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **Phase 10 — Final Submission Pipeline (MoE Inference + Output Generation)**\n",
        "\n",
        "This final phase packages the entire solution into a **single submission-ready prediction pipeline**, following the same structure as Project 1 and Project 2.\n",
        "\n",
        "#### **Purpose of This Cell**\n",
        "The following (final) cell implements the **complete inference pipeline** required for Project 3:\n",
        "\n",
        "1. **Load the trained MoE model folder**\n",
        "   - Ensures `Proj3_SVD64_GlobalAug/` exists  \n",
        "   - If running on Colab, the cell will prompt you to upload the zipped model folder  \n",
        "   - Validates the presence of `artifacts_index.pkl` and all (k,m) expert subfolders\n",
        "\n",
        "2. **Load the official Project 3 TEST dataset**\n",
        "   - Expects a pickle file containing a list of `(n, k, m, P)` entries  \n",
        "   - Automatically checks structure and prints basic sanity summaries\n",
        "\n",
        "3. **Rebuild the feature pipeline**\n",
        "   - Recomputes the **same SVD-64 permutation-invariant features** used during training  \n",
        "   - Ensures consistency across padding, token interpretation, and numeric formats  \n",
        "   - Routes each test item to its matching (k,m) expert bucket\n",
        "\n",
        "4. **Run Ensemble + Calibration Inference**\n",
        "   For each (k,m):\n",
        "   - Loads the ensemble of trained experts  \n",
        "   - Applies the saved `StandardScaler`  \n",
        "   - Computes ensemble mean prediction in **log₂ space**  \n",
        "   - Applies model-specific **linear calibration**  \n",
        "   - Converts the calibrated log₂ value back to **m-height**\n",
        "\n",
        "5. **Generate final submission output**\n",
        "   - Produces the final list of predicted **m-heights**, all ≥ 1.0  \n",
        "   - Saves them as `predictions.pkl`  \n",
        "   - Automatically downloads the file (Colab) or stores it in the working directory\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "D86MuEFJNfvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# Phase 10 - FINAL SUBMISSION CELL — Project 3 m-height Model\n",
        "# ================================================\n",
        "#\n",
        "# This cell is fully self-contained:\n",
        "#   1) Ensures Proj3_SVD64_GlobalAug/ is available\n",
        "#      - If not, prompts to upload Proj3_SVD64_GlobalAug.zip\n",
        "#   2) Loads all per-(k,m) experts, scalers, and calibration\n",
        "#   3) Prompts to upload the TEST pickle file: [(n,k,m,P), ...]\n",
        "#   4) Runs SVD-64 featurizer + MoE ensemble inference\n",
        "#   5) Saves predictions (original m-height space, >=1) as predictions.pkl\n",
        "#   6) Downloads predictions.pkl (in Colab)\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import zipfile\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler  # used via loaded scalers\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "MODEL_ROOT  = \"Proj3_SVD64_GlobalAug\"\n",
        "ZIP_EXPECT  = MODEL_ROOT + \".zip\"\n",
        "OUTPUT_FILE = \"CSCE 636-600 Fall 2025 Project 3 Test Results SHRUTI SINGH 635008775.pkl\"\n",
        "EPS         = 1e-12\n",
        "FEAT_DIM    = 64\n",
        "\n",
        "print(\"FINAL SUBMISSION CELL — Project 3 m-height Prediction\")\n",
        "\n",
        "# -----------------------------\n",
        "# STEP 0 — Ensure model folder exists (or upload ZIP)\n",
        "# -----------------------------\n",
        "if not os.path.exists(MODEL_ROOT):\n",
        "    print(f\"Model directory '{MODEL_ROOT}' not found.\")\n",
        "    print(f\"Please upload the zip file containing your trained model folder (e.g. {ZIP_EXPECT}).\\n\")\n",
        "\n",
        "    try:\n",
        "        from google.colab import files  # type: ignore\n",
        "    except Exception:\n",
        "        raise RuntimeError(\n",
        "            f\"'{MODEL_ROOT}' not found and google.colab.files is unavailable. \"\n",
        "            \"Please place the model folder or zip in the current directory.\"\n",
        "        )\n",
        "\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        raise RuntimeError(\"No zip file uploaded. Aborting.\")\n",
        "\n",
        "    # Take the first uploaded file as zip\n",
        "    zip_name = list(uploaded.keys())[0]\n",
        "    print(f\"\\nUploaded zip: {zip_name}\")\n",
        "\n",
        "    # Extract\n",
        "    with zipfile.ZipFile(zip_name, \"r\") as zf:\n",
        "        print(\"Extracting zip...\")\n",
        "        zf.extractall(\".\")\n",
        "    print(\"Extraction complete.\\n\")\n",
        "\n",
        "    # Heuristic: if MODEL_ROOT does not exist yet, try to find it in extracted contents\n",
        "    if not os.path.exists(MODEL_ROOT):\n",
        "        # Search recursively for artifacts_index.pkl and infer root from there\n",
        "        candidate_root = None\n",
        "        for root, dirs, files in os.walk(\".\"):\n",
        "            if \"artifacts_index.pkl\" in files:\n",
        "                # Assume its parent directory is the model root\n",
        "                candidate_root = root\n",
        "                break\n",
        "        if candidate_root is None:\n",
        "            raise FileNotFoundError(\n",
        "                \"Could not locate 'artifacts_index.pkl' after extraction. \"\n",
        "                \"Please verify the zip structure.\"\n",
        "            )\n",
        "        if os.path.basename(candidate_root) != MODEL_ROOT:\n",
        "            # Rename/move if necessary\n",
        "            print(f\"Discovered model root at: {candidate_root}\")\n",
        "            if not os.path.exists(MODEL_ROOT):\n",
        "                os.rename(candidate_root, MODEL_ROOT)\n",
        "                print(f\"Renamed '{candidate_root}' → '{MODEL_ROOT}'\")\n",
        "        else:\n",
        "            print(f\"Model root found at: {candidate_root}\")\n",
        "\n",
        "# Final sanity: artifacts_index.pkl must exist\n",
        "art_index_path = os.path.join(MODEL_ROOT, \"artifacts_index.pkl\")\n",
        "if not os.path.exists(art_index_path):\n",
        "    raise FileNotFoundError(\n",
        "        f\"'artifacts_index.pkl' not found in {MODEL_ROOT}. \"\n",
        "        \"Make sure the zip/folder is the one produced by training.\"\n",
        "    )\n",
        "\n",
        "print(f\" Model directory ready: {MODEL_ROOT}\")\n",
        "print(f\" Found artifacts index at: {art_index_path}\\n\")\n",
        "\n",
        "# -----------------------------\n",
        "# STEP 1 — Upload TEST pickle\n",
        "# -----------------------------\n",
        "print(\"STEP 1 — Upload TEST pickle file\")\n",
        "print(\"The test file must be a list of tuples: [(n, k, m, P), ...], where\")\n",
        "print(\"  n = 9, k ∈ {4,5,6}, 2 ≤ m ≤ n-k, and P has shape (k, 9-k).\\n\")\n",
        "\n",
        "try:\n",
        "    from google.colab import files  # type: ignore\n",
        "    uploaded_test = files.upload()\n",
        "except Exception:\n",
        "    raise RuntimeError(\n",
        "        \"google.colab.files is unavailable. If you're not in Colab, \"\n",
        "        \"please manually place the test pickle in the working directory \"\n",
        "        \"and adapt this cell accordingly.\"\n",
        "    )\n",
        "\n",
        "if not uploaded_test:\n",
        "    raise RuntimeError(\"No TEST file uploaded. Aborting.\")\n",
        "\n",
        "test_filename = list(uploaded_test.keys())[0]\n",
        "print(f\"\\nUploaded TEST file: {test_filename}\")\n",
        "\n",
        "with open(test_filename, \"rb\") as f:\n",
        "    test_data = pickle.load(f)\n",
        "\n",
        "if not isinstance(test_data, (list, tuple)) or len(test_data) == 0:\n",
        "    raise ValueError(\"Test file format error: expected non-empty list/tuple of (n,k,m,P).\")\n",
        "\n",
        "n0, k0, m0, P0 = test_data[0]\n",
        "print(f\"Sample[0]: n={n0}, k={k0}, m={m0}, P.shape={np.asarray(P0).shape}\")\n",
        "print(f\"Total test samples: {len(test_data):,}\\n\")\n",
        "\n",
        "# -----------------------------\n",
        "# STEP 2 — Define Featurizer (SVD-64, permutation-invariant)\n",
        "# -----------------------------\n",
        "def _gini_like(x: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Simple inequality measure in [0,1). Invariant to permutation and scaling.\n",
        "    Returns 0 if vector is all zeros.\n",
        "    \"\"\"\n",
        "    x = np.abs(np.asarray(x, dtype=np.float64)).ravel()\n",
        "    if x.size == 0:\n",
        "        return 0.0\n",
        "    s = np.sum(x)\n",
        "    if s <= EPS:\n",
        "        return 0.0\n",
        "    xs = np.sort(x)  # ascending\n",
        "    n = x.size\n",
        "    idx = np.arange(1, n + 1, dtype=np.float64)\n",
        "    return float((2.0 * np.sum(idx * xs) / (n * s)) - (n + 1.0) / n)\n",
        "\n",
        "def featurize_sample(n: int, k: int, m: int, P: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Build a FEAT_DIM-D permutation-invariant vector from (n,k,m,P); returns float32[FEAT_DIM].\n",
        "    Assumes n == 9, k in {4,5,6}, 2 <= m <= n-k, and P.shape == (k, 9-k).\n",
        "    Invariance: row/column permutations of P do not change the features.\n",
        "    \"\"\"\n",
        "    P = np.asarray(P, dtype=np.float64)\n",
        "    assert n == 9, f\"Expected n=9, got n={n}\"\n",
        "    assert k in (4, 5, 6), f\"Expected k in {{4,5,6}}, got k={k}\"\n",
        "    nk = n - k\n",
        "    assert 2 <= m <= nk, f\"Expected 2 <= m <= {nk}, got m={m}\"\n",
        "    assert P.shape == (k, nk), f\"P shape should be ({k}, {nk}), got {P.shape}\"\n",
        "\n",
        "    feats = []\n",
        "\n",
        "    # 1) Basic (n,k,m) geometry\n",
        "    n_f = float(n); k_f = float(k); m_f = float(m); nk_f = float(nk)\n",
        "    feats.extend([\n",
        "        n_f, k_f, m_f,\n",
        "        k_f / n_f,\n",
        "        m_f / (k_f + EPS),\n",
        "        m_f / (nk_f + EPS),\n",
        "        (m_f**2) / (k_f + EPS),\n",
        "        m_f * k_f,\n",
        "        float(np.log2(m_f + 1.0)),\n",
        "        float(np.log2(k_f + 1.0)),\n",
        "    ])  # 10\n",
        "\n",
        "    # 2) Column & row norms\n",
        "    col_norms = np.linalg.norm(P, axis=0)\n",
        "    row_norms = np.linalg.norm(P, axis=1)\n",
        "\n",
        "    c_mean = float(np.mean(col_norms)) if col_norms.size else 0.0\n",
        "    c_std  = float(np.std(col_norms))  if col_norms.size else 0.0\n",
        "    c_max  = float(np.max(col_norms))  if col_norms.size else 0.0\n",
        "    c_min  = float(np.min(col_norms))  if col_norms.size else 0.0\n",
        "    c_gini = _gini_like(col_norms)\n",
        "\n",
        "    col_sorted = np.sort(col_norms)[::-1]\n",
        "    top3 = [float(col_sorted[i]) if i < len(col_sorted) else 0.0 for i in range(3)]\n",
        "    mth  = float(col_sorted[m-1]) if (m-1) < len(col_sorted) and m >= 1 else 0.0\n",
        "    topm_sum = float(np.sum(col_sorted[:m])) if m <= len(col_sorted) else float(np.sum(col_sorted))\n",
        "    col_sum  = float(np.sum(col_sorted)) + EPS\n",
        "    topm_share = topm_sum / col_sum\n",
        "\n",
        "    feats.extend([\n",
        "        c_mean, c_std, c_max, c_min, c_gini,\n",
        "        *top3, mth, topm_share\n",
        "    ])  # +9 → 19\n",
        "\n",
        "    r_mean = float(np.mean(row_norms)) if row_norms.size else 0.0\n",
        "    r_std  = float(np.std(row_norms))  if row_norms.size else 0.0\n",
        "    r_max  = float(np.max(row_norms))  if row_norms.size else 0.0\n",
        "    r_min  = float(np.min(row_norms))  if row_norms.size else 0.0\n",
        "    r_ratio = float(r_max / (r_min + EPS)) if r_min > 0 else 1000.0\n",
        "    r_gini  = _gini_like(row_norms)\n",
        "\n",
        "    feats.extend([r_mean, r_std, r_max, r_min, r_ratio, r_gini])  # +6 → 25\n",
        "\n",
        "    # 3) Matrix-level stats\n",
        "    feats.extend([\n",
        "        float(np.mean(P)),\n",
        "        float(np.std(P)),\n",
        "        float(np.max(np.abs(P))) if P.size else 0.0,\n",
        "        float(np.linalg.norm(P, 'fro')),\n",
        "        float(np.sum(P * P)),\n",
        "        float(np.mean(P > 0)) if P.size else 0.0,\n",
        "        float(np.linalg.matrix_rank(P)),\n",
        "    ])  # +7 → 32\n",
        "\n",
        "    # 4) Spectrum (SVD)\n",
        "    try:\n",
        "        svals = np.sort(np.linalg.svd(P, compute_uv=False))[::-1]\n",
        "    except np.linalg.LinAlgError:\n",
        "        svals = np.zeros(min(k, nk), dtype=np.float64)\n",
        "\n",
        "    S = np.zeros(5, dtype=np.float64)\n",
        "    r = min(5, svals.size)\n",
        "    if r > 0:\n",
        "        S[:r] = svals[:r]\n",
        "\n",
        "    energy = S**2\n",
        "    tot_energy = float(np.sum(energy)) + EPS\n",
        "    shares = (energy / tot_energy).tolist()\n",
        "    cum_at_m = float(np.sum(energy[:min(m, 5)]) / tot_energy)\n",
        "\n",
        "    ps = energy / tot_energy\n",
        "    ps = np.clip(ps, EPS, 1.0)\n",
        "    spec_entropy = float(-np.sum(ps * np.log(ps)))\n",
        "\n",
        "    s_top = float(S[0])\n",
        "    s_bot = float(S[r-1]) if r > 0 and S[r-1] > 0 else EPS\n",
        "    s_med = float(np.median(S[:r])) if r > 0 else EPS\n",
        "    cond_tb = float(s_top / (s_bot + EPS))\n",
        "    cond_tm = float(s_top / (s_med + EPS))\n",
        "\n",
        "    feats.extend([\n",
        "        *S.tolist(),\n",
        "        *shares,\n",
        "        cum_at_m,\n",
        "        spec_entropy,\n",
        "        float(2.0 * np.sum(np.log(S[:r] + EPS))),\n",
        "        cond_tb, cond_tm,\n",
        "        float(np.sum(S[:r])),\n",
        "        float(np.mean(S[:r])) if r > 0 else 0.0,\n",
        "    ])  # +17 → 49\n",
        "\n",
        "    # 5) Cross stats\n",
        "    feats.extend([\n",
        "        float(r_mean * c_mean),\n",
        "        float((r_mean / (c_mean + EPS)) if c_mean > 0 else 0.0),\n",
        "        float((c_max / (c_min + EPS)) if c_min > 0 else 1000.0),\n",
        "    ])  # +3 → 52\n",
        "\n",
        "    # 6) Pad / truncate to FEAT_DIM\n",
        "    if len(feats) < FEAT_DIM:\n",
        "        feats.extend([0.0] * (FEAT_DIM - len(feats)))\n",
        "    elif len(feats) > FEAT_DIM:\n",
        "        feats = feats[:FEAT_DIM]\n",
        "\n",
        "    return np.asarray(feats, dtype=np.float32)\n",
        "\n",
        "def featurize_list(X_list):\n",
        "    N = len(X_list)\n",
        "    F = np.zeros((N, FEAT_DIM), dtype=np.float32)\n",
        "    KS = np.zeros(N, dtype=np.int32)\n",
        "    MS = np.zeros(N, dtype=np.int32)\n",
        "    for i, (n, k, m, P) in enumerate(X_list):\n",
        "        F[i] = featurize_sample(n, k, m, P)\n",
        "        KS[i] = int(k)\n",
        "        MS[i] = int(m)\n",
        "    return F, KS, MS\n",
        "\n",
        "print(\"\\nSTEP 2 — Building SVD-64 features for test set...\")\n",
        "X_test_features, K_test, M_test = featurize_list(test_data)\n",
        "X_test_features = np.nan_to_num(X_test_features, nan=0.0, posinf=1e3, neginf=-1e3)\n",
        "print(f\"  Features shape: {X_test_features.shape}\")\n",
        "print(\"  Done.\\n\")\n",
        "\n",
        "# -----------------------------\n",
        "# STEP 3 — Load artifacts and run MoE inference per-(k,m)\n",
        "# -----------------------------\n",
        "\n",
        "# Load artifact index\n",
        "with open(art_index_path, \"rb\") as f:\n",
        "    ARTIFACTS = pickle.load(f)\n",
        "\n",
        "def mse_np(a, b):\n",
        "    a = np.asarray(a).ravel()\n",
        "    b = np.asarray(b).ravel()\n",
        "    return float(np.mean((a - b)**2))\n",
        "\n",
        "print(\"STEP 3 — Running per-(k,m) ensemble inference...\")\n",
        "pair_to_indices = {}\n",
        "for i, (k, m) in enumerate(zip(K_test, M_test)):\n",
        "    key = (int(k), int(m))\n",
        "    pair_to_indices.setdefault(key, []).append(i)\n",
        "\n",
        "z_hat_all = np.zeros(len(test_data), dtype=np.float64)\n",
        "\n",
        "for (k, m), idx_list in sorted(pair_to_indices.items()):\n",
        "    idx_arr = np.asarray(idx_list, dtype=np.int64)\n",
        "    if (k, m) not in ARTIFACTS:\n",
        "        raise KeyError(f\"No artifacts found for pair (k={k},m={m}) in {MODEL_ROOT}.\")\n",
        "\n",
        "    art = ARTIFACTS[(k, m)]\n",
        "    scaler_path = art[\"scaler_X\"]\n",
        "    calib_path  = art[\"calib\"]\n",
        "    model_paths = art[\"model_paths\"]\n",
        "\n",
        "    # Load scaler\n",
        "    with open(scaler_path, \"rb\") as f:\n",
        "        sx = pickle.load(f)\n",
        "\n",
        "    # Load calibration\n",
        "    with open(calib_path, \"rb\") as f:\n",
        "        calib = pickle.load(f)\n",
        "    a_cal = float(calib[\"a\"])\n",
        "    b_cal = float(calib[\"b\"])\n",
        "\n",
        "    # Load ensemble models\n",
        "    models = []\n",
        "    for mp in model_paths:\n",
        "        if not os.path.exists(mp):\n",
        "            raise FileNotFoundError(f\"Expected model file not found: {mp}\")\n",
        "        models.append(keras.models.load_model(mp))\n",
        "\n",
        "    # Prepare features for this pair\n",
        "    X_pair = X_test_features[idx_arr].astype(np.float32)\n",
        "    X_pair_s = sx.transform(X_pair)\n",
        "\n",
        "    # Ensemble prediction in z-space (log2)\n",
        "    preds = [m_.predict(X_pair_s, verbose=0).ravel() for m_ in models]\n",
        "    z_hat_pair_uncal = np.mean(preds, axis=0)\n",
        "\n",
        "    # Apply linear calibration\n",
        "    z_hat_pair = a_cal * z_hat_pair_uncal + b_cal\n",
        "\n",
        "    z_hat_all[idx_arr] = z_hat_pair\n",
        "\n",
        "    print(f\"  (k={k}, m={m})  #samples={len(idx_arr):5d}\")\n",
        "\n",
        "print(\"\\nAll per-(k,m) predictions computed in log2 space.\")\n",
        "\n",
        "# -----------------------------\n",
        "# STEP 4 — Convert to original m-height space, save + download\n",
        "# -----------------------------\n",
        "print(\"\\nSTEP 4 — Converting to m-heights and saving output...\")\n",
        "\n",
        "y_hat = np.power(2.0, z_hat_all)     # invert log2\n",
        "y_hat = np.maximum(y_hat, 1.0)       # ensure ≥ 1.0\n",
        "\n",
        "print(f\"  Prediction range (m-height): [{y_hat.min():.3f}, {y_hat.max():.3e}]\")\n",
        "print(f\"  Number of predictions:       {len(y_hat):,}\")\n",
        "\n",
        "predictions_list = y_hat.tolist()\n",
        "\n",
        "with open(OUTPUT_FILE, \"wb\") as f:\n",
        "    pickle.dump(predictions_list, f)\n",
        "\n",
        "# Verify round-trip\n",
        "with open(OUTPUT_FILE, \"rb\") as f:\n",
        "    _check = pickle.load(f)\n",
        "assert len(_check) == len(predictions_list), \"Length mismatch after saving predictions.\"\n",
        "\n",
        "print(f\"\\nSaved predictions to: {OUTPUT_FILE}\")\n",
        "\n",
        "# Attempt download (Colab)\n",
        "try:\n",
        "    from google.colab import files  # type: ignore\n",
        "    print(\"Initiating download of predictions.pkl ...\")\n",
        "    files.download(OUTPUT_FILE)\n",
        "except Exception:\n",
        "    print(\"Download step skipped (not running in Google Colab).\")\n",
        "\n",
        "print(\"\\nPREDICTION PIPELINE COMPLETE.\")\n",
        "print(\"Summary:\")\n",
        "print(f\"  Test samples:     {len(test_data):,}\")\n",
        "print(f\"  Output file:      {OUTPUT_FILE}\")\n",
        "print(f\"  Prediction range: [{y_hat.min():.3f}, {y_hat.max():.3e}]\")\n"
      ],
      "metadata": {
        "id": "60pNVsPMMPml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kRFaLcuFQ87I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}